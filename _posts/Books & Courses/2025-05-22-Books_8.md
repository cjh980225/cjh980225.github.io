# 중고나라 휴대폰 거래가격 예측하기 

## 탐색적 분석 : 중고나라 데이터 분석하기 

|변수|내용|
|-|-|
|create_date|판매(혹은 구매)게시글이 올라온 시점|
|price|게시글 작성자가 제안한 휴대폰의 거래가격|
|text|게시글의 제목과 본문을 합친 텍스트 데이터|
|phone_model|휴대폰의 기종|
|factory_price|휴대폰 공시가격|
|maker|휴대폰 제조사|
|price_index|판매 게시글이 올라온 시점에서의 휴대폰 물가 지수 데이터|

🔍 중고나라 데이터셋 살펴보기


```python
# -*- coding : utf-8 -*-
%matplotlib inline 

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns 

df = pd.read_csv("./data/used_mobile_phone.csv")
print(df.info())
df.head()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 4951 entries, 0 to 4950
    Data columns (total 7 columns):
     #   Column         Non-Null Count  Dtype  
    ---  ------         --------------  -----  
     0   create_date    4951 non-null   object 
     1   price          4951 non-null   float64
     2   text           4951 non-null   object 
     3   phone_model    4951 non-null   object 
     4   factory_price  4951 non-null   int64  
     5   maker          4951 non-null   object 
     6   price_index    4951 non-null   float64
    dtypes: float64(2), int64(1), object(4)
    memory usage: 270.9+ KB
    None
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>create_date</th>
      <th>price</th>
      <th>text</th>
      <th>phone_model</th>
      <th>factory_price</th>
      <th>maker</th>
      <th>price_index</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2017-03-19  4 35 00 PM</td>
      <td>550000.0</td>
      <td>아이폰6플러스 블랙+애플라이트 64기가 팝니다  아이폰6플러스 블랙+애플라이트 64...</td>
      <td>iphone 6 64gb</td>
      <td>924000</td>
      <td>apple</td>
      <td>95.96</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2016-10-26  12 08 00 PM</td>
      <td>380000.0</td>
      <td>갤럭시s6엣지 32기가 팝니다 직거래  갤럭시s6엣지 32기가 품명 갤럭시s6엣지제...</td>
      <td>galaxy s6 edge 32gb</td>
      <td>979000</td>
      <td>samsung</td>
      <td>103.05</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2016-10-25  12 52 00 PM</td>
      <td>300000.0</td>
      <td>갤럭시s6 풀박스로 팝니다~~~ 새상품급  실기스조차 없어요  직접거래 구매한지 1...</td>
      <td>galaxy s6 32gb</td>
      <td>854000</td>
      <td>samsung</td>
      <td>103.05</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2017-03-23  11 14 00 PM</td>
      <td>290000.0</td>
      <td>sk  g5 티탄 폰 단품판매합니다  직접거래 sk g5 티탄 폰 단품판매합니다 올...</td>
      <td>lg g5 32gb</td>
      <td>836000</td>
      <td>lg</td>
      <td>95.96</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2016-04-11  7 35 00 PM</td>
      <td>280000.0</td>
      <td>sony 엑스페리아 c5 ultra e5506 16gb  미사용 새제품 팝니다 1...</td>
      <td>lg u 32gb</td>
      <td>396000</td>
      <td>lg</td>
      <td>102.59</td>
    </tr>
  </tbody>
</table>
</div>



🔍 개별 피처 탐색하기 : date 피처 탐색 


```python
# create_dat로부터 '월'을 의미하는 month 정보를 피처로 추출합니다. 
df['month'] = df['create_date'].apply(lambda x : x[:7])

# 월별 거래 횟수를 계산하여 출력합니다. 
df['month'].value_counts()
```




    month
    2016-10    2956
    2017-03    1311
    2016-08     107
    2016-09     105
    2016-04     102
    2016-05      89
    2016-06      76
    2016-07      74
    2016-03      70
    2016-02      61
    Name: count, dtype: int64



🔍 개별 피처 탐색하기 : date 피처 탐색


```python
df['create_date']
```




    0        2017-03-19  4 35 00 PM
    1       2016-10-26  12 08 00 PM
    2       2016-10-25  12 52 00 PM
    3       2017-03-23  11 14 00 PM
    4        2016-04-11  7 35 00 PM
                     ...           
    4946    2016-10-10  11 29 00 AM
    4947    2016-10-24  10 03 00 PM
    4948    2016-09-19  10 15 00 AM
    4949    2016-10-05  12 22 00 AM
    4950    2016-09-26  11 37 00 AM
    Name: create_date, Length: 4951, dtype: object




```python
# 일별 거래 횟수를 계산하여 그래프로 출력합니다. 
df['create_date'] = pd.to_datetime(df['create_date'].str[:10])
df_day = df.groupby('create_date').size()
df_day.plot()
plt.show()
```


    
![png](/assets/images/Book/8/output_6_0.png)
    


🔍 개별 피처 탐색하기 : price 피처 탐색 


```python
# 가격의 분포를 그래프로 탐색합니다. 
df['price'].hist(bins = "auto")
```




    <Axes: >




    
![png](/assets/images/Book/8/output_8_1.png)
    



```python
# 휴대폰 기종(phone_model)별 가격의 평균과 표준편차를 계산합니다. 
df_price_model_mean = df.groupby('phone_model')['price'].transform(lambda x : np.mean(x))
df_price_model_std = df.groupby('phone_model')['price'].transform(lambda x : np.std(x))

# 이를 바탕으로 모든 데이터의 z-score를 계산합니다. 이는 해당 데이터의 가격이 기종별 평균에 비해 어느 정도로 높거나 낮은지를 알 수 있게 하는 점수입니다. 
df_price_model_z_score = (df['price'] - df_price_model_mean) / df_price_model_std 
df_price_model_z_score.hist(bins = 'auto')
```




    <Axes: >




    
![png](/assets/images/Book/8/output_9_1.png)
    


🔍 개별 피처 탐색하기 : factory_price 피처 탐색 


```python
# factory_price 피처의 분포를 탐색합니다. 
df['factory_price'].hist(bins = 'auto')

# factory_price와 price 피처를 산점도 그래프로 출력하여 상관 관계를 살펴봅니다. 
df.plot.scatter(x = 'factory_price', y = 'price')
```




    <Axes: xlabel='factory_price', ylabel='price'>




    
![png](/assets/images/Book/8/output_11_1.png)
    



    
![png](/assets/images/Book/8/output_11_2.png)
    


🔍 개별 피처 탐색하기 : phone_model 피처 탐색 


```python
# 기종별 총 거래 데이터 개수를 집계합니다. 
model_counts = df['phone_model'].value_counts() 
print(model_counts.describe())

# 기종별 총 거래 데이터 개수를 상자 그림으로 살펴봅니다. 
plt.boxplot(model_counts)
plt.show()
```

    count      64.000000
    mean       77.359375
    std       143.432786
    min        10.000000
    25%        23.000000
    50%        35.000000
    75%        90.500000
    max      1002.000000
    Name: count, dtype: float64
    


    
![png](/assets/images/Book/8/output_13_1.png)
    


🔍 랜덤 포레스트 모델 

▪ 랜덤 포레스트 모델은 의사결정 나무 분석 방법을 응용한 것으로 의사 결정 나무를 여러 개 모아 하나의 숲을 구성하는 방법입니다. 하나의 모델이 정답을 푸는 것이 아닌, 여러 개의 모델이 정답을 함께 푸는 것이기 때문에 더 정확한 학습이 가능합니다. 또한 이 방법은 모델이 생성되는 과정에서의 피처 중요도를 계산하기 때문에 탐색적 데이터 분석에 자주 사용됩니다. 랜덤 포레스트 모델은 회귀와 분류, 두 가지에 모두 적용이 가능합니다. 

🔍 Random forest regressor를 이용한 가격 예측 


```python
from sklearn.model_selection import train_test_split 
from sklearn.feature_extraction import DictVectorizer 
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score 
from sklearn.metrics import mean_squared_error 

# 데이터를 학습/테스트용 데이터로 분리합니다. 
df = df[['price', 'phone_model', 'factory_price', 'maker', 'price_index', 'month']]
df = pd.get_dummies(df, columns = ['phone_model', 'maker', 'month'])
X = df.loc[:, df.columns != 'price']
y = df['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

# 랜덤 포레스트 모델을 학습합니다. 
forest = RandomForestRegressor(n_estimators = 1000, 
                               criterion = 'squared_error')
forest.fit(X_train, y_train)
y_train_pred = forest.predict(X_train)
y_test_pred = forest.predict(X_test)\

# 학습한 모델을 평가합니다. 
print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))
print('R² train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))
```

    MSE train : 10628134061.276, test : 13877320301.830
    R² train : 0.781, test : 0.683
    

🔍 피처 중요도 분석하기


```python
# 학습한 모델의 피처 중요도를 그래프로 살펴봅니다. 
importances = forest.feature_importances_
indices = np.argsort(importances)[::-1]
plt.bar(range(X.shape[1]), importances[indices])

# 학습한 모델의 피처 중요도를 출력합니다. 
feat_labels = X.columns.tolist()
feature = list(zip(feat_labels, forest.feature_importances_))
sorted(feature, key = lambda tup : tup[1], reverse = True)[:10]
```




    [('factory_price', 0.40720111478257826),
     ('maker_apple', 0.29722614544640963),
     ('phone_model_galaxy s3 3g 8gb', 0.021961223541541276),
     ('phone_model_iphone se 64gb', 0.021617636438905723),
     ('price_index', 0.020964037553217005),
     ('phone_model_galaxy s4 32gb', 0.017099664076278772),
     ('month_2017-03', 0.015072199987817987),
     ('maker_samsung', 0.014573106093241653),
     ('phone_model_galaxy s6 32gb', 0.012510113181179571),
     ('month_2016-05', 0.010929869652907428)]




    
![png](/assets/images/Book/8/output_17_1.png)
    



```python
# month 피처 중, 영향력이 높은순으로 정렬하여 출력합니다. 
for sorted_feature in sorted(feature, key = lambda tup : tup[1], reverse = True) : 
    if "month" in sorted_feature[0] : 
        print(sorted_feature)
```

    ('month_2017-03', 0.015072199987817987)
    ('month_2016-05', 0.010929869652907428)
    ('month_2016-09', 0.008264568985790957)
    ('month_2016-04', 0.0075219452690915645)
    ('month_2016-10', 0.0064203349153964685)
    ('month_2016-06', 0.004457627685315901)
    ('month_2016-08', 0.0036835895564042305)
    ('month_2016-07', 0.002683400557755442)
    ('month_2016-03', 0.002244525806963841)
    ('month_2016-02', 0.0010296127298496922)
    

## 피처 엔지니어링 : 예측 모델 개선하기 

|피처|분석 내용|파생 가능한 피처|
|-|-|-|
|date|월 단위로 살펴본 결과, 2016년 10월과 2017년 3월의 데이터가 가장 많습니다. 최근에 가까운 월(Month)일수록 예측 모델에 중요한 피처입니다. |게시글의 등록 월(Month)|
|price|전체 휴대폰의 거래가와 달리 기종별 가격의 분포는 정규 분포의 형태를 띠고 있습니다.|동일 기종 내 상대 가격(z-score)|
|factory_price|price 피처와의 양의 상관 관계가 관찰됩니다. 또한 예측 모델의 피처 중요도 분석 결과, 가장 중요한 피처로 나타났습니다.|-|
|phone_model|소수의 인기 기종이 많은 데이터를 가지고 있습니다.|휴대폰 세부 기종, 용량으로 분리한 2개의 피처|
|maker|Apple 브랜드가 가장 많으며, 가격 예측에서도 Apple 브랜드 여부는 가장 중요한 피처 중 하나입니다.|-|
|price_index|월별 변동이 크지 않으며, 총 4개의 값만을 가지고 있습니다. 가격 예측에서 그다지 중요한 피처는 아닙니다.|-|

🔍 기존 피처 가공하기 : 'create_date' 


```python
# 데이터를 다시 불러옵니다. 
df = pd.read_csv('./data/used_mobile_phone.csv')

from datetime import datetime 
import time 

# create_date 피처를 수치적으로 계산하기 위해 unixtime으로 변환하는 함수를 정의합니다. 
def date_to_unixtime(date_str) : 
    timestamp = time.mktime(datetime.strptime(date_str, '%Y-%m-%d').timetuple())
    return timestamp 

# create_date 피처를 '현재와 얼마나 가까운 데이터인지' 판단하기 위한 점수를 생성합니다. 먼저 unixtime으로 데이터를 변환합니다. 
df['create_unixtime'] = df['create_date'].apply(lambda x : date_to_unixtime(x[:10]))

# 변환된 unixtime에 min-max 스케일링을 적용합니다. 
df['create_time_score'] = (df['create_unixtime'] - df['create_unixtime'].min()) / (df['create_unixtime'].max() - df['create_unixtime'].min())
df[['create_date', 'create_unixtime', 'create_time_score']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>create_date</th>
      <th>create_unixtime</th>
      <th>create_time_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2017-03-19  4 35 00 PM</td>
      <td>1.489849e+09</td>
      <td>0.985612</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2016-10-26  12 08 00 PM</td>
      <td>1.477408e+09</td>
      <td>0.640288</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2016-10-25  12 52 00 PM</td>
      <td>1.477321e+09</td>
      <td>0.637890</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2017-03-23  11 14 00 PM</td>
      <td>1.490195e+09</td>
      <td>0.995204</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2016-04-11  7 35 00 PM</td>
      <td>1.460300e+09</td>
      <td>0.165468</td>
    </tr>
  </tbody>
</table>
</div>



🔍 기존 피처의 가공 : phone_model 


```python
# phone_model 피처에서 저장 용량(phone_model_storage) 피처를 추출합니다. 
df['phone_model_storage'] = df['phone_model'].apply(lambda x : x.split(" ")[-1])

# phone_model 피처에서 기종 세부명(phone_model_detail) 피처를 추출합니다. 
df['phone_model_detail'] = df['phone_model'].apply(lambda x : ' '.join(x.split(" ")[:-1]))
df[['phone_model_storage', 'phone_model_detail']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phone_model_storage</th>
      <th>phone_model_detail</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>64gb</td>
      <td>iphone 6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>32gb</td>
      <td>galaxy s6 edge</td>
    </tr>
    <tr>
      <th>2</th>
      <td>32gb</td>
      <td>galaxy s6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>32gb</td>
      <td>lg g5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32gb</td>
      <td>lg u</td>
    </tr>
  </tbody>
</table>
</div>




```python
# phone_model 피처의 기종별 거래 데이터 개수를 집계합니다. 
model_counts = df['phone_model'].value_counts()

# phone_model_detail 피처의 기종별 거래 데이터 개수를 집계합니다. 
model_detail_counts = df['phone_model_detail'].value_counts()
data = [model_counts, model_detail_counts] 

# 두 피처 간의 기종별 거래 데이터 개수를 비교합니다. 
mpl_fig = plt.figure()
ax = mpl_fig.add_subplot(111)
ax.boxplot(data)
plt.show()
```


    
![png](/assets/images/Book/8/output_23_0.png)
    


🔍 감성 분류로 물품의 상태 분류하기 


```python
# 거래 가격(price)의 z-score를 계산합니다. 이는 해당 데이터의 가격이 기종의 평균에 비해 어느 정도로 높거나 낮은지르 알 수 있게 하는 점수입니다. 
df['price_by_group'] = df.groupby('phone_model_detail')['price'].transform(lambda x : (x - x.mean()) / x.std())

#거래 가격의 z-score(price_by_group)의 분포를 그래프로 출력합니다. 
ax = df['price_by_group'].hist(bins = "auto")

# z-score(price_by_group) 기준으로 하위 5%, 상위 5%에 해당하는 점수를 lower_bound, upper_bound라고 지정합니다. 
lower_bound = df['price_by_group'].quantile(0.05)
upper_bound = df['price_by_group'].quantile(0.95)

# lower_bound, upper_bound 그래프에 추가합ㄴ디ㅏ. 
ax.axvline(x = lower_bound, color = 'r', linestyle = 'dashed', linewidth = 2)
ax.axvline(x = upper_bound, color = 'r', linestyle = 'dashed', linewidth = 2)

# lower_bound, upper_bound 출력합니다. 
print(lower_bound)
print(upper_bound)
```

    -1.3966616903783375
    1.666982156397844
    


    
![png](/assets/images/Book/8/output_25_1.png)
    



```python
# lower_bunde보다 낮으면 0, upper_bound보다 높으면 2, 그 중간이면 1로 가격의 상태를 분류하는 함수를 정의합니다. 
def get_price_level(price, lower, upper) : 
    if price <= lower : 
        return "0"
    elif price >= upper : 
        return "2"
    else :
        return "1"

# lower_bound보다 낮으면 0, upper_bound보다 높으면 2, 그 중간이면 1로 가격의 상태를 분류합니다. 
df['price_lower'] = df.groupby('phone_model_detail')['price'].transform(lambda x : x.quantile(0.05))
df['price_upper'] = df.groupby('phone_model_detail')['price'].transform(lambda x : x.quantile(0.95))
df['price_level'] = df.apply(lambda row : get_price_level(row['price'], row['price_lower'], row['price_upper']), axis = 1) 
df[['price', 'price_lower', 'price_upper', 'price_level', 'text']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>price_lower</th>
      <th>price_upper</th>
      <th>price_level</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>550000.0</td>
      <td>180000.0</td>
      <td>680000.0</td>
      <td>1</td>
      <td>아이폰6플러스 블랙+애플라이트 64기가 팝니다  아이폰6플러스 블랙+애플라이트 64...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>380000.0</td>
      <td>180000.0</td>
      <td>414000.0</td>
      <td>1</td>
      <td>갤럭시s6엣지 32기가 팝니다 직거래  갤럭시s6엣지 32기가 품명 갤럭시s6엣지제...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>300000.0</td>
      <td>150000.0</td>
      <td>349000.0</td>
      <td>1</td>
      <td>갤럭시s6 풀박스로 팝니다~~~ 새상품급  실기스조차 없어요  직접거래 구매한지 1...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>290000.0</td>
      <td>100000.0</td>
      <td>500000.0</td>
      <td>1</td>
      <td>sk  g5 티탄 폰 단품판매합니다  직접거래 sk g5 티탄 폰 단품판매합니다 올...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>280000.0</td>
      <td>18000.0</td>
      <td>400000.0</td>
      <td>1</td>
      <td>sony 엑스페리아 c5 ultra e5506 16gb  미사용 새제품 팝니다 1...</td>
    </tr>
  </tbody>
</table>
</div>



🔍 텍스트 전처리하기 


```python
import pickle 
import re 

# 중고나라 불용어 사전을 불러옵니다. 
with open('./data/used_mobile_phone_stopwords.pkl', 'rb') as f : 
    stopwords = pickle.load(f)

# 불용어 사전에 등록된 단어 10개를 출력합니다. 
print(stopwords[:10])
```

    ['거래', '입니', '판매', '아이폰', '갤럭시', '골드', '팝', '만원', '폰', '시']
    

🔍 형태소 단위로 추출하기


```python
from konlpy.tag import Okt 

# '+'를 제외한 특수문자를 제고하고, 숫자형태의 문자를 제거합니다. 
def text_cleaning(text) : 
    text = ''.join(c for c in text if c.isalnum() or c in '+, ')
    text = ''.join([i for i in text if not i.isdigit()])
    return text 

# 불용어에 등장하지 않는 형태소만을 추출하여 반환하는 함수입니다. 
def get_pos(x) : 
    tagger = Okt()
    poses = tagger.pos(x)
    return [pos[0] for pos in poses if pos[0] not in stopwords]

# 위 함수들을 적용한 형태소 추출을 테스트합니다. 
df['text'] = df['text'].apply(lambda x : text_cleaning(x))
result = get_pos(df['text'][0])
print(result)
```

    ['+', '애플', '라이트', '팝니다', '+', '애플', '라이트', '팝니다', '+', '애플', '라이트', '팝니다', '리퍼', '기간', '만료', '되어서', '징', '하게', '되었습니다', '상태', '초', 'a', '급', '스', '없습니다', '+', '애플', '라이트', '팝니다', '+', '애플', '라이트', '팝니다', '리퍼', '기간', '만료', '되어서', '징', '하게', '되었습니다', '상태', '초', 'a', '급', '스', '없습니다', '징', '애플', '라이트', '홈', '버튼', '링', '카메라', '링', '볼륨', '버튼', '슬립', '버튼', '검금', '심플', '튀지', '않게', '이쁘게', '했구요', '유심', '꽂고', '바로', '사용', '하시면', '됩니다', '사람', '이냐', '자주', '물어보고', '실제', '더욱', '이쁩니다', '밤', '영롱하게', '맥북', '뒷', '사과', '로고', '비춰지고', '요전', '넘어가기', '위해', '합니다', '가능합니다', '박스', '어머니', '버리시고', '이어폰', '충전기', '정품', '드립니다', '직거래', '우선', '순', '위로', '정', '싶으시면', '선', '입금', '택배', '발송', '해드리겠습니다', '믿으시면', '직거래', '하시길', '추천', '해요', '안전', '합니다', '서울시', '강남구', '역삼동', '차병원', '사거리', '근처', '가격']
    

🔍 빈출 형태소 2,500개 선정하기 


```python
from collections import Counter 

# get_pos() 함수를 모든 텍스트 데이터에 적용하여 형태소 말뭉치를 추출합니다. 
corpus = sum(df['text'].apply(lambda x : get_pos(x)).tolist(), []) 

# 추출된형태소 말뭉치에서 가장 많이 등장한 형태소 2500개를 추출합니다. 
counter = Counter(corpus)
common_words = [key for key, _ in counter.most_common(2500)]
common_words
```




    ['입니다',
     '직거래',
     's',
     '합니다',
     '택배',
     '사용',
     '급',
     '상태',
     '팝니다',
     '가능합니다',
     '정상',
     '사진',
     '가격',
     '+',
     '케이스',
     'a',
     '주세요',
     '해지',
     '삭제',
     '제품',
     '있습니다',
     '박스',
     '가능',
     '직접',
     '액정',
     '배터리',
     '성품',
     '필름',
     '리퍼',
     '충전기',
     '없습니다',
     '풀',
     '개통',
     '유심',
     '즈',
     '안전',
     '스',
     '하기',
     '신청',
     '드립니다',
     '통신사',
     '구입',
     '약정',
     '이어폰',
     '공기',
     '새',
     '기변',
     '포함',
     '모델',
     '선택',
     '됩니다',
     '확인',
     '기간',
     '기스',
     '그레이',
     '찍힘',
     '방법',
     '바로',
     '할인',
     '제',
     '시기',
     '스페이스',
     '희망',
     '번호',
     '중고나라',
     '본체',
     '같이',
     '생활',
     '잘',
     '무',
     '퀵',
     '글',
     '된',
     '않을',
     '공식',
     '앱',
     '확정',
     '기능',
     '다운',
     '양',
     '호환',
     '케이블',
     '받기',
     '미',
     '이메일',
     '작성',
     '부분',
     '금지',
     '될수',
     '식아이디',
     '허위',
     '임의',
     '통보',
     '채우지',
     '핸드폰',
     '편한',
     '전혀',
     '충전',
     '내용',
     '연락처',
     '단말기',
     '부산',
     '대구',
     '미사',
     '정품',
     '중고',
     '문제',
     '없이',
     '이상',
     '보호',
     '방문',
     '없는',
     '외관',
     '외',
     '인천',
     '깨끗합니다',
     'x',
     '초기',
     '하나',
     '참고',
     '이구',
     '요금',
     '개월',
     '이나',
     '사이트',
     '팔아요',
     '하시면',
     '했습니다',
     '동',
     '카페',
     '보내',
     '카톡',
     '블로그',
     '링크',
     '싸이',
     '강퇴',
     '삼성',
     '거치',
     '있는',
     '호선',
     '모든',
     '입금',
     '처리',
     '없음',
     '뒷',
     '핑크',
     '카메라',
     '거주지',
     '공',
     '하여',
     '역도',
     '재판매',
     '유도',
     '선',
     '교체',
     '강화유리',
     '경매',
     '만만',
     '부탁드립니다',
     '구성',
     '필수',
     '차대',
     '재시',
     '없고',
     '전체',
     '파손',
     '다른',
     '가능하며',
     '작동',
     '가능한',
     '교환',
     '드리겠습니다',
     '좋습니다',
     '기계',
     '생각',
     '그대로',
     '추가',
     '약간',
     '살짝',
     '바랍니다',
     '테두리',
     '풀박',
     '미개',
     '거의',
     '부담',
     '쪽',
     '조금',
     '비',
     '주시',
     'as',
     '하지',
     '싸게',
     '때',
     '하겠습니다',
     '봉',
     '완전',
     '상품',
     '댓글',
     '착불',
     '부착',
     '때문',
     '금액',
     '아주',
     '폴더',
     '원하시면',
     '와인',
     '할',
     '하며',
     '수',
     '하단',
     '현재',
     '거주',
     '한번',
     '버튼',
     '더',
     '가능하고',
     '정말',
     '있고',
     '엘지',
     '커버',
     '블루',
     '번',
     '원합니다',
     '기본',
     '해주세요',
     '터치',
     '그냥',
     '하는',
     '용감',
     '시간',
     '전부',
     '대전',
     '되어',
     '통화',
     '센터',
     '있구요',
     '쿨',
     '깨끗한',
     '앞',
     '새거',
     '미국',
     '같습니다',
     '광주',
     '근처',
     '없구요',
     '하실',
     '착',
     '방식',
     '환불',
     '애플',
     '아래',
     '서비스',
     '젤리',
     '유리',
     '가능하구요',
     '선호',
     '않습니다',
     '수원',
     '모서리',
     '곳',
     '달',
     '하세요',
     '스마트폰',
     '화면',
     '경기도',
     '신품',
     '강화',
     '제트',
     '드려요',
     '특',
     '부품',
     '발송',
     '년월',
     '상단',
     '유플러스',
     '새것',
     '이후',
     '풀셋',
     '좋은',
     '사양',
     '홍',
     '역',
     '개봉',
     '테스트',
     '수리',
     '있어요',
     '아무',
     '투명',
     '잔기스',
     '흠집',
     '미노트',
     '분실',
     '천안',
     '받은',
     '나머지',
     '점',
     '하자',
     '하시고',
     '저렴하게',
     '않은',
     '신분',
     '유',
     '용량',
     '하시는',
     '전면',
     '언락폰',
     '양호',
     '금',
     '하였습니다',
     '보시다시피',
     '별도',
     '하구요',
     '방탄',
     '스그',
     '여분',
     '본',
     '하셔도',
     '무상',
     '따로',
     '세이프',
     '좀',
     '와이파이',
     '무선',
     '제외',
     '종',
     '되었습니다',
     '천원',
     '프로',
     '눌',
     '매트',
     '배송',
     '약',
     '절충',
     '했구요',
     '우선',
     '대리점',
     '인터넷',
     '없으며',
     '수수료',
     '다시',
     '초',
     '끼',
     '평일',
     '삽니다',
     '고장',
     '이번',
     '부근',
     '겁니다',
     '아님',
     '매장',
     '해드립니다',
     '보조',
     '하던',
     '인식',
     '불량',
     '포장',
     '부천',
     '걸',
     '군데',
     '베가',
     '언제',
     '월일',
     '첨부',
     '전주',
     '항상',
     '갤',
     '처분',
     '불가',
     '비는',
     '매우',
     '남음',
     '없어요',
     '참조',
     '국내',
     '언',
     '가입',
     '잔',
     '지문',
     '있어서',
     '장소',
     '절대',
     '밑',
     '해외',
     '되는',
     '용인',
     '적용',
     '오시',
     '옵티머스',
     '있으며',
     '유니크로',
     '무음',
     '실사',
     '분만',
     '좋아요',
     '팔',
     '안녕하세요',
     '하면서',
     '답변',
     '작은',
     '젠더',
     '가능해요',
     '아직',
     '당연히',
     '넥서스',
     '최초',
     '불입',
     '삼',
     '베터리',
     '드릴게요',
     '개인',
     '오른쪽',
     '아이디',
     '밧데리',
     '드릴께요',
     '스크래치',
     '보관',
     '관심',
     '있지만',
     '선불',
     '변경',
     '큰',
     '되고',
     '팩',
     '공장',
     '급처',
     '꼭',
     '예약',
     '혹시',
     '감사합니다',
     '출구',
     '이용',
     '되구요',
     '안심',
     '내장',
     '펜',
     '먼저',
     '했던',
     '버전',
     '아닙니다',
     '메인보드',
     '안산',
     '한지',
     '안됩니다',
     '주말',
     '사절',
     '스마트',
     '하면',
     '용이',
     '한국',
     '문',
     '최상',
     '오늘',
     '겔럭시',
     '맥스',
     '하게',
     '너무',
     '필요하시면',
     '자국',
     '일본',
     '물',
     '홈',
     '보기',
     '지금',
     '있음',
     'nbsp',
     '최대한',
     '홍콩',
     '저녁',
     '답장',
     '보니',
     '가지',
     '있는데',
     '궁금하신',
     '쓰던',
     '보고',
     '왼쪽',
     '깨끗하고',
     '택포',
     '쪽지',
     '있으면',
     '작년',
     '기타',
     '반품',
     '뒤',
     '많은',
     '사항',
     '만료',
     '락',
     '문의사항',
     '아이언',
     '자세한',
     '상처',
     '그랜드',
     '범퍼',
     '붙여서',
     '진행',
     '청주',
     'schw',
     '알파',
     '남아있습니다',
     '분당',
     '위해',
     '배송비',
     '망',
     '기준',
     '카드',
     '드리구요',
     '네오',
     '사실',
     '임',
     '보이는',
     '오후',
     '사파이어',
     '새로',
     '조건',
     '침수',
     '인근',
     '해요',
     '자세히',
     '처음',
     '강남',
     '환영',
     '이어팟',
     '물건',
     '원하시는',
     '등록',
     '이미지',
     '일산',
     '이동',
     '또한',
     '징',
     '비닐',
     '찍힘이',
     '완납',
     '무료',
     '단자',
     '이외',
     '연',
     '금제',
     '구성은',
     '찍힌',
     '의사',
     '중화역',
     '있으나',
     '하니',
     '부',
     '의정부',
     '있으니',
     '일반',
     '남았습니다',
     '칩',
     '톡',
     '엑스페리아',
     '후시',
     '받지',
     '붙여',
     '빠른',
     '락폰',
     '개호환',
     '현상',
     '대개',
     '얼마',
     '제거',
     '감안',
     '했는데',
     '하였고',
     '안전거래도',
     '팜',
     '하려고',
     '올립니다',
     '예정',
     '유지',
     '목포',
     '월희',
     '알뜰폰',
     '둘다',
     '성남',
     '악세사리',
     '공공',
     '물품',
     '크게',
     '울산',
     '안양',
     '심',
     '같은',
     '집',
     '어댑터',
     '않았습니다',
     'iphone',
     '검수',
     '정중히',
     '레드',
     '전화기',
     '빼',
     '화웨이',
     '경기',
     '내년',
     '이력',
     '업무',
     '샤오미',
     '짐',
     '용기',
     '일단',
     '받고',
     '각',
     '있으시면',
     '광역시',
     '창원',
     '결과',
     '가죽',
     '설정',
     '하셔서',
     '어디',
     '이면',
     '지프로',
     '했고',
     '결제',
     '데이터',
     '전원',
     '미세한',
     'aa',
     '가능하니',
     '있으',
     '써서',
     '받습니다',
     '기존',
     '등등',
     '없네요',
     '되도록',
     '무기',
     '실기',
     '자부',
     '아시겠지만',
     '세트',
     '반',
     '눈',
     '우측',
     '언락',
     '올해',
     '빨리',
     '제조',
     '++',
     '주변',
     '않으며',
     '봅니다',
     '지원',
     '함',
     '상관없이',
     '입니다구',
     '이유',
     '가서',
     '위주',
     '않고',
     '출시',
     '화이트골드',
     '오닉스',
     '티',
     '내부',
     '쓰실',
     '없어서',
     'slte',
     '현금',
     '챙겨',
     '말씀',
     '보증',
     '에누리',
     'sktg',
     '전용',
     '신용',
     '헬로모바일',
     '통일',
     '실제',
     '드리고',
     '깨끗하게',
     '스피커',
     '총',
     '흰색',
     '우체국택배',
     '보면',
     '통신',
     '스카이',
     '쓰시',
     '밖에',
     '원래',
     '정보',
     '물론',
     '날',
     '마지막',
     '되어있습니다',
     '받았습니다',
     '애플스토어',
     '믿고',
     '흔적',
     '되면',
     '통',
     '드림',
     '실리콘',
     '선물',
     '위치',
     '조정',
     '회사',
     'plus',
     '근무',
     '바',
     '내놓습니다',
     '상해',
     '붙이',
     '있어',
     '지장',
     '되지',
     '셋',
     '부평',
     '편입',
     '김포',
     '의무',
     '안전하게',
     '일이',
     '시크릿',
     '칠',
     '거리',
     '인치',
     '역시',
     '흥정',
     '찔러',
     '빼고',
     '순천',
     'c',
     '비밀번호',
     '잠금',
     'sphw',
     '부탁',
     'cj',
     '직',
     '되며',
     '성능',
     '최상급',
     'aaa',
     '사서',
     '해지한',
     '램',
     '잠실',
     '스크레치',
     '걱정',
     '늦어요',
     '법적',
     '찍힘은',
     '순',
     '불로',
     '없지만',
     'lgsu',
     '다녀서',
     '넣어',
     '쓰고',
     '카카오',
     '받아서',
     '일주일',
     '지하철',
     '직구',
     '무조건',
     '평택',
     '협의',
     '루나',
     '잔기',
     '좋구요',
     '끝',
     '죄송합니다',
     '법',
     '빠르게',
     '하다가',
     '찍어',
     '안나',
     '로만',
     '브라운',
     '육',
     '티타늄',
     '안전한',
     '책임집니다',
     '되서',
     'note',
     '색',
     '티탄',
     '여기',
     '일체',
     '메모리',
     '측면',
     '옆',
     '드릴수',
     '오셔서',
     '외부',
     'gold',
     '빼고는',
     '우체국',
     '깨짐',
     '고객',
     '좋음',
     '특성',
     '기단',
     'lt',
     'dmb',
     'lglu',
     '좋겠습니다',
     '계속',
     '위쪽',
     '알',
     '하는데',
     '깨끗이',
     '하루',
     '드릴',
     '롬',
     '애지중지',
     '정',
     '서울시',
     '편이',
     '관계',
     '신규',
     '년도',
     '하였으며',
     '업',
     '어플',
     '지난',
     '쓴',
     '방수',
     '조회',
     '관',
     '하셔야',
     '시오',
     '슈피겐',
     '앞뒤',
     '추천',
     'lgsh',
     '서구',
     '상관없습니다',
     '가능하십니다',
     'm',
     '울',
     '별로',
     '이상무',
     '고속',
     '마시고',
     '등급',
     '저촉',
     '이기',
     '됐습니다',
     'smnk',
     '끝났습니다',
     '취급',
     '요청',
     '동봉',
     '팬택',
     '수준',
     '맨',
     '깨끗함',
     '세용',
     '동대문구',
     '깨진',
     '보입니다',
     '강동',
     '사설',
     '계양구',
     '업자',
     '퀄컴',
     '바꾸게',
     '본인',
     '키',
     '되있습니다',
     '이내',
     '진동',
     '같은거',
     '사은',
     '않아',
     '스티커',
     '깔끔한',
     '뽁뽁',
     '송파',
     '여부',
     '홍대',
     '롤리팝',
     '핀',
     'im',
     '깨끗',
     '블루투스',
     '씌우고',
     '깔끔합니다',
     '라인',
     '했어요',
     '남아',
     '쓰셔도',
     '할부',
     '값',
     '라이트닝',
     '해드리겠습니다',
     '보이지',
     '남겨주세요',
     '하다',
     '샤베트',
     'p',
     '검색',
     '끼워서',
     '인하',
     '남은',
     '받을',
     '관련',
     '드리고요',
     '경산',
     '끼우면',
     '사기',
     '영',
     '광양',
     '퀵서비스',
     '사람',
     '넣어서',
     '아니니',
     '마세요',
     '상의',
     '짜리',
     '현',
     '낮',
     '깨끗해요',
     '여러',
     '잭',
     '흠',
     '됨',
     '끝난',
     '설치',
     '있는거',
     '가장',
     '진짜',
     '광대역',
     '없다고',
     '찍힘이나',
     '원하구요',
     'ok',
     'lgkh',
     '자급',
     '아이',
     '경남',
     '오전',
     '부탁드려요',
     '일괄',
     '가셔서',
     '올려',
     '하시기',
     '대신',
     '촬영',
     '전북',
     '바꾸면서',
     '저장',
     '한글',
     '시세',
     '상자',
     '여수',
     '칠이사이',
     '답터',
     '착용',
     '이전',
     '멀쩡합니다',
     '연결',
     '해보니',
     '최저',
     '당일',
     '편의점',
     'shves',
     '써',
     '회',
     '알리',
     '드리며',
     '없고요',
     '파는',
     '있네요',
     '아예',
     '중랑구',
     '일자',
     '있고요',
     '월말',
     '쓰다가',
     '여서',
     '와같이',
     '받아',
     '소니',
     '스타일',
     '휘',
     '긁',
     '되었고',
     '요구',
     '가구',
     '뭐',
     '강동구',
     '실물',
     '넣고',
     '붙어있는',
     '되요',
     '가능하고요',
     '정식',
     '강남역',
     '눌러서',
     '점검',
     '일대',
     '보험',
     '밤',
     '둘',
     ...]



🔍 TF-IDF 벡터 생성하기 


```python
from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.feature_extraction.text import TfidfTransformer
from konlpy.tag import Okt

# 빈출 형태소를 제외한 모든 형태소를 제거하는 함수를 정의합니다. 
tagger = Okt()

def custom_analyzer(text):
    poses = tagger.pos(text)
    return [pos[0] for pos in poses if pos[0] in common_words]

# 1:3:1 비율로 랜덤 샘플링을 수행합니다. 
negative_random = df[df['price_level'] == '0'].sample(321, random_state = 30)
neutral_random = df[df['price_level'] == '1'].sample(321 * 3, random_state = 30) 
positive_random = df[df['price_level'] == '2'].sample(321, random_state = 30) 

# 샘플링 완료된 데이터셋을 정의합니다. 
df_sample = pd.concat([negative_random, neutral_random, positive_random], ignore_index=True)

# TF-IDF를 수행하여 피처를 변환합니다. 
index_vectorizer = CountVectorizer(analyzer = custom_analyzer)
X = index_vectorizer.fit_transform(df_sample['text'].tolist())
tfidf_vectorizer = TfidfTransformer()
X = tfidf_vectorizer.fit_transform(X)

# 감성 분류를 위한 학습 데이터셋을 정의합니다. 
y = df_sample['price_level']
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 30)
print(x_train.shape)
print(x_test.shape)
```


    ---------------------------------------------------------------------------

    KeyError                                  Traceback (most recent call last)

    File C:\python_basic\python3.9\lib\site-packages\pandas\core\indexes\base.py:3805, in Index.get_loc(self, key)
       3804 try:
    -> 3805     return self._engine.get_loc(casted_key)
       3806 except KeyError as err:
    

    File index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()
    

    File index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()
    

    File pandas\\_libs\\hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()
    

    File pandas\\_libs\\hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()
    

    KeyError: 'price_level'

    
    The above exception was the direct cause of the following exception:
    

    KeyError                                  Traceback (most recent call last)

    Cell In[46], line 13
         10     return [pos[0] for pos in poses if pos[0] in common_words]
         12 # 1:3:1 비율로 랜덤 샘플링을 수행합니다. 
    ---> 13 negative_random = df[df['price_level'] == '0'].sample(321, random_state = 30)
         14 neutral_random = df[df['price_level'] == '1'].sample(321 * 3, random_state = 30) 
         15 positive_random = df[df['price_level'] == '2'].sample(321, random_state = 30) 
    

    File C:\python_basic\python3.9\lib\site-packages\pandas\core\frame.py:4102, in DataFrame.__getitem__(self, key)
       4100 if self.columns.nlevels > 1:
       4101     return self._getitem_multilevel(key)
    -> 4102 indexer = self.columns.get_loc(key)
       4103 if is_integer(indexer):
       4104     indexer = [indexer]
    

    File C:\python_basic\python3.9\lib\site-packages\pandas\core\indexes\base.py:3812, in Index.get_loc(self, key)
       3807     if isinstance(casted_key, slice) or (
       3808         isinstance(casted_key, abc.Iterable)
       3809         and any(isinstance(x, slice) for x in casted_key)
       3810     ):
       3811         raise InvalidIndexError(key)
    -> 3812     raise KeyError(key) from err
       3813 except TypeError:
       3814     # If we have a listlike key, _check_indexing_error will raise
       3815     #  InvalidIndexError. Otherwise we fall through and re-raise
       3816     #  the TypeError.
       3817     self._check_indexing_error(key)
    

    KeyError: 'price_level'


🔍 상품의 상태 분류하기 


```python
from sklearn.metrics import accuracy_score 
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix 

# 비선형 SVM 분류 모델을 학습하고 평가합니다. 
svm = SVC(kernel = 'rbf', C = 10.0, random_state = 0, gamma = 0.10) 
svm.fit(x_train, y_train) 
y_pred_ksvc = svm.predict(x_test)
print('Accuracy : %.2f' % accuracy_score(y_test, y_pred_ksvc)) 

# Confusion matrix를 출력합니다. 
confmat = confusion_matrix(y_true = y_test, y_pred = y_pred_ksvc) 
print(confmat)
```

    Accuracy : 0.77
    [[ 30  28   4]
     [ 10 181  10]
     [  2  21  35]]
    

## 예측 : 중고 휴대폰 거래가 예측하기 

|피처|설명|
|-|-|
|create_time_score|create_date 피처를 unixtime으로 바꾸어 얼마나 오래된 게시물인지를 0~1 사이의 값으로 계산하여 표현합니다. 1에 가까울수록 최근에 작성한 게시물을 의미합니다.|
|phone_model_storage phone_model_detail|phone_model 피처를 둘로 나눈 것입니다.|
|product_status|동일 기종 내 상대 가격을 기준으로 텍스트 데이터의 감성(상품 상태)을 분류한 것입니다. 상품의 상태는 3개의 범주로 표현합니다.|

🔍 Random forest regressor 재학습하기 


```python
# text 피처로부터 '상품 상태 피처(product_status)'를 생성합니다. 
X = index_vectorizer.transform(df['text'].tolist())
X = tfidf_vectorizer.transform(X)
df['product_status'] = pd.Series(svm.predict(X))

# 랜덤 포레스트 모델 학습을 위한 데이터를 준비합니다. 
df = df[['price', 'factory_price', 'maker', 'price_index', 'create_time_score', 'phone_model_storage', 'phone_model_detail', 'product_status']]
df = pd.get_dummies(df, columns = ['maker', 'phone_model_storage', 'phone_model_detail', 'product_status'])

# 학습 / 테스트 데이터를 분리합니다. 
X = df.loc[:, df.columns != 'price']
y = df['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

# 랜덤 포레스트 모델을 학습하고 평가합니다. 
forest = RandomForestRegressor(n_estimators = 1000, 
                               criterion = 'squared_error')
forest.fit(X_train, y_train) 
y_train_pred = forest.predict(X_train)
y_test_pred = forest.predict(X_test) 
print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))
print('R² train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))

# 피처 중요도 plot을 출력합니다. 
importances = forest.feature_importances_
plt.plot(importances, "o")

# 피처 중요도를 print로 출력합니다. 
feat_labels = X.columns.tolist()
feature = list(zip(feat_labels, forest.feature_importances_))
sorted(feature, key = lambda tup : tup[1], reverse = True)[:10]
```

    MSE train : 4776787502.800, test : 10989939019.024
    R² train : 0.902, test : 0.749
    




    [('factory_price', 0.25541447618127155),
     ('maker_apple', 0.25412616119268205),
     ('create_time_score', 0.11668495448580446),
     ('phone_model_storage_16gb', 0.06051378719594219),
     ('product_status_2', 0.047367428981745625),
     ('phone_model_detail_galaxy s7 edge', 0.028075173013449806),
     ('phone_model_storage_64gb', 0.025290274383250877),
     ('phone_model_detail_galaxy note5', 0.02385578043405257),
     ('phone_model_detail_galaxy s7', 0.021782726181949062),
     ('product_status_0', 0.021419475822646257)]




    
![png](/assets/images/Book/8/output_38_2.png)
    


🔍 예측 결과 산점도 그래프 


```python
# 테스트 데이터의 y값과 예측된 y값을 산점도 그래프를 활용하여 상관 관계를 살펴봅니다. 
plt.scatter(y_test.values, y_test_pred)
```




    <matplotlib.collections.PathCollection at 0x1cca24a27f0>




    
![png](/assets/images/Book/8/output_40_1.png)
    


🔍 최적의 모델 파라미터 찾기 


```python
from sklearn.model_selection import RandomizedSearchCV

# Randomized Search로 찾아낼 파라미터 후보군을 각각 리스트로 선정합니다. 
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] 
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
bootstrap = [True, False] 

# RandomizedSearchCV 오브젝트를 생성하여 모델을 정의합니다. 
random_grid = {'n_estimators' : n_estimators, 
              'max_features' : max_features, 
              'max_depth' : max_depth, 
              'bootstrap' : bootstrap}
forest = RandomForestRegressor()
optimal_forest = RandomizedSearchCV(estimator = forest, 
                                    param_distributions = random_grid, 
                                    n_iter = 100, 
                                    cv = 3, 
                                    verbose = 2, 
                                    random_state = 42, 
                                    n_jobs = -1) 

# RandomizedSearchCV 모델을 학습합니다. 
X = df.loc[:, df.columns != 'price']
y = df['price']
optimal_forest.fit(X, y)
```

    Fitting 3 folds for each of 100 candidates, totalling 300 fits
    

    C:\python_basic\python3.9\lib\site-packages\sklearn\model_selection\_validation.py:528: FitFailedWarning: 
    120 fits failed out of a total of 300.
    The score on these train-test partitions for these parameters will be set to nan.
    If these failures are not expected, you can try to debug them by setting error_score='raise'.
    
    Below are more details about the failures:
    --------------------------------------------------------------------------------
    47 fits failed with the following error:
    Traceback (most recent call last):
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\model_selection\_validation.py", line 866, in _fit_and_score
        estimator.fit(X_train, y_train, **fit_params)
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\base.py", line 1382, in wrapper
        estimator._validate_params()
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\base.py", line 436, in _validate_params
        validate_parameter_constraints(
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\utils\_param_validation.py", line 98, in validate_parameter_constraints
        raise InvalidParameterError(
    sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.
    
    --------------------------------------------------------------------------------
    73 fits failed with the following error:
    Traceback (most recent call last):
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\model_selection\_validation.py", line 866, in _fit_and_score
        estimator.fit(X_train, y_train, **fit_params)
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\base.py", line 1382, in wrapper
        estimator._validate_params()
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\base.py", line 436, in _validate_params
        validate_parameter_constraints(
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\utils\_param_validation.py", line 98, in validate_parameter_constraints
        raise InvalidParameterError(
    sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.
    
      warnings.warn(some_fits_failed_message, FitFailedWarning)
    C:\python_basic\python3.9\lib\site-packages\sklearn\model_selection\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-13.65937944 -14.52390335 -14.5284538  -13.99875649 -14.58222073
     -13.36061919          nan -14.50886882 -13.57540033          nan
              nan          nan -14.57935743 -14.52489091 -13.37921243
     -13.32894865 -13.5217637           nan -13.37651722          nan
              nan          nan -13.20598533          nan          nan
     -14.49201868 -14.52376463          nan          nan          nan
     -14.5517001  -13.11146139          nan -14.49838937 -14.57688875
     -13.55702815          nan -13.32174781 -14.63419008 -12.88180624
     -14.56359166          nan -13.73369932          nan -13.39039801
              nan -14.57909513 -13.53539239 -13.48197411          nan
     -14.6128912           nan -14.48256156 -14.52870307          nan
              nan          nan          nan -14.5995115  -13.53770993
              nan -12.5151585  -13.68484306 -13.52295203 -13.50380885
              nan          nan          nan -13.42981901 -13.6277595
     -14.43237698 -13.49804953          nan          nan -13.49844051
     -13.38332709          nan -14.62415385 -14.54572495 -13.53803176
              nan -12.96686997 -13.42388862          nan -12.84564472
     -14.5005583           nan -13.60818056          nan -13.7258187
     -14.64789159          nan -13.65957203          nan          nan
     -14.53617181 -13.56716564          nan -14.56510044          nan]
      warnings.warn(
    




<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,
                   n_jobs=-1,
                   param_distributions={&#x27;bootstrap&#x27;: [True, False],
                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,
                                                      70, 80, 90, 100, 110,
                                                      None],
                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],
                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,
                                                         1000, 1200, 1400, 1600,
                                                         1800, 2000]},
                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>RandomizedSearchCV</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">?<span>Documentation for RandomizedSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,
                   n_jobs=-1,
                   param_distributions={&#x27;bootstrap&#x27;: [True, False],
                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,
                                                      70, 80, 90, 100, 110,
                                                      None],
                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],
                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,
                                                         1000, 1200, 1400, 1600,
                                                         1800, 2000]},
                   random_state=42, verbose=2)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>best_estimator_: RandomForestRegressor</div></div></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(bootstrap=False, max_depth=10, max_features=&#x27;sqrt&#x27;,
                      n_estimators=800)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>RandomForestRegressor</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html">?<span>Documentation for RandomForestRegressor</span></a></div></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(bootstrap=False, max_depth=10, max_features=&#x27;sqrt&#x27;,
                      n_estimators=800)</pre></div> </div></div></div></div></div></div></div></div></div>




```python
# 앞서 선정한 파라미터 후보군 중에서 가장 좋은 결과를 보인 파라미터의 조합을 출력합니다. 
print(optimal_forest.best_params_)
```

    {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}
    

🔍 최적 모델 학습 결과 


```python
# 최적의 파라미터를 적용한 모델로 중고 휴대폰의 가격을 예측하고 평가합니다. 
y_train_pred = optimal_forest.predict(X_train)
y_test_pred = optimal_forest.predict(X_test) 
print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))
print('R² train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))

# 가격 예측 모델의 피처 중요도 plot을 출력합니다. 
importances = optimal_forest.best_estimator_.feature_importances_
indices = np.argsort(importances)[::-1]
plt.bar(range(X.shape[1]), importances[indices])

# 가격 예측 모델의 피처 중요도를 출력합니다. 
feat_labels = X.columns.tolist()
feature = list(zip(feat_labels, optimal_forest.best_estimator_.feature_importances_))
sorted(feature, key = lambda tup : tup[1], reverse = True)[:10]
```

    MSE train : 9147924289.929, test : 8523056673.840
    R² train : 0.811, test : 0.805
    




    [('factory_price', 0.12862997585867847),
     ('maker_apple', 0.10688582914657667),
     ('phone_model_storage_128gb', 0.08710363454652008),
     ('phone_model_detail_iphone 7', 0.08602750647756545),
     ('phone_model_storage_64gb', 0.08098972166396726),
     ('create_time_score', 0.04967264647569188),
     ('product_status_0', 0.0405762829270737),
     ('phone_model_detail_iphone 7 plus', 0.0374777624382044),
     ('phone_model_storage_16gb', 0.03590211566115451),
     ('product_status_2', 0.03492787121301639)]




    
![png](/assets/images/Book/8/output_45_2.png)
    


🔍 예측 결과 산점도 그래프


```python
# 테스트 데이터의 y값과, 예측된 y값을 산점도 그래프를 활용하여 상관 관계를 살펴봅니다. 
plt.scatter(y_test.values, y_test_pred)
```




    <matplotlib.collections.PathCollection at 0x1ccc04b3880>




    
![png](/assets/images/Book/8/output_47_1.png)
    


## 프로토타입 : 얼마고(Almhago?)

🔍 재사용을 위한 파일 저장하기


```python
import joblib 

# 모델명 + 용량으로 출고가를 찾을 수 있는 딕셔너리를 생성합니다. 
model_to_factory_price_dict = {} 

for index, row in df.iterrows():
    # One-Hot된 컬럼들 중에서 True인 값을 복원
    detail = [col.replace('phone_model_detail_', '') for col in row.index if col.startswith('phone_model_detail_') and row[col] == True]
    storage = [col.replace('phone_model_storage_', '') for col in row.index if col.startswith('phone_model_storage_') and row[col] == True]

    # 둘 다 있을 경우만 딕셔너리에 등록
    if detail and storage:
        model_concat = (detail[0], storage[0])
        if model_concat not in model_to_factory_price_dict:
            model_to_factory_price_dict[model_concat] = row['factory_price']

print(str(model_to_factory_price_dict)[:40], "...")

# 프로그램에서 입력값에 대한 피처를 찾기 위한 딕셔너리를 생성합니다. 
col_to_index_dict = {} 
for idx, col in enumerate(df.columns[1:]) : 
    col_to_index_dict[col] = idx 

print(str(col_to_index_dict)[:40], "...")

# 모델 예측을 위한 중간 오브젝트들을 각각 파일로 저장합니다. 
with open('./data/used_mobile_pickles/model_to_factory_price_dict.pickle', 'wb') as f : 
    pickle.dump(model_to_factory_price_dict, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/col_to_index_dict.pickle', 'wb') as f : 
    pickle.dump(col_to_index_dict, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/common_words.pickle', 'wb') as f : 
    pickle.dump(common_words, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/init_vectorizer_vocabulary.pickle', 'wb') as f : 
    pickle.dump(index_vectorizer.vocabulary_, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/tfidf_vectorizer.pickle', 'wb') as f : 
    pickle.dump(tfidf_vectorizer, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/svm_classifier.pickle', 'wb') as f : 
    pickle.dump(svm, f, pickle.HIGHEST_PROTOCOL) 

joblib.dump(optimal_forest.best_estimator_, './data/used_mobile_pickles/rf_regressor.pickle', compress = 1) 
```

    {('iphone 6', '64gb'): 924000, ('galaxy  ...
    {'factory_price': 0, 'price_index': 1, ' ...
    




    ['./data/used_mobile_pickles/rf_regressor.pickle']



🔍 프로그램(클래스) 만들기 


```python
import numpy as np 

from konlpy.tag import Okt 
from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestRegressor 
from sklearn.model_selection import RandomizedSearchCV 

class Almhago() : 
    def __init__(self, model_to_factory_price_dict, col_to_index_dict, common_words, init_vectorizer_vocabulary, 
                 tfidf_vectorizer, prd_status_classifier, price_regressor) : 
        self._model_to_factory_price_dict = model_to_factory_price_dict
        self._col_to_index_dict = col_to_index_dict
        self._common_words = common_words 
        self._init_vectorizer_vocabulary = init_vectorizer_vocabulary 
        self._index_vectorizer = self._init_index_vectorizer()
        self._tfidf_vectorizer = tfidf_vectorizer 
        self._prd_status_classifier = prd_status_classifier 
        self._price_regressor = price_regressor 

    def _get_common_pos(self, x) : 
        tagger = Okt()
        poses = tagger.pos(x) 
        return [pos[0] for pos in poses if pos[0] in self._common_words] 

    def _text_cleaning(self, text) : 
        text = ''.join(c for c in text if c.isalnum() or c in '+, ')
        text = ''.join([i for i in text if not i.isdigit()])
        return text 

    def _init_index_vectorizer(self) : 
        word_index_vectorizer = CountVectorizer(tokenizer = lambda x : self._get_common_pos(x))
        word_index_vectorizer.vocabulary_ = self._init_vectorizer_vocabulary
        return word_index_vectorizer 

    def _get_ftr_price(self, model_name, storage) : 
        return self._model_to_factory_price_dict[(model_name, storage)] 

    def _get_prd_status(self, text) : 
        X = self._index_vectorizer.transform([self._text_cleaning(program_test_dict['text'])])
        X = self._tfidf_vectorizer.transform(X)
        return self._prd_status_classifier.predict(X)[0]

    def _print_almhago(self, model, price, prd_status) : 
        status = ""
        if prd_status == "0" : 
            status = "불량한" 
        elif prd_status == "1" : 
            status = "양호한" 
        else : 
            status = "좋은"
        print("선택하신", model, "모델은", status, "상태입니다. Almhago 예상 가격은", str(int(price[0])), "원 입니다.")

    def predict(self, input_dict) : 
        feature = np.zeros(64)
        feature[self._col_to_index_dict['factory_price']] = self._get_ftr_price(input_dict['phone_model_detail'], input_dict['phone_model_storage'])
        feature[self._col_to_index_dict['price_index']] = input_dict['price_index']
        feature[self._col_to_index_dict['create_time_score']] = input_dict['create_time_score']
        feature[self._col_to_index_dict["_".join(['maker', input_dict['maker']])]] = 1
        feature[self._col_to_index_dict["_".join(["phone_model_detail", input_dict['phone_model_detail']])]] = 1
        feature[self._col_to_index_dict["_".join(['phone_model_storage', input_dict['phone_model_storage']])]] = 1
        feature[self._col_to_index_dict["_".join(['product_status', self._get_prd_status(input_dict['text'])])]] = 1
    
        # ✅ 경고 없이 예측하기 위해 DataFrame으로 변환
        import pandas as pd
        feature_df = pd.DataFrame([feature], columns=list(self._col_to_index_dict.keys()))
        predicted_price = self._price_regressor.predict(feature_df)
    
        self._print_almhago(input_dict['phone_model_detail'], 
                            predicted_price, 
                            self._get_prd_status(input_dict['text']))
```

🔍 프로그램 테스트하기 


```python
import pickle
import joblib

# 저장했던 객체들 로드
with open('./data/used_mobile_pickles/model_to_factory_price_dict.pickle', 'rb') as f:
    model_to_factory_price_dict = pickle.load(f)

with open('./data/used_mobile_pickles/col_to_index_dict.pickle', 'rb') as f:
    col_to_index_dict = pickle.load(f)

with open('./data/used_mobile_pickles/common_words.pickle', 'rb') as f:
    common_words = pickle.load(f)

with open('./data/used_mobile_pickles/init_vectorizer_vocabulary.pickle', 'rb') as f:
    init_vectorizer_vocabulary = pickle.load(f)

with open('./data/used_mobile_pickles/tfidf_vectorizer.pickle', 'rb') as f:
    tfidf_vectorizer = pickle.load(f)

with open('./data/used_mobile_pickles/svm_classifier.pickle', 'rb') as f:
    svm_classifier = pickle.load(f)

rf_regressor = joblib.load('./data/used_mobile_pickles/rf_regressor.pickle')

```


```python
# 데이터의 가장 최근 시점인 2017년 4월을 기준으로 하기 위한 2개(price_index, create_time_score)의 피처를 정의합니다. 
recent_price_index =  95.96
recent_create_time_score = 1.0 

# 판매 가격을 예측하고자 하는 메이커, 기종, 용량을 입력하고, 상품의 상태를 나타내는 게시글을 입력합니다. 
program_test_dict = {'maker' : 'apple', 
                    'phone_model_detail' : 'iphone 6', 
                    'phone_model_storage' : '16gb', 
                    'text' : '아이폰6스페이스그레이 16기가 10만원에 팔아요~ 직접거래\
                    메인보드 세척 완료 한 침수 폰입니다폰 안켜지는 상테이구요 고쳐서 쓰실분 가져가세요10만원에 팔아요 \
                    리퍼한지 얼마안되서 기스 이런거 하나도 없습니당~서울 강남 근처 직거래 가능하며택배거래도 가능해요', 
                    'price_index' : recent_price_index, 
                    'create_time_score' : recent_create_time_score}

# 정의한 피처를 파라미터로 하여 almhago 오브젝트를 생성합니다. 
almhago = Almhago(model_to_factory_price_dict, col_to_index_dict, common_words, init_vectorizer_vocabulary, tfidf_vectorizer, svm_classifier, rf_regressor) 

# 입력한 데이터로 판매 가격을 예측합니다. 
almhago.predict(program_test_dict)
```

    선택하신 iphone 6 모델은 불량한 상태입니다. Almhago 예상 가격은 184641 원 입니다.
    

## 표로 정리하는 데이터 분석

|주요 키워드|핵심 내용|설명|
|-|-|-|
|랜덤 포레스트 모델|랜덤 포레스트 예측 모델을 활용한 데이터 분석|랜덤 포레스트 모델은 의사결정 나무(Decision Tree)를 응용한 모델로 회귀와 분류를 모두 수행할 수 있습니다. 또한 피처 중요도를 분석할 수 있기 때문에 탐색적 데이터 분석의 과정에서도 유용하게 사용할 수 있습니다.|
|그룹 내 피처의 표준화|z-score를 계산하여 피처를 표준화 하는 방법|피처의 평균값, 그리고 표준편차 값을 이용하여 그룹 내의 피처를 z-score로 변환합니다. 이를 통해 데이터의 상대적 위치를 점수로 표현할 수 있습니다.|
|시계열 데이터의 활용|unixtime을 이용한 시간 점수 계산|시간을 피처로 활용하기 위해 unixtime을 이용하여 '얼마나 오래되었는가'를 점수로 나타내었습니다. 그리고 이를 다시 min-max 스케일링을 적용하여 0~1 사이의 값으로 변환합니다. 이 값이 1에 가까울수록 최근의 데이터를 의미합니다.|
|감성 분류의 과정|직접 감성 분류를 설계하여 평가하는 방법|z-score로 가격의 상, 중, 하를 결정한 뒤, 이를 감성 분류의 정답 데이터셋으로 활용합니다. 피처를 만들기 위해 빈출 단어 3,000개 내에서의 TF-IDF 변환을 사용하였고, 감성 분류 모델읜 SVM을 사용하였습니다.|
|최적 파라미터 튜닝|분류 모델에서의 클래스 불균형 문제|분류 모델에서는 Positive sample, Negative sample의 비율 때문에 클래스 불균형 문제가 발생합니다.|
|프로그램 응용|분석 모델을 프로그램으로 만들기|분석의 과정에서 생성된 Dictionary, 모델 객체 등을 모두 파일 형태로 저장합니다. 이를 활용하여 입력 데이터를 피처로 변환하고, 변환된 피처를 모델의 predict() 함수에 입력합니다. 그 결과, 분석 과정에서와 똑같은 결과를 프로그램에서 실행할 수 있습니다.|
