# ì¤‘ê³ ë‚˜ë¼ íœ´ëŒ€í° ê±°ë˜ê°€ê²© ì˜ˆì¸¡í•˜ê¸° 

## íƒìƒ‰ì  ë¶„ì„ : ì¤‘ê³ ë‚˜ë¼ ë°ì´í„° ë¶„ì„í•˜ê¸° 

|ë³€ìˆ˜|ë‚´ìš©|
|-|-|
|create_date|íŒë§¤(í˜¹ì€ êµ¬ë§¤)ê²Œì‹œê¸€ì´ ì˜¬ë¼ì˜¨ ì‹œì |
|price|ê²Œì‹œê¸€ ì‘ì„±ìê°€ ì œì•ˆí•œ íœ´ëŒ€í°ì˜ ê±°ë˜ê°€ê²©|
|text|ê²Œì‹œê¸€ì˜ ì œëª©ê³¼ ë³¸ë¬¸ì„ í•©ì¹œ í…ìŠ¤íŠ¸ ë°ì´í„°|
|phone_model|íœ´ëŒ€í°ì˜ ê¸°ì¢…|
|factory_price|íœ´ëŒ€í° ê³µì‹œê°€ê²©|
|maker|íœ´ëŒ€í° ì œì¡°ì‚¬|
|price_index|íŒë§¤ ê²Œì‹œê¸€ì´ ì˜¬ë¼ì˜¨ ì‹œì ì—ì„œì˜ íœ´ëŒ€í° ë¬¼ê°€ ì§€ìˆ˜ ë°ì´í„°|

ğŸ” ì¤‘ê³ ë‚˜ë¼ ë°ì´í„°ì…‹ ì‚´í´ë³´ê¸°


```python
# -*- coding : utf-8 -*-
%matplotlib inline 

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns 

df = pd.read_csv("./data/used_mobile_phone.csv")
print(df.info())
df.head()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 4951 entries, 0 to 4950
    Data columns (total 7 columns):
     #   Column         Non-Null Count  Dtype  
    ---  ------         --------------  -----  
     0   create_date    4951 non-null   object 
     1   price          4951 non-null   float64
     2   text           4951 non-null   object 
     3   phone_model    4951 non-null   object 
     4   factory_price  4951 non-null   int64  
     5   maker          4951 non-null   object 
     6   price_index    4951 non-null   float64
    dtypes: float64(2), int64(1), object(4)
    memory usage: 270.9+ KB
    None
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>create_date</th>
      <th>price</th>
      <th>text</th>
      <th>phone_model</th>
      <th>factory_price</th>
      <th>maker</th>
      <th>price_index</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2017-03-19  4 35 00 PM</td>
      <td>550000.0</td>
      <td>ì•„ì´í°6í”ŒëŸ¬ìŠ¤ ë¸”ë™+ì• í”Œë¼ì´íŠ¸ 64ê¸°ê°€ íŒë‹ˆë‹¤  ì•„ì´í°6í”ŒëŸ¬ìŠ¤ ë¸”ë™+ì• í”Œë¼ì´íŠ¸ 64...</td>
      <td>iphone 6 64gb</td>
      <td>924000</td>
      <td>apple</td>
      <td>95.96</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2016-10-26  12 08 00 PM</td>
      <td>380000.0</td>
      <td>ê°¤ëŸ­ì‹œs6ì—£ì§€ 32ê¸°ê°€ íŒë‹ˆë‹¤ ì§ê±°ë˜  ê°¤ëŸ­ì‹œs6ì—£ì§€ 32ê¸°ê°€ í’ˆëª… ê°¤ëŸ­ì‹œs6ì—£ì§€ì œ...</td>
      <td>galaxy s6 edge 32gb</td>
      <td>979000</td>
      <td>samsung</td>
      <td>103.05</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2016-10-25  12 52 00 PM</td>
      <td>300000.0</td>
      <td>ê°¤ëŸ­ì‹œs6 í’€ë°•ìŠ¤ë¡œ íŒë‹ˆë‹¤~~~ ìƒˆìƒí’ˆê¸‰  ì‹¤ê¸°ìŠ¤ì¡°ì°¨ ì—†ì–´ìš”  ì§ì ‘ê±°ë˜ êµ¬ë§¤í•œì§€ 1...</td>
      <td>galaxy s6 32gb</td>
      <td>854000</td>
      <td>samsung</td>
      <td>103.05</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2017-03-23  11 14 00 PM</td>
      <td>290000.0</td>
      <td>sk  g5 í‹°íƒ„ í° ë‹¨í’ˆíŒë§¤í•©ë‹ˆë‹¤  ì§ì ‘ê±°ë˜ sk g5 í‹°íƒ„ í° ë‹¨í’ˆíŒë§¤í•©ë‹ˆë‹¤ ì˜¬...</td>
      <td>lg g5 32gb</td>
      <td>836000</td>
      <td>lg</td>
      <td>95.96</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2016-04-11  7 35 00 PM</td>
      <td>280000.0</td>
      <td>sony ì—‘ìŠ¤í˜ë¦¬ì•„ c5 ultra e5506 16gb  ë¯¸ì‚¬ìš© ìƒˆì œí’ˆ íŒë‹ˆë‹¤ 1...</td>
      <td>lg u 32gb</td>
      <td>396000</td>
      <td>lg</td>
      <td>102.59</td>
    </tr>
  </tbody>
</table>
</div>



ğŸ” ê°œë³„ í”¼ì²˜ íƒìƒ‰í•˜ê¸° : date í”¼ì²˜ íƒìƒ‰ 


```python
# create_datë¡œë¶€í„° 'ì›”'ì„ ì˜ë¯¸í•˜ëŠ” month ì •ë³´ë¥¼ í”¼ì²˜ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. 
df['month'] = df['create_date'].apply(lambda x : x[:7])

# ì›”ë³„ ê±°ë˜ íšŸìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤. 
df['month'].value_counts()
```




    month
    2016-10    2956
    2017-03    1311
    2016-08     107
    2016-09     105
    2016-04     102
    2016-05      89
    2016-06      76
    2016-07      74
    2016-03      70
    2016-02      61
    Name: count, dtype: int64



ğŸ” ê°œë³„ í”¼ì²˜ íƒìƒ‰í•˜ê¸° : date í”¼ì²˜ íƒìƒ‰


```python
df['create_date']
```




    0        2017-03-19  4 35 00 PM
    1       2016-10-26  12 08 00 PM
    2       2016-10-25  12 52 00 PM
    3       2017-03-23  11 14 00 PM
    4        2016-04-11  7 35 00 PM
                     ...           
    4946    2016-10-10  11 29 00 AM
    4947    2016-10-24  10 03 00 PM
    4948    2016-09-19  10 15 00 AM
    4949    2016-10-05  12 22 00 AM
    4950    2016-09-26  11 37 00 AM
    Name: create_date, Length: 4951, dtype: object




```python
# ì¼ë³„ ê±°ë˜ íšŸìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ê·¸ë˜í”„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. 
df['create_date'] = pd.to_datetime(df['create_date'].str[:10])
df_day = df.groupby('create_date').size()
df_day.plot()
plt.show()
```


    
![png](/assets/images/Book/8/output_6_0.png)
    


ğŸ” ê°œë³„ í”¼ì²˜ íƒìƒ‰í•˜ê¸° : price í”¼ì²˜ íƒìƒ‰ 


```python
# ê°€ê²©ì˜ ë¶„í¬ë¥¼ ê·¸ë˜í”„ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤. 
df['price'].hist(bins = "auto")
```




    <Axes: >




    
![png](/assets/images/Book/8/output_8_1.png)
    



```python
# íœ´ëŒ€í° ê¸°ì¢…(phone_model)ë³„ ê°€ê²©ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. 
df_price_model_mean = df.groupby('phone_model')['price'].transform(lambda x : np.mean(x))
df_price_model_std = df.groupby('phone_model')['price'].transform(lambda x : np.std(x))

# ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë“  ë°ì´í„°ì˜ z-scoreë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ëŠ” í•´ë‹¹ ë°ì´í„°ì˜ ê°€ê²©ì´ ê¸°ì¢…ë³„ í‰ê· ì— ë¹„í•´ ì–´ëŠ ì •ë„ë¡œ ë†’ê±°ë‚˜ ë‚®ì€ì§€ë¥¼ ì•Œ ìˆ˜ ìˆê²Œ í•˜ëŠ” ì ìˆ˜ì…ë‹ˆë‹¤. 
df_price_model_z_score = (df['price'] - df_price_model_mean) / df_price_model_std 
df_price_model_z_score.hist(bins = 'auto')
```




    <Axes: >




    
![png](/assets/images/Book/8/output_9_1.png)
    


ğŸ” ê°œë³„ í”¼ì²˜ íƒìƒ‰í•˜ê¸° : factory_price í”¼ì²˜ íƒìƒ‰ 


```python
# factory_price í”¼ì²˜ì˜ ë¶„í¬ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤. 
df['factory_price'].hist(bins = 'auto')

# factory_priceì™€ price í”¼ì²˜ë¥¼ ì‚°ì ë„ ê·¸ë˜í”„ë¡œ ì¶œë ¥í•˜ì—¬ ìƒê´€ ê´€ê³„ë¥¼ ì‚´í´ë´…ë‹ˆë‹¤. 
df.plot.scatter(x = 'factory_price', y = 'price')
```




    <Axes: xlabel='factory_price', ylabel='price'>




    
![png](/assets/images/Book/8/output_11_1.png)
    



    
![png](/assets/images/Book/8/output_11_2.png)
    


ğŸ” ê°œë³„ í”¼ì²˜ íƒìƒ‰í•˜ê¸° : phone_model í”¼ì²˜ íƒìƒ‰ 


```python
# ê¸°ì¢…ë³„ ì´ ê±°ë˜ ë°ì´í„° ê°œìˆ˜ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤. 
model_counts = df['phone_model'].value_counts() 
print(model_counts.describe())

# ê¸°ì¢…ë³„ ì´ ê±°ë˜ ë°ì´í„° ê°œìˆ˜ë¥¼ ìƒì ê·¸ë¦¼ìœ¼ë¡œ ì‚´í´ë´…ë‹ˆë‹¤. 
plt.boxplot(model_counts)
plt.show()
```

    count      64.000000
    mean       77.359375
    std       143.432786
    min        10.000000
    25%        23.000000
    50%        35.000000
    75%        90.500000
    max      1002.000000
    Name: count, dtype: float64
    


    
![png](/assets/images/Book/8/output_13_1.png)
    


ğŸ” ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ 

â–ª ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì€ ì˜ì‚¬ê²°ì • ë‚˜ë¬´ ë¶„ì„ ë°©ë²•ì„ ì‘ìš©í•œ ê²ƒìœ¼ë¡œ ì˜ì‚¬ ê²°ì • ë‚˜ë¬´ë¥¼ ì—¬ëŸ¬ ê°œ ëª¨ì•„ í•˜ë‚˜ì˜ ìˆ²ì„ êµ¬ì„±í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. í•˜ë‚˜ì˜ ëª¨ë¸ì´ ì •ë‹µì„ í‘¸ëŠ” ê²ƒì´ ì•„ë‹Œ, ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ì´ ì •ë‹µì„ í•¨ê»˜ í‘¸ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ë” ì •í™•í•œ í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë˜í•œ ì´ ë°©ë²•ì€ ëª¨ë¸ì´ ìƒì„±ë˜ëŠ” ê³¼ì •ì—ì„œì˜ í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ì— ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤. ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì€ íšŒê·€ì™€ ë¶„ë¥˜, ë‘ ê°€ì§€ì— ëª¨ë‘ ì ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. 

ğŸ” Random forest regressorë¥¼ ì´ìš©í•œ ê°€ê²© ì˜ˆì¸¡ 


```python
from sklearn.model_selection import train_test_split 
from sklearn.feature_extraction import DictVectorizer 
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score 
from sklearn.metrics import mean_squared_error 

# ë°ì´í„°ë¥¼ í•™ìŠµ/í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤. 
df = df[['price', 'phone_model', 'factory_price', 'maker', 'price_index', 'month']]
df = pd.get_dummies(df, columns = ['phone_model', 'maker', 'month'])
X = df.loc[:, df.columns != 'price']
y = df['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. 
forest = RandomForestRegressor(n_estimators = 1000, 
                               criterion = 'squared_error')
forest.fit(X_train, y_train)
y_train_pred = forest.predict(X_train)
y_test_pred = forest.predict(X_test)\

# í•™ìŠµí•œ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤. 
print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))
print('RÂ² train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))
```

    MSE train : 10628134061.276, test : 13877320301.830
    RÂ² train : 0.781, test : 0.683
    

ğŸ” í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„í•˜ê¸°


```python
# í•™ìŠµí•œ ëª¨ë¸ì˜ í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ê·¸ë˜í”„ë¡œ ì‚´í´ë´…ë‹ˆë‹¤. 
importances = forest.feature_importances_
indices = np.argsort(importances)[::-1]
plt.bar(range(X.shape[1]), importances[indices])

# í•™ìŠµí•œ ëª¨ë¸ì˜ í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. 
feat_labels = X.columns.tolist()
feature = list(zip(feat_labels, forest.feature_importances_))
sorted(feature, key = lambda tup : tup[1], reverse = True)[:10]
```




    [('factory_price', 0.40720111478257826),
     ('maker_apple', 0.29722614544640963),
     ('phone_model_galaxy s3 3g 8gb', 0.021961223541541276),
     ('phone_model_iphone se 64gb', 0.021617636438905723),
     ('price_index', 0.020964037553217005),
     ('phone_model_galaxy s4 32gb', 0.017099664076278772),
     ('month_2017-03', 0.015072199987817987),
     ('maker_samsung', 0.014573106093241653),
     ('phone_model_galaxy s6 32gb', 0.012510113181179571),
     ('month_2016-05', 0.010929869652907428)]




    
![png](/assets/images/Book/8/output_17_1.png)
    



```python
# month í”¼ì²˜ ì¤‘, ì˜í–¥ë ¥ì´ ë†’ì€ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤. 
for sorted_feature in sorted(feature, key = lambda tup : tup[1], reverse = True) : 
    if "month" in sorted_feature[0] : 
        print(sorted_feature)
```

    ('month_2017-03', 0.015072199987817987)
    ('month_2016-05', 0.010929869652907428)
    ('month_2016-09', 0.008264568985790957)
    ('month_2016-04', 0.0075219452690915645)
    ('month_2016-10', 0.0064203349153964685)
    ('month_2016-06', 0.004457627685315901)
    ('month_2016-08', 0.0036835895564042305)
    ('month_2016-07', 0.002683400557755442)
    ('month_2016-03', 0.002244525806963841)
    ('month_2016-02', 0.0010296127298496922)
    

## í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ : ì˜ˆì¸¡ ëª¨ë¸ ê°œì„ í•˜ê¸° 

|í”¼ì²˜|ë¶„ì„ ë‚´ìš©|íŒŒìƒ ê°€ëŠ¥í•œ í”¼ì²˜|
|-|-|-|
|date|ì›” ë‹¨ìœ„ë¡œ ì‚´í´ë³¸ ê²°ê³¼, 2016ë…„ 10ì›”ê³¼ 2017ë…„ 3ì›”ì˜ ë°ì´í„°ê°€ ê°€ì¥ ë§ìŠµë‹ˆë‹¤. ìµœê·¼ì— ê°€ê¹Œìš´ ì›”(Month)ì¼ìˆ˜ë¡ ì˜ˆì¸¡ ëª¨ë¸ì— ì¤‘ìš”í•œ í”¼ì²˜ì…ë‹ˆë‹¤. |ê²Œì‹œê¸€ì˜ ë“±ë¡ ì›”(Month)|
|price|ì „ì²´ íœ´ëŒ€í°ì˜ ê±°ë˜ê°€ì™€ ë‹¬ë¦¬ ê¸°ì¢…ë³„ ê°€ê²©ì˜ ë¶„í¬ëŠ” ì •ê·œ ë¶„í¬ì˜ í˜•íƒœë¥¼ ë ê³  ìˆìŠµë‹ˆë‹¤.|ë™ì¼ ê¸°ì¢… ë‚´ ìƒëŒ€ ê°€ê²©(z-score)|
|factory_price|price í”¼ì²˜ì™€ì˜ ì–‘ì˜ ìƒê´€ ê´€ê³„ê°€ ê´€ì°°ë©ë‹ˆë‹¤. ë˜í•œ ì˜ˆì¸¡ ëª¨ë¸ì˜ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ê²°ê³¼, ê°€ì¥ ì¤‘ìš”í•œ í”¼ì²˜ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.|-|
|phone_model|ì†Œìˆ˜ì˜ ì¸ê¸° ê¸°ì¢…ì´ ë§ì€ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.|íœ´ëŒ€í° ì„¸ë¶€ ê¸°ì¢…, ìš©ëŸ‰ìœ¼ë¡œ ë¶„ë¦¬í•œ 2ê°œì˜ í”¼ì²˜|
|maker|Apple ë¸Œëœë“œê°€ ê°€ì¥ ë§ìœ¼ë©°, ê°€ê²© ì˜ˆì¸¡ì—ì„œë„ Apple ë¸Œëœë“œ ì—¬ë¶€ëŠ” ê°€ì¥ ì¤‘ìš”í•œ í”¼ì²˜ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.|-|
|price_index|ì›”ë³„ ë³€ë™ì´ í¬ì§€ ì•Šìœ¼ë©°, ì´ 4ê°œì˜ ê°’ë§Œì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê°€ê²© ì˜ˆì¸¡ì—ì„œ ê·¸ë‹¤ì§€ ì¤‘ìš”í•œ í”¼ì²˜ëŠ” ì•„ë‹™ë‹ˆë‹¤.|-|

ğŸ” ê¸°ì¡´ í”¼ì²˜ ê°€ê³µí•˜ê¸° : 'create_date' 


```python
# ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. 
df = pd.read_csv('./data/used_mobile_phone.csv')

from datetime import datetime 
import time 

# create_date í”¼ì²˜ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ ê³„ì‚°í•˜ê¸° ìœ„í•´ unixtimeìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. 
def date_to_unixtime(date_str) : 
    timestamp = time.mktime(datetime.strptime(date_str, '%Y-%m-%d').timetuple())
    return timestamp 

# create_date í”¼ì²˜ë¥¼ 'í˜„ì¬ì™€ ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ ë°ì´í„°ì¸ì§€' íŒë‹¨í•˜ê¸° ìœ„í•œ ì ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë¨¼ì € unixtimeìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤. 
df['create_unixtime'] = df['create_date'].apply(lambda x : date_to_unixtime(x[:10]))

# ë³€í™˜ëœ unixtimeì— min-max ìŠ¤ì¼€ì¼ë§ì„ ì ìš©í•©ë‹ˆë‹¤. 
df['create_time_score'] = (df['create_unixtime'] - df['create_unixtime'].min()) / (df['create_unixtime'].max() - df['create_unixtime'].min())
df[['create_date', 'create_unixtime', 'create_time_score']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>create_date</th>
      <th>create_unixtime</th>
      <th>create_time_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2017-03-19  4 35 00 PM</td>
      <td>1.489849e+09</td>
      <td>0.985612</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2016-10-26  12 08 00 PM</td>
      <td>1.477408e+09</td>
      <td>0.640288</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2016-10-25  12 52 00 PM</td>
      <td>1.477321e+09</td>
      <td>0.637890</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2017-03-23  11 14 00 PM</td>
      <td>1.490195e+09</td>
      <td>0.995204</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2016-04-11  7 35 00 PM</td>
      <td>1.460300e+09</td>
      <td>0.165468</td>
    </tr>
  </tbody>
</table>
</div>



ğŸ” ê¸°ì¡´ í”¼ì²˜ì˜ ê°€ê³µ : phone_model 


```python
# phone_model í”¼ì²˜ì—ì„œ ì €ì¥ ìš©ëŸ‰(phone_model_storage) í”¼ì²˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. 
df['phone_model_storage'] = df['phone_model'].apply(lambda x : x.split(" ")[-1])

# phone_model í”¼ì²˜ì—ì„œ ê¸°ì¢… ì„¸ë¶€ëª…(phone_model_detail) í”¼ì²˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. 
df['phone_model_detail'] = df['phone_model'].apply(lambda x : ' '.join(x.split(" ")[:-1]))
df[['phone_model_storage', 'phone_model_detail']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phone_model_storage</th>
      <th>phone_model_detail</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>64gb</td>
      <td>iphone 6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>32gb</td>
      <td>galaxy s6 edge</td>
    </tr>
    <tr>
      <th>2</th>
      <td>32gb</td>
      <td>galaxy s6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>32gb</td>
      <td>lg g5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32gb</td>
      <td>lg u</td>
    </tr>
  </tbody>
</table>
</div>




```python
# phone_model í”¼ì²˜ì˜ ê¸°ì¢…ë³„ ê±°ë˜ ë°ì´í„° ê°œìˆ˜ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤. 
model_counts = df['phone_model'].value_counts()

# phone_model_detail í”¼ì²˜ì˜ ê¸°ì¢…ë³„ ê±°ë˜ ë°ì´í„° ê°œìˆ˜ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤. 
model_detail_counts = df['phone_model_detail'].value_counts()
data = [model_counts, model_detail_counts] 

# ë‘ í”¼ì²˜ ê°„ì˜ ê¸°ì¢…ë³„ ê±°ë˜ ë°ì´í„° ê°œìˆ˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. 
mpl_fig = plt.figure()
ax = mpl_fig.add_subplot(111)
ax.boxplot(data)
plt.show()
```


    
![png](/assets/images/Book/8/output_23_0.png)
    


ğŸ” ê°ì„± ë¶„ë¥˜ë¡œ ë¬¼í’ˆì˜ ìƒíƒœ ë¶„ë¥˜í•˜ê¸° 


```python
# ê±°ë˜ ê°€ê²©(price)ì˜ z-scoreë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ëŠ” í•´ë‹¹ ë°ì´í„°ì˜ ê°€ê²©ì´ ê¸°ì¢…ì˜ í‰ê· ì— ë¹„í•´ ì–´ëŠ ì •ë„ë¡œ ë†’ê±°ë‚˜ ë‚®ì€ì§€ë¥´ ì•Œ ìˆ˜ ìˆê²Œ í•˜ëŠ” ì ìˆ˜ì…ë‹ˆë‹¤. 
df['price_by_group'] = df.groupby('phone_model_detail')['price'].transform(lambda x : (x - x.mean()) / x.std())

#ê±°ë˜ ê°€ê²©ì˜ z-score(price_by_group)ì˜ ë¶„í¬ë¥¼ ê·¸ë˜í”„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. 
ax = df['price_by_group'].hist(bins = "auto")

# z-score(price_by_group) ê¸°ì¤€ìœ¼ë¡œ í•˜ìœ„ 5%, ìƒìœ„ 5%ì— í•´ë‹¹í•˜ëŠ” ì ìˆ˜ë¥¼ lower_bound, upper_boundë¼ê³  ì§€ì •í•©ë‹ˆë‹¤. 
lower_bound = df['price_by_group'].quantile(0.05)
upper_bound = df['price_by_group'].quantile(0.95)

# lower_bound, upper_bound ê·¸ë˜í”„ì— ì¶”ê°€í•©ã„´ë””ã…. 
ax.axvline(x = lower_bound, color = 'r', linestyle = 'dashed', linewidth = 2)
ax.axvline(x = upper_bound, color = 'r', linestyle = 'dashed', linewidth = 2)

# lower_bound, upper_bound ì¶œë ¥í•©ë‹ˆë‹¤. 
print(lower_bound)
print(upper_bound)
```

    -1.3966616903783375
    1.666982156397844
    


    
![png](/assets/images/Book/8/output_25_1.png)
    



```python
# lower_bundeë³´ë‹¤ ë‚®ìœ¼ë©´ 0, upper_boundë³´ë‹¤ ë†’ìœ¼ë©´ 2, ê·¸ ì¤‘ê°„ì´ë©´ 1ë¡œ ê°€ê²©ì˜ ìƒíƒœë¥¼ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. 
def get_price_level(price, lower, upper) : 
    if price <= lower : 
        return "0"
    elif price >= upper : 
        return "2"
    else :
        return "1"

# lower_boundë³´ë‹¤ ë‚®ìœ¼ë©´ 0, upper_boundë³´ë‹¤ ë†’ìœ¼ë©´ 2, ê·¸ ì¤‘ê°„ì´ë©´ 1ë¡œ ê°€ê²©ì˜ ìƒíƒœë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤. 
df['price_lower'] = df.groupby('phone_model_detail')['price'].transform(lambda x : x.quantile(0.05))
df['price_upper'] = df.groupby('phone_model_detail')['price'].transform(lambda x : x.quantile(0.95))
df['price_level'] = df.apply(lambda row : get_price_level(row['price'], row['price_lower'], row['price_upper']), axis = 1) 
df[['price', 'price_lower', 'price_upper', 'price_level', 'text']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>price_lower</th>
      <th>price_upper</th>
      <th>price_level</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>550000.0</td>
      <td>180000.0</td>
      <td>680000.0</td>
      <td>1</td>
      <td>ì•„ì´í°6í”ŒëŸ¬ìŠ¤ ë¸”ë™+ì• í”Œë¼ì´íŠ¸ 64ê¸°ê°€ íŒë‹ˆë‹¤  ì•„ì´í°6í”ŒëŸ¬ìŠ¤ ë¸”ë™+ì• í”Œë¼ì´íŠ¸ 64...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>380000.0</td>
      <td>180000.0</td>
      <td>414000.0</td>
      <td>1</td>
      <td>ê°¤ëŸ­ì‹œs6ì—£ì§€ 32ê¸°ê°€ íŒë‹ˆë‹¤ ì§ê±°ë˜  ê°¤ëŸ­ì‹œs6ì—£ì§€ 32ê¸°ê°€ í’ˆëª… ê°¤ëŸ­ì‹œs6ì—£ì§€ì œ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>300000.0</td>
      <td>150000.0</td>
      <td>349000.0</td>
      <td>1</td>
      <td>ê°¤ëŸ­ì‹œs6 í’€ë°•ìŠ¤ë¡œ íŒë‹ˆë‹¤~~~ ìƒˆìƒí’ˆê¸‰  ì‹¤ê¸°ìŠ¤ì¡°ì°¨ ì—†ì–´ìš”  ì§ì ‘ê±°ë˜ êµ¬ë§¤í•œì§€ 1...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>290000.0</td>
      <td>100000.0</td>
      <td>500000.0</td>
      <td>1</td>
      <td>sk  g5 í‹°íƒ„ í° ë‹¨í’ˆíŒë§¤í•©ë‹ˆë‹¤  ì§ì ‘ê±°ë˜ sk g5 í‹°íƒ„ í° ë‹¨í’ˆíŒë§¤í•©ë‹ˆë‹¤ ì˜¬...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>280000.0</td>
      <td>18000.0</td>
      <td>400000.0</td>
      <td>1</td>
      <td>sony ì—‘ìŠ¤í˜ë¦¬ì•„ c5 ultra e5506 16gb  ë¯¸ì‚¬ìš© ìƒˆì œí’ˆ íŒë‹ˆë‹¤ 1...</td>
    </tr>
  </tbody>
</table>
</div>



ğŸ” í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬í•˜ê¸° 


```python
import pickle 
import re 

# ì¤‘ê³ ë‚˜ë¼ ë¶ˆìš©ì–´ ì‚¬ì „ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. 
with open('./data/used_mobile_phone_stopwords.pkl', 'rb') as f : 
    stopwords = pickle.load(f)

# ë¶ˆìš©ì–´ ì‚¬ì „ì— ë“±ë¡ëœ ë‹¨ì–´ 10ê°œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. 
print(stopwords[:10])
```

    ['ê±°ë˜', 'ì…ë‹ˆ', 'íŒë§¤', 'ì•„ì´í°', 'ê°¤ëŸ­ì‹œ', 'ê³¨ë“œ', 'íŒ', 'ë§Œì›', 'í°', 'ì‹œ']
    

ğŸ” í˜•íƒœì†Œ ë‹¨ìœ„ë¡œ ì¶”ì¶œí•˜ê¸°


```python
from konlpy.tag import Okt 

# '+'ë¥¼ ì œì™¸í•œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê³ í•˜ê³ , ìˆ«ìí˜•íƒœì˜ ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤. 
def text_cleaning(text) : 
    text = ''.join(c for c in text if c.isalnum() or c in '+, ')
    text = ''.join([i for i in text if not i.isdigit()])
    return text 

# ë¶ˆìš©ì–´ì— ë“±ì¥í•˜ì§€ ì•ŠëŠ” í˜•íƒœì†Œë§Œì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. 
def get_pos(x) : 
    tagger = Okt()
    poses = tagger.pos(x)
    return [pos[0] for pos in poses if pos[0] not in stopwords]

# ìœ„ í•¨ìˆ˜ë“¤ì„ ì ìš©í•œ í˜•íƒœì†Œ ì¶”ì¶œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. 
df['text'] = df['text'].apply(lambda x : text_cleaning(x))
result = get_pos(df['text'][0])
print(result)
```

    ['+', 'ì• í”Œ', 'ë¼ì´íŠ¸', 'íŒë‹ˆë‹¤', '+', 'ì• í”Œ', 'ë¼ì´íŠ¸', 'íŒë‹ˆë‹¤', '+', 'ì• í”Œ', 'ë¼ì´íŠ¸', 'íŒë‹ˆë‹¤', 'ë¦¬í¼', 'ê¸°ê°„', 'ë§Œë£Œ', 'ë˜ì–´ì„œ', 'ì§•', 'í•˜ê²Œ', 'ë˜ì—ˆìŠµë‹ˆë‹¤', 'ìƒíƒœ', 'ì´ˆ', 'a', 'ê¸‰', 'ìŠ¤', 'ì—†ìŠµë‹ˆë‹¤', '+', 'ì• í”Œ', 'ë¼ì´íŠ¸', 'íŒë‹ˆë‹¤', '+', 'ì• í”Œ', 'ë¼ì´íŠ¸', 'íŒë‹ˆë‹¤', 'ë¦¬í¼', 'ê¸°ê°„', 'ë§Œë£Œ', 'ë˜ì–´ì„œ', 'ì§•', 'í•˜ê²Œ', 'ë˜ì—ˆìŠµë‹ˆë‹¤', 'ìƒíƒœ', 'ì´ˆ', 'a', 'ê¸‰', 'ìŠ¤', 'ì—†ìŠµë‹ˆë‹¤', 'ì§•', 'ì• í”Œ', 'ë¼ì´íŠ¸', 'í™ˆ', 'ë²„íŠ¼', 'ë§', 'ì¹´ë©”ë¼', 'ë§', 'ë³¼ë¥¨', 'ë²„íŠ¼', 'ìŠ¬ë¦½', 'ë²„íŠ¼', 'ê²€ê¸ˆ', 'ì‹¬í”Œ', 'íŠ€ì§€', 'ì•Šê²Œ', 'ì´ì˜ê²Œ', 'í–ˆêµ¬ìš”', 'ìœ ì‹¬', 'ê½‚ê³ ', 'ë°”ë¡œ', 'ì‚¬ìš©', 'í•˜ì‹œë©´', 'ë©ë‹ˆë‹¤', 'ì‚¬ëŒ', 'ì´ëƒ', 'ìì£¼', 'ë¬¼ì–´ë³´ê³ ', 'ì‹¤ì œ', 'ë”ìš±', 'ì´ì©ë‹ˆë‹¤', 'ë°¤', 'ì˜ë¡±í•˜ê²Œ', 'ë§¥ë¶', 'ë’·', 'ì‚¬ê³¼', 'ë¡œê³ ', 'ë¹„ì¶°ì§€ê³ ', 'ìš”ì „', 'ë„˜ì–´ê°€ê¸°', 'ìœ„í•´', 'í•©ë‹ˆë‹¤', 'ê°€ëŠ¥í•©ë‹ˆë‹¤', 'ë°•ìŠ¤', 'ì–´ë¨¸ë‹ˆ', 'ë²„ë¦¬ì‹œê³ ', 'ì´ì–´í°', 'ì¶©ì „ê¸°', 'ì •í’ˆ', 'ë“œë¦½ë‹ˆë‹¤', 'ì§ê±°ë˜', 'ìš°ì„ ', 'ìˆœ', 'ìœ„ë¡œ', 'ì •', 'ì‹¶ìœ¼ì‹œë©´', 'ì„ ', 'ì…ê¸ˆ', 'íƒë°°', 'ë°œì†¡', 'í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤', 'ë¯¿ìœ¼ì‹œë©´', 'ì§ê±°ë˜', 'í•˜ì‹œê¸¸', 'ì¶”ì²œ', 'í•´ìš”', 'ì•ˆì „', 'í•©ë‹ˆë‹¤', 'ì„œìš¸ì‹œ', 'ê°•ë‚¨êµ¬', 'ì—­ì‚¼ë™', 'ì°¨ë³‘ì›', 'ì‚¬ê±°ë¦¬', 'ê·¼ì²˜', 'ê°€ê²©']
    

ğŸ” ë¹ˆì¶œ í˜•íƒœì†Œ 2,500ê°œ ì„ ì •í•˜ê¸° 


```python
from collections import Counter 

# get_pos() í•¨ìˆ˜ë¥¼ ëª¨ë“  í…ìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•˜ì—¬ í˜•íƒœì†Œ ë§ë­‰ì¹˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. 
corpus = sum(df['text'].apply(lambda x : get_pos(x)).tolist(), []) 

# ì¶”ì¶œëœí˜•íƒœì†Œ ë§ë­‰ì¹˜ì—ì„œ ê°€ì¥ ë§ì´ ë“±ì¥í•œ í˜•íƒœì†Œ 2500ê°œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. 
counter = Counter(corpus)
common_words = [key for key, _ in counter.most_common(2500)]
common_words
```




    ['ì…ë‹ˆë‹¤',
     'ì§ê±°ë˜',
     's',
     'í•©ë‹ˆë‹¤',
     'íƒë°°',
     'ì‚¬ìš©',
     'ê¸‰',
     'ìƒíƒœ',
     'íŒë‹ˆë‹¤',
     'ê°€ëŠ¥í•©ë‹ˆë‹¤',
     'ì •ìƒ',
     'ì‚¬ì§„',
     'ê°€ê²©',
     '+',
     'ì¼€ì´ìŠ¤',
     'a',
     'ì£¼ì„¸ìš”',
     'í•´ì§€',
     'ì‚­ì œ',
     'ì œí’ˆ',
     'ìˆìŠµë‹ˆë‹¤',
     'ë°•ìŠ¤',
     'ê°€ëŠ¥',
     'ì§ì ‘',
     'ì•¡ì •',
     'ë°°í„°ë¦¬',
     'ì„±í’ˆ',
     'í•„ë¦„',
     'ë¦¬í¼',
     'ì¶©ì „ê¸°',
     'ì—†ìŠµë‹ˆë‹¤',
     'í’€',
     'ê°œí†µ',
     'ìœ ì‹¬',
     'ì¦ˆ',
     'ì•ˆì „',
     'ìŠ¤',
     'í•˜ê¸°',
     'ì‹ ì²­',
     'ë“œë¦½ë‹ˆë‹¤',
     'í†µì‹ ì‚¬',
     'êµ¬ì…',
     'ì•½ì •',
     'ì´ì–´í°',
     'ê³µê¸°',
     'ìƒˆ',
     'ê¸°ë³€',
     'í¬í•¨',
     'ëª¨ë¸',
     'ì„ íƒ',
     'ë©ë‹ˆë‹¤',
     'í™•ì¸',
     'ê¸°ê°„',
     'ê¸°ìŠ¤',
     'ê·¸ë ˆì´',
     'ì°í˜',
     'ë°©ë²•',
     'ë°”ë¡œ',
     'í• ì¸',
     'ì œ',
     'ì‹œê¸°',
     'ìŠ¤í˜ì´ìŠ¤',
     'í¬ë§',
     'ë²ˆí˜¸',
     'ì¤‘ê³ ë‚˜ë¼',
     'ë³¸ì²´',
     'ê°™ì´',
     'ìƒí™œ',
     'ì˜',
     'ë¬´',
     'í€µ',
     'ê¸€',
     'ëœ',
     'ì•Šì„',
     'ê³µì‹',
     'ì•±',
     'í™•ì •',
     'ê¸°ëŠ¥',
     'ë‹¤ìš´',
     'ì–‘',
     'í˜¸í™˜',
     'ì¼€ì´ë¸”',
     'ë°›ê¸°',
     'ë¯¸',
     'ì´ë©”ì¼',
     'ì‘ì„±',
     'ë¶€ë¶„',
     'ê¸ˆì§€',
     'ë ìˆ˜',
     'ì‹ì•„ì´ë””',
     'í—ˆìœ„',
     'ì„ì˜',
     'í†µë³´',
     'ì±„ìš°ì§€',
     'í•¸ë“œí°',
     'í¸í•œ',
     'ì „í˜€',
     'ì¶©ì „',
     'ë‚´ìš©',
     'ì—°ë½ì²˜',
     'ë‹¨ë§ê¸°',
     'ë¶€ì‚°',
     'ëŒ€êµ¬',
     'ë¯¸ì‚¬',
     'ì •í’ˆ',
     'ì¤‘ê³ ',
     'ë¬¸ì œ',
     'ì—†ì´',
     'ì´ìƒ',
     'ë³´í˜¸',
     'ë°©ë¬¸',
     'ì—†ëŠ”',
     'ì™¸ê´€',
     'ì™¸',
     'ì¸ì²œ',
     'ê¹¨ë—í•©ë‹ˆë‹¤',
     'x',
     'ì´ˆê¸°',
     'í•˜ë‚˜',
     'ì°¸ê³ ',
     'ì´êµ¬',
     'ìš”ê¸ˆ',
     'ê°œì›”',
     'ì´ë‚˜',
     'ì‚¬ì´íŠ¸',
     'íŒ”ì•„ìš”',
     'í•˜ì‹œë©´',
     'í–ˆìŠµë‹ˆë‹¤',
     'ë™',
     'ì¹´í˜',
     'ë³´ë‚´',
     'ì¹´í†¡',
     'ë¸”ë¡œê·¸',
     'ë§í¬',
     'ì‹¸ì´',
     'ê°•í‡´',
     'ì‚¼ì„±',
     'ê±°ì¹˜',
     'ìˆëŠ”',
     'í˜¸ì„ ',
     'ëª¨ë“ ',
     'ì…ê¸ˆ',
     'ì²˜ë¦¬',
     'ì—†ìŒ',
     'ë’·',
     'í•‘í¬',
     'ì¹´ë©”ë¼',
     'ê±°ì£¼ì§€',
     'ê³µ',
     'í•˜ì—¬',
     'ì—­ë„',
     'ì¬íŒë§¤',
     'ìœ ë„',
     'ì„ ',
     'êµì²´',
     'ê°•í™”ìœ ë¦¬',
     'ê²½ë§¤',
     'ë§Œë§Œ',
     'ë¶€íƒë“œë¦½ë‹ˆë‹¤',
     'êµ¬ì„±',
     'í•„ìˆ˜',
     'ì°¨ëŒ€',
     'ì¬ì‹œ',
     'ì—†ê³ ',
     'ì „ì²´',
     'íŒŒì†',
     'ë‹¤ë¥¸',
     'ê°€ëŠ¥í•˜ë©°',
     'ì‘ë™',
     'ê°€ëŠ¥í•œ',
     'êµí™˜',
     'ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
     'ì¢‹ìŠµë‹ˆë‹¤',
     'ê¸°ê³„',
     'ìƒê°',
     'ê·¸ëŒ€ë¡œ',
     'ì¶”ê°€',
     'ì•½ê°„',
     'ì‚´ì§',
     'ë°”ëë‹ˆë‹¤',
     'í…Œë‘ë¦¬',
     'í’€ë°•',
     'ë¯¸ê°œ',
     'ê±°ì˜',
     'ë¶€ë‹´',
     'ìª½',
     'ì¡°ê¸ˆ',
     'ë¹„',
     'ì£¼ì‹œ',
     'as',
     'í•˜ì§€',
     'ì‹¸ê²Œ',
     'ë•Œ',
     'í•˜ê² ìŠµë‹ˆë‹¤',
     'ë´‰',
     'ì™„ì „',
     'ìƒí’ˆ',
     'ëŒ“ê¸€',
     'ì°©ë¶ˆ',
     'ë¶€ì°©',
     'ë•Œë¬¸',
     'ê¸ˆì•¡',
     'ì•„ì£¼',
     'í´ë”',
     'ì›í•˜ì‹œë©´',
     'ì™€ì¸',
     'í• ',
     'í•˜ë©°',
     'ìˆ˜',
     'í•˜ë‹¨',
     'í˜„ì¬',
     'ê±°ì£¼',
     'í•œë²ˆ',
     'ë²„íŠ¼',
     'ë”',
     'ê°€ëŠ¥í•˜ê³ ',
     'ì •ë§',
     'ìˆê³ ',
     'ì—˜ì§€',
     'ì»¤ë²„',
     'ë¸”ë£¨',
     'ë²ˆ',
     'ì›í•©ë‹ˆë‹¤',
     'ê¸°ë³¸',
     'í•´ì£¼ì„¸ìš”',
     'í„°ì¹˜',
     'ê·¸ëƒ¥',
     'í•˜ëŠ”',
     'ìš©ê°',
     'ì‹œê°„',
     'ì „ë¶€',
     'ëŒ€ì „',
     'ë˜ì–´',
     'í†µí™”',
     'ì„¼í„°',
     'ìˆêµ¬ìš”',
     'ì¿¨',
     'ê¹¨ë—í•œ',
     'ì•',
     'ìƒˆê±°',
     'ë¯¸êµ­',
     'ê°™ìŠµë‹ˆë‹¤',
     'ê´‘ì£¼',
     'ê·¼ì²˜',
     'ì—†êµ¬ìš”',
     'í•˜ì‹¤',
     'ì°©',
     'ë°©ì‹',
     'í™˜ë¶ˆ',
     'ì• í”Œ',
     'ì•„ë˜',
     'ì„œë¹„ìŠ¤',
     'ì ¤ë¦¬',
     'ìœ ë¦¬',
     'ê°€ëŠ¥í•˜êµ¬ìš”',
     'ì„ í˜¸',
     'ì•ŠìŠµë‹ˆë‹¤',
     'ìˆ˜ì›',
     'ëª¨ì„œë¦¬',
     'ê³³',
     'ë‹¬',
     'í•˜ì„¸ìš”',
     'ìŠ¤ë§ˆíŠ¸í°',
     'í™”ë©´',
     'ê²½ê¸°ë„',
     'ì‹ í’ˆ',
     'ê°•í™”',
     'ì œíŠ¸',
     'ë“œë ¤ìš”',
     'íŠ¹',
     'ë¶€í’ˆ',
     'ë°œì†¡',
     'ë…„ì›”',
     'ìƒë‹¨',
     'ìœ í”ŒëŸ¬ìŠ¤',
     'ìƒˆê²ƒ',
     'ì´í›„',
     'í’€ì…‹',
     'ì¢‹ì€',
     'ì‚¬ì–‘',
     'í™',
     'ì—­',
     'ê°œë´‰',
     'í…ŒìŠ¤íŠ¸',
     'ìˆ˜ë¦¬',
     'ìˆì–´ìš”',
     'ì•„ë¬´',
     'íˆ¬ëª…',
     'ì”ê¸°ìŠ¤',
     'í ì§‘',
     'ë¯¸ë…¸íŠ¸',
     'ë¶„ì‹¤',
     'ì²œì•ˆ',
     'ë°›ì€',
     'ë‚˜ë¨¸ì§€',
     'ì ',
     'í•˜ì',
     'í•˜ì‹œê³ ',
     'ì €ë ´í•˜ê²Œ',
     'ì•Šì€',
     'ì‹ ë¶„',
     'ìœ ',
     'ìš©ëŸ‰',
     'í•˜ì‹œëŠ”',
     'ì „ë©´',
     'ì–¸ë½í°',
     'ì–‘í˜¸',
     'ê¸ˆ',
     'í•˜ì˜€ìŠµë‹ˆë‹¤',
     'ë³´ì‹œë‹¤ì‹œí”¼',
     'ë³„ë„',
     'í•˜êµ¬ìš”',
     'ë°©íƒ„',
     'ìŠ¤ê·¸',
     'ì—¬ë¶„',
     'ë³¸',
     'í•˜ì…”ë„',
     'ë¬´ìƒ',
     'ë”°ë¡œ',
     'ì„¸ì´í”„',
     'ì¢€',
     'ì™€ì´íŒŒì´',
     'ë¬´ì„ ',
     'ì œì™¸',
     'ì¢…',
     'ë˜ì—ˆìŠµë‹ˆë‹¤',
     'ì²œì›',
     'í”„ë¡œ',
     'ëˆŒ',
     'ë§¤íŠ¸',
     'ë°°ì†¡',
     'ì•½',
     'ì ˆì¶©',
     'í–ˆêµ¬ìš”',
     'ìš°ì„ ',
     'ëŒ€ë¦¬ì ',
     'ì¸í„°ë„·',
     'ì—†ìœ¼ë©°',
     'ìˆ˜ìˆ˜ë£Œ',
     'ë‹¤ì‹œ',
     'ì´ˆ',
     'ë¼',
     'í‰ì¼',
     'ì‚½ë‹ˆë‹¤',
     'ê³ ì¥',
     'ì´ë²ˆ',
     'ë¶€ê·¼',
     'ê²ë‹ˆë‹¤',
     'ì•„ë‹˜',
     'ë§¤ì¥',
     'í•´ë“œë¦½ë‹ˆë‹¤',
     'ë³´ì¡°',
     'í•˜ë˜',
     'ì¸ì‹',
     'ë¶ˆëŸ‰',
     'í¬ì¥',
     'ë¶€ì²œ',
     'ê±¸',
     'êµ°ë°',
     'ë² ê°€',
     'ì–¸ì œ',
     'ì›”ì¼',
     'ì²¨ë¶€',
     'ì „ì£¼',
     'í•­ìƒ',
     'ê°¤',
     'ì²˜ë¶„',
     'ë¶ˆê°€',
     'ë¹„ëŠ”',
     'ë§¤ìš°',
     'ë‚¨ìŒ',
     'ì—†ì–´ìš”',
     'ì°¸ì¡°',
     'êµ­ë‚´',
     'ì–¸',
     'ê°€ì…',
     'ì”',
     'ì§€ë¬¸',
     'ìˆì–´ì„œ',
     'ì¥ì†Œ',
     'ì ˆëŒ€',
     'ë°‘',
     'í•´ì™¸',
     'ë˜ëŠ”',
     'ìš©ì¸',
     'ì ìš©',
     'ì˜¤ì‹œ',
     'ì˜µí‹°ë¨¸ìŠ¤',
     'ìˆìœ¼ë©°',
     'ìœ ë‹ˆí¬ë¡œ',
     'ë¬´ìŒ',
     'ì‹¤ì‚¬',
     'ë¶„ë§Œ',
     'ì¢‹ì•„ìš”',
     'íŒ”',
     'ì•ˆë…•í•˜ì„¸ìš”',
     'í•˜ë©´ì„œ',
     'ë‹µë³€',
     'ì‘ì€',
     'ì  ë”',
     'ê°€ëŠ¥í•´ìš”',
     'ì•„ì§',
     'ë‹¹ì—°íˆ',
     'ë„¥ì„œìŠ¤',
     'ìµœì´ˆ',
     'ë¶ˆì…',
     'ì‚¼',
     'ë² í„°ë¦¬',
     'ë“œë¦´ê²Œìš”',
     'ê°œì¸',
     'ì˜¤ë¥¸ìª½',
     'ì•„ì´ë””',
     'ë°§ë°ë¦¬',
     'ë“œë¦´ê»˜ìš”',
     'ìŠ¤í¬ë˜ì¹˜',
     'ë³´ê´€',
     'ê´€ì‹¬',
     'ìˆì§€ë§Œ',
     'ì„ ë¶ˆ',
     'ë³€ê²½',
     'í°',
     'ë˜ê³ ',
     'íŒ©',
     'ê³µì¥',
     'ê¸‰ì²˜',
     'ê¼­',
     'ì˜ˆì•½',
     'í˜¹ì‹œ',
     'ê°ì‚¬í•©ë‹ˆë‹¤',
     'ì¶œêµ¬',
     'ì´ìš©',
     'ë˜êµ¬ìš”',
     'ì•ˆì‹¬',
     'ë‚´ì¥',
     'íœ',
     'ë¨¼ì €',
     'í–ˆë˜',
     'ë²„ì „',
     'ì•„ë‹™ë‹ˆë‹¤',
     'ë©”ì¸ë³´ë“œ',
     'ì•ˆì‚°',
     'í•œì§€',
     'ì•ˆë©ë‹ˆë‹¤',
     'ì£¼ë§',
     'ì‚¬ì ˆ',
     'ìŠ¤ë§ˆíŠ¸',
     'í•˜ë©´',
     'ìš©ì´',
     'í•œêµ­',
     'ë¬¸',
     'ìµœìƒ',
     'ì˜¤ëŠ˜',
     'ê²”ëŸ­ì‹œ',
     'ë§¥ìŠ¤',
     'í•˜ê²Œ',
     'ë„ˆë¬´',
     'í•„ìš”í•˜ì‹œë©´',
     'ìêµ­',
     'ì¼ë³¸',
     'ë¬¼',
     'í™ˆ',
     'ë³´ê¸°',
     'ì§€ê¸ˆ',
     'ìˆìŒ',
     'nbsp',
     'ìµœëŒ€í•œ',
     'í™ì½©',
     'ì €ë…',
     'ë‹µì¥',
     'ë³´ë‹ˆ',
     'ê°€ì§€',
     'ìˆëŠ”ë°',
     'ê¶ê¸ˆí•˜ì‹ ',
     'ì“°ë˜',
     'ë³´ê³ ',
     'ì™¼ìª½',
     'ê¹¨ë—í•˜ê³ ',
     'íƒí¬',
     'ìª½ì§€',
     'ìˆìœ¼ë©´',
     'ì‘ë…„',
     'ê¸°íƒ€',
     'ë°˜í’ˆ',
     'ë’¤',
     'ë§ì€',
     'ì‚¬í•­',
     'ë§Œë£Œ',
     'ë½',
     'ë¬¸ì˜ì‚¬í•­',
     'ì•„ì´ì–¸',
     'ìì„¸í•œ',
     'ìƒì²˜',
     'ê·¸ëœë“œ',
     'ë²”í¼',
     'ë¶™ì—¬ì„œ',
     'ì§„í–‰',
     'ì²­ì£¼',
     'schw',
     'ì•ŒíŒŒ',
     'ë‚¨ì•„ìˆìŠµë‹ˆë‹¤',
     'ë¶„ë‹¹',
     'ìœ„í•´',
     'ë°°ì†¡ë¹„',
     'ë§',
     'ê¸°ì¤€',
     'ì¹´ë“œ',
     'ë“œë¦¬êµ¬ìš”',
     'ë„¤ì˜¤',
     'ì‚¬ì‹¤',
     'ì„',
     'ë³´ì´ëŠ”',
     'ì˜¤í›„',
     'ì‚¬íŒŒì´ì–´',
     'ìƒˆë¡œ',
     'ì¡°ê±´',
     'ì¹¨ìˆ˜',
     'ì¸ê·¼',
     'í•´ìš”',
     'ìì„¸íˆ',
     'ì²˜ìŒ',
     'ê°•ë‚¨',
     'í™˜ì˜',
     'ì´ì–´íŒŸ',
     'ë¬¼ê±´',
     'ì›í•˜ì‹œëŠ”',
     'ë“±ë¡',
     'ì´ë¯¸ì§€',
     'ì¼ì‚°',
     'ì´ë™',
     'ë˜í•œ',
     'ì§•',
     'ë¹„ë‹',
     'ì°í˜ì´',
     'ì™„ë‚©',
     'ë¬´ë£Œ',
     'ë‹¨ì',
     'ì´ì™¸',
     'ì—°',
     'ê¸ˆì œ',
     'êµ¬ì„±ì€',
     'ì°íŒ',
     'ì˜ì‚¬',
     'ì¤‘í™”ì—­',
     'ìˆìœ¼ë‚˜',
     'í•˜ë‹ˆ',
     'ë¶€',
     'ì˜ì •ë¶€',
     'ìˆìœ¼ë‹ˆ',
     'ì¼ë°˜',
     'ë‚¨ì•˜ìŠµë‹ˆë‹¤',
     'ì¹©',
     'í†¡',
     'ì—‘ìŠ¤í˜ë¦¬ì•„',
     'í›„ì‹œ',
     'ë°›ì§€',
     'ë¶™ì—¬',
     'ë¹ ë¥¸',
     'ë½í°',
     'ê°œí˜¸í™˜',
     'í˜„ìƒ',
     'ëŒ€ê°œ',
     'ì–¼ë§ˆ',
     'ì œê±°',
     'ê°ì•ˆ',
     'í–ˆëŠ”ë°',
     'í•˜ì˜€ê³ ',
     'ì•ˆì „ê±°ë˜ë„',
     'íŒœ',
     'í•˜ë ¤ê³ ',
     'ì˜¬ë¦½ë‹ˆë‹¤',
     'ì˜ˆì •',
     'ìœ ì§€',
     'ëª©í¬',
     'ì›”í¬',
     'ì•Œëœ°í°',
     'ë‘˜ë‹¤',
     'ì„±ë‚¨',
     'ì•…ì„¸ì‚¬ë¦¬',
     'ê³µê³µ',
     'ë¬¼í’ˆ',
     'í¬ê²Œ',
     'ìš¸ì‚°',
     'ì•ˆì–‘',
     'ì‹¬',
     'ê°™ì€',
     'ì§‘',
     'ì–´ëŒ‘í„°',
     'ì•Šì•˜ìŠµë‹ˆë‹¤',
     'iphone',
     'ê²€ìˆ˜',
     'ì •ì¤‘íˆ',
     'ë ˆë“œ',
     'ì „í™”ê¸°',
     'ë¹¼',
     'í™”ì›¨ì´',
     'ê²½ê¸°',
     'ë‚´ë…„',
     'ì´ë ¥',
     'ì—…ë¬´',
     'ìƒ¤ì˜¤ë¯¸',
     'ì§',
     'ìš©ê¸°',
     'ì¼ë‹¨',
     'ë°›ê³ ',
     'ê°',
     'ìˆìœ¼ì‹œë©´',
     'ê´‘ì—­ì‹œ',
     'ì°½ì›',
     'ê²°ê³¼',
     'ê°€ì£½',
     'ì„¤ì •',
     'í•˜ì…”ì„œ',
     'ì–´ë””',
     'ì´ë©´',
     'ì§€í”„ë¡œ',
     'í–ˆê³ ',
     'ê²°ì œ',
     'ë°ì´í„°',
     'ì „ì›',
     'ë¯¸ì„¸í•œ',
     'aa',
     'ê°€ëŠ¥í•˜ë‹ˆ',
     'ìˆìœ¼',
     'ì¨ì„œ',
     'ë°›ìŠµë‹ˆë‹¤',
     'ê¸°ì¡´',
     'ë“±ë“±',
     'ì—†ë„¤ìš”',
     'ë˜ë„ë¡',
     'ë¬´ê¸°',
     'ì‹¤ê¸°',
     'ìë¶€',
     'ì•„ì‹œê² ì§€ë§Œ',
     'ì„¸íŠ¸',
     'ë°˜',
     'ëˆˆ',
     'ìš°ì¸¡',
     'ì–¸ë½',
     'ì˜¬í•´',
     'ë¹¨ë¦¬',
     'ì œì¡°',
     '++',
     'ì£¼ë³€',
     'ì•Šìœ¼ë©°',
     'ë´…ë‹ˆë‹¤',
     'ì§€ì›',
     'í•¨',
     'ìƒê´€ì—†ì´',
     'ì…ë‹ˆë‹¤êµ¬',
     'ì´ìœ ',
     'ê°€ì„œ',
     'ìœ„ì£¼',
     'ì•Šê³ ',
     'ì¶œì‹œ',
     'í™”ì´íŠ¸ê³¨ë“œ',
     'ì˜¤ë‹‰ìŠ¤',
     'í‹°',
     'ë‚´ë¶€',
     'ì“°ì‹¤',
     'ì—†ì–´ì„œ',
     'slte',
     'í˜„ê¸ˆ',
     'ì±™ê²¨',
     'ë§ì”€',
     'ë³´ì¦',
     'ì—ëˆ„ë¦¬',
     'sktg',
     'ì „ìš©',
     'ì‹ ìš©',
     'í—¬ë¡œëª¨ë°”ì¼',
     'í†µì¼',
     'ì‹¤ì œ',
     'ë“œë¦¬ê³ ',
     'ê¹¨ë—í•˜ê²Œ',
     'ìŠ¤í”¼ì»¤',
     'ì´',
     'í°ìƒ‰',
     'ìš°ì²´êµ­íƒë°°',
     'ë³´ë©´',
     'í†µì‹ ',
     'ìŠ¤ì¹´ì´',
     'ì“°ì‹œ',
     'ë°–ì—',
     'ì›ë˜',
     'ì •ë³´',
     'ë¬¼ë¡ ',
     'ë‚ ',
     'ë§ˆì§€ë§‰',
     'ë˜ì–´ìˆìŠµë‹ˆë‹¤',
     'ë°›ì•˜ìŠµë‹ˆë‹¤',
     'ì• í”ŒìŠ¤í† ì–´',
     'ë¯¿ê³ ',
     'í”ì ',
     'ë˜ë©´',
     'í†µ',
     'ë“œë¦¼',
     'ì‹¤ë¦¬ì½˜',
     'ì„ ë¬¼',
     'ìœ„ì¹˜',
     'ì¡°ì •',
     'íšŒì‚¬',
     'plus',
     'ê·¼ë¬´',
     'ë°”',
     'ë‚´ë†“ìŠµë‹ˆë‹¤',
     'ìƒí•´',
     'ë¶™ì´',
     'ìˆì–´',
     'ì§€ì¥',
     'ë˜ì§€',
     'ì…‹',
     'ë¶€í‰',
     'í¸ì…',
     'ê¹€í¬',
     'ì˜ë¬´',
     'ì•ˆì „í•˜ê²Œ',
     'ì¼ì´',
     'ì‹œí¬ë¦¿',
     'ì¹ ',
     'ê±°ë¦¬',
     'ì¸ì¹˜',
     'ì—­ì‹œ',
     'í¥ì •',
     'ì°”ëŸ¬',
     'ë¹¼ê³ ',
     'ìˆœì²œ',
     'c',
     'ë¹„ë°€ë²ˆí˜¸',
     'ì ê¸ˆ',
     'sphw',
     'ë¶€íƒ',
     'cj',
     'ì§',
     'ë˜ë©°',
     'ì„±ëŠ¥',
     'ìµœìƒê¸‰',
     'aaa',
     'ì‚¬ì„œ',
     'í•´ì§€í•œ',
     'ë¨',
     'ì ì‹¤',
     'ìŠ¤í¬ë ˆì¹˜',
     'ê±±ì •',
     'ëŠ¦ì–´ìš”',
     'ë²•ì ',
     'ì°í˜ì€',
     'ìˆœ',
     'ë¶ˆë¡œ',
     'ì—†ì§€ë§Œ',
     'lgsu',
     'ë‹¤ë…€ì„œ',
     'ë„£ì–´',
     'ì“°ê³ ',
     'ì¹´ì¹´ì˜¤',
     'ë°›ì•„ì„œ',
     'ì¼ì£¼ì¼',
     'ì§€í•˜ì² ',
     'ì§êµ¬',
     'ë¬´ì¡°ê±´',
     'í‰íƒ',
     'í˜‘ì˜',
     'ë£¨ë‚˜',
     'ì”ê¸°',
     'ì¢‹êµ¬ìš”',
     'ë',
     'ì£„ì†¡í•©ë‹ˆë‹¤',
     'ë²•',
     'ë¹ ë¥´ê²Œ',
     'í•˜ë‹¤ê°€',
     'ì°ì–´',
     'ì•ˆë‚˜',
     'ë¡œë§Œ',
     'ë¸Œë¼ìš´',
     'ìœ¡',
     'í‹°íƒ€ëŠ„',
     'ì•ˆì „í•œ',
     'ì±…ì„ì§‘ë‹ˆë‹¤',
     'ë˜ì„œ',
     'note',
     'ìƒ‰',
     'í‹°íƒ„',
     'ì—¬ê¸°',
     'ì¼ì²´',
     'ë©”ëª¨ë¦¬',
     'ì¸¡ë©´',
     'ì˜†',
     'ë“œë¦´ìˆ˜',
     'ì˜¤ì…”ì„œ',
     'ì™¸ë¶€',
     'gold',
     'ë¹¼ê³ ëŠ”',
     'ìš°ì²´êµ­',
     'ê¹¨ì§',
     'ê³ ê°',
     'ì¢‹ìŒ',
     'íŠ¹ì„±',
     'ê¸°ë‹¨',
     'lt',
     'dmb',
     'lglu',
     'ì¢‹ê² ìŠµë‹ˆë‹¤',
     'ê³„ì†',
     'ìœ„ìª½',
     'ì•Œ',
     'í•˜ëŠ”ë°',
     'ê¹¨ë—ì´',
     'í•˜ë£¨',
     'ë“œë¦´',
     'ë¡¬',
     'ì• ì§€ì¤‘ì§€',
     'ì •',
     'ì„œìš¸ì‹œ',
     'í¸ì´',
     'ê´€ê³„',
     'ì‹ ê·œ',
     'ë…„ë„',
     'í•˜ì˜€ìœ¼ë©°',
     'ì—…',
     'ì–´í”Œ',
     'ì§€ë‚œ',
     'ì“´',
     'ë°©ìˆ˜',
     'ì¡°íšŒ',
     'ê´€',
     'í•˜ì…”ì•¼',
     'ì‹œì˜¤',
     'ìŠˆí”¼ê²',
     'ì•ë’¤',
     'ì¶”ì²œ',
     'lgsh',
     'ì„œêµ¬',
     'ìƒê´€ì—†ìŠµë‹ˆë‹¤',
     'ê°€ëŠ¥í•˜ì‹­ë‹ˆë‹¤',
     'm',
     'ìš¸',
     'ë³„ë¡œ',
     'ì´ìƒë¬´',
     'ê³ ì†',
     'ë§ˆì‹œê³ ',
     'ë“±ê¸‰',
     'ì €ì´‰',
     'ì´ê¸°',
     'ëìŠµë‹ˆë‹¤',
     'smnk',
     'ëë‚¬ìŠµë‹ˆë‹¤',
     'ì·¨ê¸‰',
     'ìš”ì²­',
     'ë™ë´‰',
     'íŒ¬íƒ',
     'ìˆ˜ì¤€',
     'ë§¨',
     'ê¹¨ë—í•¨',
     'ì„¸ìš©',
     'ë™ëŒ€ë¬¸êµ¬',
     'ê¹¨ì§„',
     'ë³´ì…ë‹ˆë‹¤',
     'ê°•ë™',
     'ì‚¬ì„¤',
     'ê³„ì–‘êµ¬',
     'ì—…ì',
     'í€„ì»´',
     'ë°”ê¾¸ê²Œ',
     'ë³¸ì¸',
     'í‚¤',
     'ë˜ìˆìŠµë‹ˆë‹¤',
     'ì´ë‚´',
     'ì§„ë™',
     'ê°™ì€ê±°',
     'ì‚¬ì€',
     'ì•Šì•„',
     'ìŠ¤í‹°ì»¤',
     'ê¹”ë”í•œ',
     'ë½ë½',
     'ì†¡íŒŒ',
     'ì—¬ë¶€',
     'í™ëŒ€',
     'ë¡¤ë¦¬íŒ',
     'í•€',
     'im',
     'ê¹¨ë—',
     'ë¸”ë£¨íˆ¬ìŠ¤',
     'ì”Œìš°ê³ ',
     'ê¹”ë”í•©ë‹ˆë‹¤',
     'ë¼ì¸',
     'í–ˆì–´ìš”',
     'ë‚¨ì•„',
     'ì“°ì…”ë„',
     'í• ë¶€',
     'ê°’',
     'ë¼ì´íŠ¸ë‹',
     'í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤',
     'ë³´ì´ì§€',
     'ë‚¨ê²¨ì£¼ì„¸ìš”',
     'í•˜ë‹¤',
     'ìƒ¤ë² íŠ¸',
     'p',
     'ê²€ìƒ‰',
     'ë¼ì›Œì„œ',
     'ì¸í•˜',
     'ë‚¨ì€',
     'ë°›ì„',
     'ê´€ë ¨',
     'ë“œë¦¬ê³ ìš”',
     'ê²½ì‚°',
     'ë¼ìš°ë©´',
     'ì‚¬ê¸°',
     'ì˜',
     'ê´‘ì–‘',
     'í€µì„œë¹„ìŠ¤',
     'ì‚¬ëŒ',
     'ë„£ì–´ì„œ',
     'ì•„ë‹ˆë‹ˆ',
     'ë§ˆì„¸ìš”',
     'ìƒì˜',
     'ì§œë¦¬',
     'í˜„',
     'ë‚®',
     'ê¹¨ë—í•´ìš”',
     'ì—¬ëŸ¬',
     'ì­',
     'í ',
     'ë¨',
     'ëë‚œ',
     'ì„¤ì¹˜',
     'ìˆëŠ”ê±°',
     'ê°€ì¥',
     'ì§„ì§œ',
     'ê´‘ëŒ€ì—­',
     'ì—†ë‹¤ê³ ',
     'ì°í˜ì´ë‚˜',
     'ì›í•˜êµ¬ìš”',
     'ok',
     'lgkh',
     'ìê¸‰',
     'ì•„ì´',
     'ê²½ë‚¨',
     'ì˜¤ì „',
     'ë¶€íƒë“œë ¤ìš”',
     'ì¼ê´„',
     'ê°€ì…”ì„œ',
     'ì˜¬ë ¤',
     'í•˜ì‹œê¸°',
     'ëŒ€ì‹ ',
     'ì´¬ì˜',
     'ì „ë¶',
     'ë°”ê¾¸ë©´ì„œ',
     'ì €ì¥',
     'í•œê¸€',
     'ì‹œì„¸',
     'ìƒì',
     'ì—¬ìˆ˜',
     'ì¹ ì´ì‚¬ì´',
     'ë‹µí„°',
     'ì°©ìš©',
     'ì´ì „',
     'ë©€ì©¡í•©ë‹ˆë‹¤',
     'ì—°ê²°',
     'í•´ë³´ë‹ˆ',
     'ìµœì €',
     'ë‹¹ì¼',
     'í¸ì˜ì ',
     'shves',
     'ì¨',
     'íšŒ',
     'ì•Œë¦¬',
     'ë“œë¦¬ë©°',
     'ì—†ê³ ìš”',
     'íŒŒëŠ”',
     'ìˆë„¤ìš”',
     'ì•„ì˜ˆ',
     'ì¤‘ë‘êµ¬',
     'ì¼ì',
     'ìˆê³ ìš”',
     'ì›”ë§',
     'ì“°ë‹¤ê°€',
     'ì—¬ì„œ',
     'ì™€ê°™ì´',
     'ë°›ì•„',
     'ì†Œë‹ˆ',
     'ìŠ¤íƒ€ì¼',
     'íœ˜',
     'ê¸',
     'ë˜ì—ˆê³ ',
     'ìš”êµ¬',
     'ê°€êµ¬',
     'ë­',
     'ê°•ë™êµ¬',
     'ì‹¤ë¬¼',
     'ë„£ê³ ',
     'ë¶™ì–´ìˆëŠ”',
     'ë˜ìš”',
     'ê°€ëŠ¥í•˜ê³ ìš”',
     'ì •ì‹',
     'ê°•ë‚¨ì—­',
     'ëˆŒëŸ¬ì„œ',
     'ì ê²€',
     'ì¼ëŒ€',
     'ë³´í—˜',
     'ë°¤',
     'ë‘˜',
     ...]



ğŸ” TF-IDF ë²¡í„° ìƒì„±í•˜ê¸° 


```python
from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.feature_extraction.text import TfidfTransformer
from konlpy.tag import Okt

# ë¹ˆì¶œ í˜•íƒœì†Œë¥¼ ì œì™¸í•œ ëª¨ë“  í˜•íƒœì†Œë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. 
tagger = Okt()

def custom_analyzer(text):
    poses = tagger.pos(text)
    return [pos[0] for pos in poses if pos[0] in common_words]

# 1:3:1 ë¹„ìœ¨ë¡œ ëœë¤ ìƒ˜í”Œë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 
negative_random = df[df['price_level'] == '0'].sample(321, random_state = 30)
neutral_random = df[df['price_level'] == '1'].sample(321 * 3, random_state = 30) 
positive_random = df[df['price_level'] == '2'].sample(321, random_state = 30) 

# ìƒ˜í”Œë§ ì™„ë£Œëœ ë°ì´í„°ì…‹ì„ ì •ì˜í•©ë‹ˆë‹¤. 
df_sample = pd.concat([negative_random, neutral_random, positive_random], ignore_index=True)

# TF-IDFë¥¼ ìˆ˜í–‰í•˜ì—¬ í”¼ì²˜ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤. 
index_vectorizer = CountVectorizer(analyzer = custom_analyzer)
X = index_vectorizer.fit_transform(df_sample['text'].tolist())
tfidf_vectorizer = TfidfTransformer()
X = tfidf_vectorizer.fit_transform(X)

# ê°ì„± ë¶„ë¥˜ë¥¼ ìœ„í•œ í•™ìŠµ ë°ì´í„°ì…‹ì„ ì •ì˜í•©ë‹ˆë‹¤. 
y = df_sample['price_level']
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 30)
print(x_train.shape)
print(x_test.shape)
```


    ---------------------------------------------------------------------------

    KeyError                                  Traceback (most recent call last)

    File C:\python_basic\python3.9\lib\site-packages\pandas\core\indexes\base.py:3805, in Index.get_loc(self, key)
       3804 try:
    -> 3805     return self._engine.get_loc(casted_key)
       3806 except KeyError as err:
    

    File index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()
    

    File index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()
    

    File pandas\\_libs\\hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()
    

    File pandas\\_libs\\hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()
    

    KeyError: 'price_level'

    
    The above exception was the direct cause of the following exception:
    

    KeyError                                  Traceback (most recent call last)

    Cell In[46], line 13
         10     return [pos[0] for pos in poses if pos[0] in common_words]
         12 # 1:3:1 ë¹„ìœ¨ë¡œ ëœë¤ ìƒ˜í”Œë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 
    ---> 13 negative_random = df[df['price_level'] == '0'].sample(321, random_state = 30)
         14 neutral_random = df[df['price_level'] == '1'].sample(321 * 3, random_state = 30) 
         15 positive_random = df[df['price_level'] == '2'].sample(321, random_state = 30) 
    

    File C:\python_basic\python3.9\lib\site-packages\pandas\core\frame.py:4102, in DataFrame.__getitem__(self, key)
       4100 if self.columns.nlevels > 1:
       4101     return self._getitem_multilevel(key)
    -> 4102 indexer = self.columns.get_loc(key)
       4103 if is_integer(indexer):
       4104     indexer = [indexer]
    

    File C:\python_basic\python3.9\lib\site-packages\pandas\core\indexes\base.py:3812, in Index.get_loc(self, key)
       3807     if isinstance(casted_key, slice) or (
       3808         isinstance(casted_key, abc.Iterable)
       3809         and any(isinstance(x, slice) for x in casted_key)
       3810     ):
       3811         raise InvalidIndexError(key)
    -> 3812     raise KeyError(key) from err
       3813 except TypeError:
       3814     # If we have a listlike key, _check_indexing_error will raise
       3815     #  InvalidIndexError. Otherwise we fall through and re-raise
       3816     #  the TypeError.
       3817     self._check_indexing_error(key)
    

    KeyError: 'price_level'


ğŸ” ìƒí’ˆì˜ ìƒíƒœ ë¶„ë¥˜í•˜ê¸° 


```python
from sklearn.metrics import accuracy_score 
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix 

# ë¹„ì„ í˜• SVM ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤. 
svm = SVC(kernel = 'rbf', C = 10.0, random_state = 0, gamma = 0.10) 
svm.fit(x_train, y_train) 
y_pred_ksvc = svm.predict(x_test)
print('Accuracy : %.2f' % accuracy_score(y_test, y_pred_ksvc)) 

# Confusion matrixë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. 
confmat = confusion_matrix(y_true = y_test, y_pred = y_pred_ksvc) 
print(confmat)
```

    Accuracy : 0.77
    [[ 30  28   4]
     [ 10 181  10]
     [  2  21  35]]
    

## ì˜ˆì¸¡ : ì¤‘ê³  íœ´ëŒ€í° ê±°ë˜ê°€ ì˜ˆì¸¡í•˜ê¸° 

|í”¼ì²˜|ì„¤ëª…|
|-|-|
|create_time_score|create_date í”¼ì²˜ë¥¼ unixtimeìœ¼ë¡œ ë°”ê¾¸ì–´ ì–¼ë§ˆë‚˜ ì˜¤ë˜ëœ ê²Œì‹œë¬¼ì¸ì§€ë¥¼ 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ í‘œí˜„í•©ë‹ˆë‹¤. 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìµœê·¼ì— ì‘ì„±í•œ ê²Œì‹œë¬¼ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.|
|phone_model_storage phone_model_detail|phone_model í”¼ì²˜ë¥¼ ë‘˜ë¡œ ë‚˜ëˆˆ ê²ƒì…ë‹ˆë‹¤.|
|product_status|ë™ì¼ ê¸°ì¢… ë‚´ ìƒëŒ€ ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°ì„±(ìƒí’ˆ ìƒíƒœ)ì„ ë¶„ë¥˜í•œ ê²ƒì…ë‹ˆë‹¤. ìƒí’ˆì˜ ìƒíƒœëŠ” 3ê°œì˜ ë²”ì£¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.|

ğŸ” Random forest regressor ì¬í•™ìŠµí•˜ê¸° 


```python
# text í”¼ì²˜ë¡œë¶€í„° 'ìƒí’ˆ ìƒíƒœ í”¼ì²˜(product_status)'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
X = index_vectorizer.transform(df['text'].tolist())
X = tfidf_vectorizer.transform(X)
df['product_status'] = pd.Series(svm.predict(X))

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. 
df = df[['price', 'factory_price', 'maker', 'price_index', 'create_time_score', 'phone_model_storage', 'phone_model_detail', 'product_status']]
df = pd.get_dummies(df, columns = ['maker', 'phone_model_storage', 'phone_model_detail', 'product_status'])

# í•™ìŠµ / í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤. 
X = df.loc[:, df.columns != 'price']
y = df['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤. 
forest = RandomForestRegressor(n_estimators = 1000, 
                               criterion = 'squared_error')
forest.fit(X_train, y_train) 
y_train_pred = forest.predict(X_train)
y_test_pred = forest.predict(X_test) 
print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))
print('RÂ² train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))

# í”¼ì²˜ ì¤‘ìš”ë„ plotì„ ì¶œë ¥í•©ë‹ˆë‹¤. 
importances = forest.feature_importances_
plt.plot(importances, "o")

# í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ printë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. 
feat_labels = X.columns.tolist()
feature = list(zip(feat_labels, forest.feature_importances_))
sorted(feature, key = lambda tup : tup[1], reverse = True)[:10]
```

    MSE train : 4776787502.800, test : 10989939019.024
    RÂ² train : 0.902, test : 0.749
    




    [('factory_price', 0.25541447618127155),
     ('maker_apple', 0.25412616119268205),
     ('create_time_score', 0.11668495448580446),
     ('phone_model_storage_16gb', 0.06051378719594219),
     ('product_status_2', 0.047367428981745625),
     ('phone_model_detail_galaxy s7 edge', 0.028075173013449806),
     ('phone_model_storage_64gb', 0.025290274383250877),
     ('phone_model_detail_galaxy note5', 0.02385578043405257),
     ('phone_model_detail_galaxy s7', 0.021782726181949062),
     ('product_status_0', 0.021419475822646257)]




    
![png](/assets/images/Book/8/output_38_2.png)
    


ğŸ” ì˜ˆì¸¡ ê²°ê³¼ ì‚°ì ë„ ê·¸ë˜í”„ 


```python
# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ yê°’ê³¼ ì˜ˆì¸¡ëœ yê°’ì„ ì‚°ì ë„ ê·¸ë˜í”„ë¥¼ í™œìš©í•˜ì—¬ ìƒê´€ ê´€ê³„ë¥¼ ì‚´í´ë´…ë‹ˆë‹¤. 
plt.scatter(y_test.values, y_test_pred)
```




    <matplotlib.collections.PathCollection at 0x1cca24a27f0>




    
![png](/assets/images/Book/8/output_40_1.png)
    


ğŸ” ìµœì ì˜ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì°¾ê¸° 


```python
from sklearn.model_selection import RandomizedSearchCV

# Randomized Searchë¡œ ì°¾ì•„ë‚¼ íŒŒë¼ë¯¸í„° í›„ë³´êµ°ì„ ê°ê° ë¦¬ìŠ¤íŠ¸ë¡œ ì„ ì •í•©ë‹ˆë‹¤. 
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] 
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
bootstrap = [True, False] 

# RandomizedSearchCV ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤. 
random_grid = {'n_estimators' : n_estimators, 
              'max_features' : max_features, 
              'max_depth' : max_depth, 
              'bootstrap' : bootstrap}
forest = RandomForestRegressor()
optimal_forest = RandomizedSearchCV(estimator = forest, 
                                    param_distributions = random_grid, 
                                    n_iter = 100, 
                                    cv = 3, 
                                    verbose = 2, 
                                    random_state = 42, 
                                    n_jobs = -1) 

# RandomizedSearchCV ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. 
X = df.loc[:, df.columns != 'price']
y = df['price']
optimal_forest.fit(X, y)
```

    Fitting 3 folds for each of 100 candidates, totalling 300 fits
    

    C:\python_basic\python3.9\lib\site-packages\sklearn\model_selection\_validation.py:528: FitFailedWarning: 
    120 fits failed out of a total of 300.
    The score on these train-test partitions for these parameters will be set to nan.
    If these failures are not expected, you can try to debug them by setting error_score='raise'.
    
    Below are more details about the failures:
    --------------------------------------------------------------------------------
    47 fits failed with the following error:
    Traceback (most recent call last):
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\model_selection\_validation.py", line 866, in _fit_and_score
        estimator.fit(X_train, y_train, **fit_params)
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\base.py", line 1382, in wrapper
        estimator._validate_params()
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\base.py", line 436, in _validate_params
        validate_parameter_constraints(
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\utils\_param_validation.py", line 98, in validate_parameter_constraints
        raise InvalidParameterError(
    sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.
    
    --------------------------------------------------------------------------------
    73 fits failed with the following error:
    Traceback (most recent call last):
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\model_selection\_validation.py", line 866, in _fit_and_score
        estimator.fit(X_train, y_train, **fit_params)
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\base.py", line 1382, in wrapper
        estimator._validate_params()
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\base.py", line 436, in _validate_params
        validate_parameter_constraints(
      File "C:\python_basic\python3.9\lib\site-packages\sklearn\utils\_param_validation.py", line 98, in validate_parameter_constraints
        raise InvalidParameterError(
    sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.
    
      warnings.warn(some_fits_failed_message, FitFailedWarning)
    C:\python_basic\python3.9\lib\site-packages\sklearn\model_selection\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-13.65937944 -14.52390335 -14.5284538  -13.99875649 -14.58222073
     -13.36061919          nan -14.50886882 -13.57540033          nan
              nan          nan -14.57935743 -14.52489091 -13.37921243
     -13.32894865 -13.5217637           nan -13.37651722          nan
              nan          nan -13.20598533          nan          nan
     -14.49201868 -14.52376463          nan          nan          nan
     -14.5517001  -13.11146139          nan -14.49838937 -14.57688875
     -13.55702815          nan -13.32174781 -14.63419008 -12.88180624
     -14.56359166          nan -13.73369932          nan -13.39039801
              nan -14.57909513 -13.53539239 -13.48197411          nan
     -14.6128912           nan -14.48256156 -14.52870307          nan
              nan          nan          nan -14.5995115  -13.53770993
              nan -12.5151585  -13.68484306 -13.52295203 -13.50380885
              nan          nan          nan -13.42981901 -13.6277595
     -14.43237698 -13.49804953          nan          nan -13.49844051
     -13.38332709          nan -14.62415385 -14.54572495 -13.53803176
              nan -12.96686997 -13.42388862          nan -12.84564472
     -14.5005583           nan -13.60818056          nan -13.7258187
     -14.64789159          nan -13.65957203          nan          nan
     -14.53617181 -13.56716564          nan -14.56510044          nan]
      warnings.warn(
    




<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "â–¸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "â–¾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,
                   n_jobs=-1,
                   param_distributions={&#x27;bootstrap&#x27;: [True, False],
                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,
                                                      70, 80, 90, 100, 110,
                                                      None],
                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],
                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,
                                                         1000, 1200, 1400, 1600,
                                                         1800, 2000]},
                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>RandomizedSearchCV</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">?<span>Documentation for RandomizedSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,
                   n_jobs=-1,
                   param_distributions={&#x27;bootstrap&#x27;: [True, False],
                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,
                                                      70, 80, 90, 100, 110,
                                                      None],
                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],
                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,
                                                         1000, 1200, 1400, 1600,
                                                         1800, 2000]},
                   random_state=42, verbose=2)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>best_estimator_: RandomForestRegressor</div></div></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(bootstrap=False, max_depth=10, max_features=&#x27;sqrt&#x27;,
                      n_estimators=800)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>RandomForestRegressor</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html">?<span>Documentation for RandomForestRegressor</span></a></div></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(bootstrap=False, max_depth=10, max_features=&#x27;sqrt&#x27;,
                      n_estimators=800)</pre></div> </div></div></div></div></div></div></div></div></div>




```python
# ì•ì„œ ì„ ì •í•œ íŒŒë¼ë¯¸í„° í›„ë³´êµ° ì¤‘ì—ì„œ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ íŒŒë¼ë¯¸í„°ì˜ ì¡°í•©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. 
print(optimal_forest.best_params_)
```

    {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}
    

ğŸ” ìµœì  ëª¨ë¸ í•™ìŠµ ê²°ê³¼ 


```python
# ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì ìš©í•œ ëª¨ë¸ë¡œ ì¤‘ê³  íœ´ëŒ€í°ì˜ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤. 
y_train_pred = optimal_forest.predict(X_train)
y_test_pred = optimal_forest.predict(X_test) 
print('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))
print('RÂ² train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))

# ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ì˜ í”¼ì²˜ ì¤‘ìš”ë„ plotì„ ì¶œë ¥í•©ë‹ˆë‹¤. 
importances = optimal_forest.best_estimator_.feature_importances_
indices = np.argsort(importances)[::-1]
plt.bar(range(X.shape[1]), importances[indices])

# ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ì˜ í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. 
feat_labels = X.columns.tolist()
feature = list(zip(feat_labels, optimal_forest.best_estimator_.feature_importances_))
sorted(feature, key = lambda tup : tup[1], reverse = True)[:10]
```

    MSE train : 9147924289.929, test : 8523056673.840
    RÂ² train : 0.811, test : 0.805
    




    [('factory_price', 0.12862997585867847),
     ('maker_apple', 0.10688582914657667),
     ('phone_model_storage_128gb', 0.08710363454652008),
     ('phone_model_detail_iphone 7', 0.08602750647756545),
     ('phone_model_storage_64gb', 0.08098972166396726),
     ('create_time_score', 0.04967264647569188),
     ('product_status_0', 0.0405762829270737),
     ('phone_model_detail_iphone 7 plus', 0.0374777624382044),
     ('phone_model_storage_16gb', 0.03590211566115451),
     ('product_status_2', 0.03492787121301639)]




    
![png](/assets/images/Book/8/output_45_2.png)
    


ğŸ” ì˜ˆì¸¡ ê²°ê³¼ ì‚°ì ë„ ê·¸ë˜í”„


```python
# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ yê°’ê³¼, ì˜ˆì¸¡ëœ yê°’ì„ ì‚°ì ë„ ê·¸ë˜í”„ë¥¼ í™œìš©í•˜ì—¬ ìƒê´€ ê´€ê³„ë¥¼ ì‚´í´ë´…ë‹ˆë‹¤. 
plt.scatter(y_test.values, y_test_pred)
```




    <matplotlib.collections.PathCollection at 0x1ccc04b3880>




    
![png](/assets/images/Book/8/output_47_1.png)
    


## í”„ë¡œí† íƒ€ì… : ì–¼ë§ˆê³ (Almhago?)

ğŸ” ì¬ì‚¬ìš©ì„ ìœ„í•œ íŒŒì¼ ì €ì¥í•˜ê¸°


```python
import joblib 

# ëª¨ë¸ëª… + ìš©ëŸ‰ìœ¼ë¡œ ì¶œê³ ê°€ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
model_to_factory_price_dict = {} 

for index, row in df.iterrows():
    # One-Hotëœ ì»¬ëŸ¼ë“¤ ì¤‘ì—ì„œ Trueì¸ ê°’ì„ ë³µì›
    detail = [col.replace('phone_model_detail_', '') for col in row.index if col.startswith('phone_model_detail_') and row[col] == True]
    storage = [col.replace('phone_model_storage_', '') for col in row.index if col.startswith('phone_model_storage_') and row[col] == True]

    # ë‘˜ ë‹¤ ìˆì„ ê²½ìš°ë§Œ ë”•ì…”ë„ˆë¦¬ì— ë“±ë¡
    if detail and storage:
        model_concat = (detail[0], storage[0])
        if model_concat not in model_to_factory_price_dict:
            model_to_factory_price_dict[model_concat] = row['factory_price']

print(str(model_to_factory_price_dict)[:40], "...")

# í”„ë¡œê·¸ë¨ì—ì„œ ì…ë ¥ê°’ì— ëŒ€í•œ í”¼ì²˜ë¥¼ ì°¾ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
col_to_index_dict = {} 
for idx, col in enumerate(df.columns[1:]) : 
    col_to_index_dict[col] = idx 

print(str(col_to_index_dict)[:40], "...")

# ëª¨ë¸ ì˜ˆì¸¡ì„ ìœ„í•œ ì¤‘ê°„ ì˜¤ë¸Œì íŠ¸ë“¤ì„ ê°ê° íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. 
with open('./data/used_mobile_pickles/model_to_factory_price_dict.pickle', 'wb') as f : 
    pickle.dump(model_to_factory_price_dict, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/col_to_index_dict.pickle', 'wb') as f : 
    pickle.dump(col_to_index_dict, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/common_words.pickle', 'wb') as f : 
    pickle.dump(common_words, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/init_vectorizer_vocabulary.pickle', 'wb') as f : 
    pickle.dump(index_vectorizer.vocabulary_, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/tfidf_vectorizer.pickle', 'wb') as f : 
    pickle.dump(tfidf_vectorizer, f, pickle.HIGHEST_PROTOCOL) 

with open('./data/used_mobile_pickles/svm_classifier.pickle', 'wb') as f : 
    pickle.dump(svm, f, pickle.HIGHEST_PROTOCOL) 

joblib.dump(optimal_forest.best_estimator_, './data/used_mobile_pickles/rf_regressor.pickle', compress = 1) 
```

    {('iphone 6', '64gb'): 924000, ('galaxy  ...
    {'factory_price': 0, 'price_index': 1, ' ...
    




    ['./data/used_mobile_pickles/rf_regressor.pickle']



ğŸ” í”„ë¡œê·¸ë¨(í´ë˜ìŠ¤) ë§Œë“¤ê¸° 


```python
import numpy as np 

from konlpy.tag import Okt 
from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestRegressor 
from sklearn.model_selection import RandomizedSearchCV 

class Almhago() : 
    def __init__(self, model_to_factory_price_dict, col_to_index_dict, common_words, init_vectorizer_vocabulary, 
                 tfidf_vectorizer, prd_status_classifier, price_regressor) : 
        self._model_to_factory_price_dict = model_to_factory_price_dict
        self._col_to_index_dict = col_to_index_dict
        self._common_words = common_words 
        self._init_vectorizer_vocabulary = init_vectorizer_vocabulary 
        self._index_vectorizer = self._init_index_vectorizer()
        self._tfidf_vectorizer = tfidf_vectorizer 
        self._prd_status_classifier = prd_status_classifier 
        self._price_regressor = price_regressor 

    def _get_common_pos(self, x) : 
        tagger = Okt()
        poses = tagger.pos(x) 
        return [pos[0] for pos in poses if pos[0] in self._common_words] 

    def _text_cleaning(self, text) : 
        text = ''.join(c for c in text if c.isalnum() or c in '+, ')
        text = ''.join([i for i in text if not i.isdigit()])
        return text 

    def _init_index_vectorizer(self) : 
        word_index_vectorizer = CountVectorizer(tokenizer = lambda x : self._get_common_pos(x))
        word_index_vectorizer.vocabulary_ = self._init_vectorizer_vocabulary
        return word_index_vectorizer 

    def _get_ftr_price(self, model_name, storage) : 
        return self._model_to_factory_price_dict[(model_name, storage)] 

    def _get_prd_status(self, text) : 
        X = self._index_vectorizer.transform([self._text_cleaning(program_test_dict['text'])])
        X = self._tfidf_vectorizer.transform(X)
        return self._prd_status_classifier.predict(X)[0]

    def _print_almhago(self, model, price, prd_status) : 
        status = ""
        if prd_status == "0" : 
            status = "ë¶ˆëŸ‰í•œ" 
        elif prd_status == "1" : 
            status = "ì–‘í˜¸í•œ" 
        else : 
            status = "ì¢‹ì€"
        print("ì„ íƒí•˜ì‹ ", model, "ëª¨ë¸ì€", status, "ìƒíƒœì…ë‹ˆë‹¤. Almhago ì˜ˆìƒ ê°€ê²©ì€", str(int(price[0])), "ì› ì…ë‹ˆë‹¤.")

    def predict(self, input_dict) : 
        feature = np.zeros(64)
        feature[self._col_to_index_dict['factory_price']] = self._get_ftr_price(input_dict['phone_model_detail'], input_dict['phone_model_storage'])
        feature[self._col_to_index_dict['price_index']] = input_dict['price_index']
        feature[self._col_to_index_dict['create_time_score']] = input_dict['create_time_score']
        feature[self._col_to_index_dict["_".join(['maker', input_dict['maker']])]] = 1
        feature[self._col_to_index_dict["_".join(["phone_model_detail", input_dict['phone_model_detail']])]] = 1
        feature[self._col_to_index_dict["_".join(['phone_model_storage', input_dict['phone_model_storage']])]] = 1
        feature[self._col_to_index_dict["_".join(['product_status', self._get_prd_status(input_dict['text'])])]] = 1
    
        # âœ… ê²½ê³  ì—†ì´ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ DataFrameìœ¼ë¡œ ë³€í™˜
        import pandas as pd
        feature_df = pd.DataFrame([feature], columns=list(self._col_to_index_dict.keys()))
        predicted_price = self._price_regressor.predict(feature_df)
    
        self._print_almhago(input_dict['phone_model_detail'], 
                            predicted_price, 
                            self._get_prd_status(input_dict['text']))
```

ğŸ” í”„ë¡œê·¸ë¨ í…ŒìŠ¤íŠ¸í•˜ê¸° 


```python
import pickle
import joblib

# ì €ì¥í–ˆë˜ ê°ì²´ë“¤ ë¡œë“œ
with open('./data/used_mobile_pickles/model_to_factory_price_dict.pickle', 'rb') as f:
    model_to_factory_price_dict = pickle.load(f)

with open('./data/used_mobile_pickles/col_to_index_dict.pickle', 'rb') as f:
    col_to_index_dict = pickle.load(f)

with open('./data/used_mobile_pickles/common_words.pickle', 'rb') as f:
    common_words = pickle.load(f)

with open('./data/used_mobile_pickles/init_vectorizer_vocabulary.pickle', 'rb') as f:
    init_vectorizer_vocabulary = pickle.load(f)

with open('./data/used_mobile_pickles/tfidf_vectorizer.pickle', 'rb') as f:
    tfidf_vectorizer = pickle.load(f)

with open('./data/used_mobile_pickles/svm_classifier.pickle', 'rb') as f:
    svm_classifier = pickle.load(f)

rf_regressor = joblib.load('./data/used_mobile_pickles/rf_regressor.pickle')

```


```python
# ë°ì´í„°ì˜ ê°€ì¥ ìµœê·¼ ì‹œì ì¸ 2017ë…„ 4ì›”ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ê¸° ìœ„í•œ 2ê°œ(price_index, create_time_score)ì˜ í”¼ì²˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. 
recent_price_index =  95.96
recent_create_time_score = 1.0 

# íŒë§¤ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ë©”ì´ì»¤, ê¸°ì¢…, ìš©ëŸ‰ì„ ì…ë ¥í•˜ê³ , ìƒí’ˆì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²Œì‹œê¸€ì„ ì…ë ¥í•©ë‹ˆë‹¤. 
program_test_dict = {'maker' : 'apple', 
                    'phone_model_detail' : 'iphone 6', 
                    'phone_model_storage' : '16gb', 
                    'text' : 'ì•„ì´í°6ìŠ¤í˜ì´ìŠ¤ê·¸ë ˆì´ 16ê¸°ê°€ 10ë§Œì›ì— íŒ”ì•„ìš”~ ì§ì ‘ê±°ë˜\
                    ë©”ì¸ë³´ë“œ ì„¸ì²™ ì™„ë£Œ í•œ ì¹¨ìˆ˜ í°ì…ë‹ˆë‹¤í° ì•ˆì¼œì§€ëŠ” ìƒí…Œì´êµ¬ìš” ê³ ì³ì„œ ì“°ì‹¤ë¶„ ê°€ì ¸ê°€ì„¸ìš”10ë§Œì›ì— íŒ”ì•„ìš” \
                    ë¦¬í¼í•œì§€ ì–¼ë§ˆì•ˆë˜ì„œ ê¸°ìŠ¤ ì´ëŸ°ê±° í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¹~ì„œìš¸ ê°•ë‚¨ ê·¼ì²˜ ì§ê±°ë˜ ê°€ëŠ¥í•˜ë©°íƒë°°ê±°ë˜ë„ ê°€ëŠ¥í•´ìš”', 
                    'price_index' : recent_price_index, 
                    'create_time_score' : recent_create_time_score}

# ì •ì˜í•œ í”¼ì²˜ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ í•˜ì—¬ almhago ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
almhago = Almhago(model_to_factory_price_dict, col_to_index_dict, common_words, init_vectorizer_vocabulary, tfidf_vectorizer, svm_classifier, rf_regressor) 

# ì…ë ¥í•œ ë°ì´í„°ë¡œ íŒë§¤ ê°€ê²©ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. 
almhago.predict(program_test_dict)
```

    ì„ íƒí•˜ì‹  iphone 6 ëª¨ë¸ì€ ë¶ˆëŸ‰í•œ ìƒíƒœì…ë‹ˆë‹¤. Almhago ì˜ˆìƒ ê°€ê²©ì€ 184641 ì› ì…ë‹ˆë‹¤.
    

## í‘œë¡œ ì •ë¦¬í•˜ëŠ” ë°ì´í„° ë¶„ì„

|ì£¼ìš” í‚¤ì›Œë“œ|í•µì‹¬ ë‚´ìš©|ì„¤ëª…|
|-|-|-|
|ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸|ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì˜ˆì¸¡ ëª¨ë¸ì„ í™œìš©í•œ ë°ì´í„° ë¶„ì„|ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì€ ì˜ì‚¬ê²°ì • ë‚˜ë¬´(Decision Tree)ë¥¼ ì‘ìš©í•œ ëª¨ë¸ë¡œ íšŒê·€ì™€ ë¶„ë¥˜ë¥¼ ëª¨ë‘ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ì˜ ê³¼ì •ì—ì„œë„ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.|
|ê·¸ë£¹ ë‚´ í”¼ì²˜ì˜ í‘œì¤€í™”|z-scoreë¥¼ ê³„ì‚°í•˜ì—¬ í”¼ì²˜ë¥¼ í‘œì¤€í™” í•˜ëŠ” ë°©ë²•|í”¼ì²˜ì˜ í‰ê· ê°’, ê·¸ë¦¬ê³  í‘œì¤€í¸ì°¨ ê°’ì„ ì´ìš©í•˜ì—¬ ê·¸ë£¹ ë‚´ì˜ í”¼ì²˜ë¥¼ z-scoreë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì˜ ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ ì ìˆ˜ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.|
|ì‹œê³„ì—´ ë°ì´í„°ì˜ í™œìš©|unixtimeì„ ì´ìš©í•œ ì‹œê°„ ì ìˆ˜ ê³„ì‚°|ì‹œê°„ì„ í”¼ì²˜ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ unixtimeì„ ì´ìš©í•˜ì—¬ 'ì–¼ë§ˆë‚˜ ì˜¤ë˜ë˜ì—ˆëŠ”ê°€'ë¥¼ ì ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ì—ˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ë¥¼ ë‹¤ì‹œ min-max ìŠ¤ì¼€ì¼ë§ì„ ì ìš©í•˜ì—¬ 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìµœê·¼ì˜ ë°ì´í„°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.|
|ê°ì„± ë¶„ë¥˜ì˜ ê³¼ì •|ì§ì ‘ ê°ì„± ë¶„ë¥˜ë¥¼ ì„¤ê³„í•˜ì—¬ í‰ê°€í•˜ëŠ” ë°©ë²•|z-scoreë¡œ ê°€ê²©ì˜ ìƒ, ì¤‘, í•˜ë¥¼ ê²°ì •í•œ ë’¤, ì´ë¥¼ ê°ì„± ë¶„ë¥˜ì˜ ì •ë‹µ ë°ì´í„°ì…‹ìœ¼ë¡œ í™œìš©í•©ë‹ˆë‹¤. í”¼ì²˜ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ë¹ˆì¶œ ë‹¨ì–´ 3,000ê°œ ë‚´ì—ì„œì˜ TF-IDF ë³€í™˜ì„ ì‚¬ìš©í•˜ì˜€ê³ , ê°ì„± ë¶„ë¥˜ ëª¨ë¸ìœ SVMì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.|
|ìµœì  íŒŒë¼ë¯¸í„° íŠœë‹|ë¶„ë¥˜ ëª¨ë¸ì—ì„œì˜ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ|ë¶„ë¥˜ ëª¨ë¸ì—ì„œëŠ” Positive sample, Negative sampleì˜ ë¹„ìœ¨ ë•Œë¬¸ì— í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.|
|í”„ë¡œê·¸ë¨ ì‘ìš©|ë¶„ì„ ëª¨ë¸ì„ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ë§Œë“¤ê¸°|ë¶„ì„ì˜ ê³¼ì •ì—ì„œ ìƒì„±ëœ Dictionary, ëª¨ë¸ ê°ì²´ ë“±ì„ ëª¨ë‘ íŒŒì¼ í˜•íƒœë¡œ ì €ì¥í•©ë‹ˆë‹¤. ì´ë¥¼ í™œìš©í•˜ì—¬ ì…ë ¥ ë°ì´í„°ë¥¼ í”¼ì²˜ë¡œ ë³€í™˜í•˜ê³ , ë³€í™˜ëœ í”¼ì²˜ë¥¼ ëª¨ë¸ì˜ predict() í•¨ìˆ˜ì— ì…ë ¥í•©ë‹ˆë‹¤. ê·¸ ê²°ê³¼, ë¶„ì„ ê³¼ì •ì—ì„œì™€ ë˜‘ê°™ì€ ê²°ê³¼ë¥¼ í”„ë¡œê·¸ë¨ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.|
