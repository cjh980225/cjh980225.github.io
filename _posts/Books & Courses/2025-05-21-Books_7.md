---

title: "[이것이 데이터 분석이다] 타이타닉의 생존자 가려내기"

categories: Books&Courses

tags: [Book, 이것이_데이터_분석이다, pandas, visualization, analysis]

---

# 타이타닉의 생존자 가려내기 

## 탐색 : 타이타닉 데이터 살펴보기 

|변수|내용|
|-|-|
|pclass|Passenger Class, 승객 등급|
|survived|생존 여부(생존은 1, 아닌 경우는 0)|
|name|승객 이름|
|sex|승객 성별|
|age|승객 나이|
|sibsp|동승한 형제 또는 배우자 수|
|parch|동승한 부모 또는 자녀 수|
|ticket|티켓 번호|
|fare|승객 지불 요금|
|cabin|선실 이름|
|embarked|승선항(C = 쉘부르크, Q = 퀸즈타운, S = 사우스 햄튼)|
|body|사망자 확인 번호|
|home.dest|고향/목적지|

🔍 타이타닉 데이터셋의 기본 정보 구하기 


```python
# -*- coding : utf-8 -*- 
%matplotlib inline 

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns 

df_train = pd.read_csv("./data/titanic_train.csv")
df_test = pd.read_csv("./data/titanic_test.csv")
df_train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pclass</th>
      <th>survived</th>
      <th>name</th>
      <th>sex</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>ticket</th>
      <th>fare</th>
      <th>cabin</th>
      <th>embarked</th>
      <th>body</th>
      <th>home.dest</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>1</td>
      <td>Mellinger, Miss. Madeleine Violet</td>
      <td>female</td>
      <td>13.0</td>
      <td>0</td>
      <td>1</td>
      <td>250644</td>
      <td>19.5000</td>
      <td>NaN</td>
      <td>S</td>
      <td>NaN</td>
      <td>England / Bennington, VT</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>Wells, Miss. Joan</td>
      <td>female</td>
      <td>4.0</td>
      <td>1</td>
      <td>1</td>
      <td>29103</td>
      <td>23.0000</td>
      <td>NaN</td>
      <td>S</td>
      <td>NaN</td>
      <td>Cornwall / Akron, OH</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>Duran y More, Miss. Florentina</td>
      <td>female</td>
      <td>30.0</td>
      <td>1</td>
      <td>0</td>
      <td>SC/PARIS 2148</td>
      <td>13.8583</td>
      <td>NaN</td>
      <td>C</td>
      <td>NaN</td>
      <td>Barcelona, Spain / Havana, Cuba</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>0</td>
      <td>Scanlan, Mr. James</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>36209</td>
      <td>7.7250</td>
      <td>NaN</td>
      <td>Q</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>1</td>
      <td>Bradley, Miss. Bridget Delia</td>
      <td>female</td>
      <td>22.0</td>
      <td>0</td>
      <td>0</td>
      <td>334914</td>
      <td>7.7250</td>
      <td>NaN</td>
      <td>Q</td>
      <td>NaN</td>
      <td>Kingwilliamstown, Co Cork, Ireland Glens Falls...</td>
    </tr>
  </tbody>
</table>
</div>




```python
print(df_train.info())
print("-----------------------------------------------------")
print(df_test.info())
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 916 entries, 0 to 915
    Data columns (total 13 columns):
     #   Column     Non-Null Count  Dtype  
    ---  ------     --------------  -----  
     0   pclass     916 non-null    int64  
     1   survived   916 non-null    int64  
     2   name       916 non-null    object 
     3   sex        916 non-null    object 
     4   age        741 non-null    float64
     5   sibsp      916 non-null    int64  
     6   parch      916 non-null    int64  
     7   ticket     916 non-null    object 
     8   fare       916 non-null    float64
     9   cabin      214 non-null    object 
     10  embarked   914 non-null    object 
     11  body       85 non-null     float64
     12  home.dest  527 non-null    object 
    dtypes: float64(3), int64(4), object(6)
    memory usage: 93.2+ KB
    None
    -----------------------------------------------------
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 393 entries, 0 to 392
    Data columns (total 13 columns):
     #   Column     Non-Null Count  Dtype  
    ---  ------     --------------  -----  
     0   pclass     393 non-null    int64  
     1   survived   393 non-null    int64  
     2   name       393 non-null    object 
     3   sex        393 non-null    object 
     4   age        305 non-null    float64
     5   sibsp      393 non-null    int64  
     6   parch      393 non-null    int64  
     7   ticket     393 non-null    object 
     8   fare       393 non-null    float64
     9   cabin      81 non-null     object 
     10  embarked   393 non-null    object 
     11  body       36 non-null     float64
     12  home.dest  218 non-null    object 
    dtypes: float64(3), int64(4), object(6)
    memory usage: 40.0+ KB
    None
    

🔍 불필요한 피처 제거하기


```python
# 데이터셋에서 name, ticket, body, cabin, home.dest 피처를 제거합니다. 
df_train = df_train.drop(['name', 'ticket', 'body', 'cabin', 'home.dest'], axis = 1)
df_test = df_test.drop(['name', 'ticket', 'body', 'cabin', 'home.dest'], axis = 1)
```

🔍 탐색적 데이터 분석하기 


```python
print(df_train['survived'].value_counts())
df_train['survived'].value_counts().plot.bar()
```

    survived
    0    563
    1    353
    Name: count, dtype: int64
    




    <Axes: xlabel='survived'>




    
![png](/assets/images/Book/7/output_6_2.png)
    



```python
# survived 피처를 기준으로 그룹을 나누어 그룹별 pclass 피처의 분포를 살펴봅니다. 
print(df_train['pclass'].value_counts())
ax = sns.countplot(x = 'pclass', hue = 'survived', data = df_train)
```

    pclass
    3    498
    1    230
    2    188
    Name: count, dtype: int64
    


    
![png](/assets/images/Book/7/output_7_1.png)
    


🔍 Shapiro-wilk 검정

▪ Shapiro-wilk 검정이란 주어진 데이터가 얼마나 정규성을 따르는지, 즉 얼마나 정규분포에 가까운지를 측정하는 검정입니다. 

🔍 변수 탐색작업 자동화하기 


```python
from scipy import stats 

# 두 집단의 피처를 비교해주며 탐색작업을 자동화하는 함수를 정의합니다. 
def valid_features(df, col_name, distribution_check = True) : 

    # 두 집단 (survivied = 1, survivied = 0)의 분포 그래프를 출력합니다. 
    g = sns.FacetGrid(df, col = 'survived')
    g.map(plt.hist, col_name, bins = 30)

    # 두 집단 (survived = 1, survived = 0)의 표준편차를 각각 출력합니다. 
    titanic_survived = df[df['survived'] == 1]
    titanic_survived_static = np.array(titanic_survived[col_name])
    print("data std id", "%.2f" % np.std(titanic_survived_static))
    titanic_n_survived = df[df['survived'] == 0] 
    titanic_n_survived_static = np.array(titanic_n_survived[col_name])
    print("data std id", "%.2f" % np.std(titanic_n_survived_static))

    # T-test로 두 집단의 평균 차이를 검정합니다. 
    tTestResult = stats.ttest_ind(titanic_survived[col_name], titanic_n_survived[col_name])
    tTestResultDiffVar = stats.ttest_ind(titanic_survived[col_name], titanic_n_survived[col_name], equal_var = False)
    print("The t-statistic and p-value assuming equal variances is %.3f and %.3f." % tTestResult)
    print("The t-statistic and p-value not assuming equal variances is %.3f and %.3f." % tTestResultDiffVar)

    if distribution_check : 
        # Shapiro-Wilk 검정 : 분포의 정규성 정도를 검증합니다. 
        print("The w-statistic and p-value in Survived %.3f and %.3f" % stats.shapiro(titanic_survived[col_name]))
        print("The w-statistic and p-value in Non-Survived %.3f and %.3f" % stats.shapiro(titanic_n_survived[col_name]))
```

🔍 자동화 함수 실행하기


```python
# 앞서 정의한 valid_features 함수를 실행합니다. age 피처와 sibsp 피처를 탐색합니다. 
valid_features(df_train[df_train['age'] > 0], 'age', distribution_check = True)
valid_features(df_train, 'sibsp', distribution_check = False)
```

    data std id 14.22
    data std id 13.71
    The t-statistic and p-value assuming equal variances is -0.546 and 0.585.
    The t-statistic and p-value not assuming equal variances is -0.543 and 0.587.
    The w-statistic and p-value in Survived 0.982 and 0.001
    The w-statistic and p-value in Non-Survived 0.968 and 0.000
    data std id 0.64
    data std id 1.34
    The t-statistic and p-value assuming equal variances is -2.118 and 0.034.
    The t-statistic and p-value not assuming equal variances is -2.446 and 0.015.
    


    
![png](/assets/images/Book/7/output_11_1.png)
    



    
![png](/assets/images/Book/7/output_11_2.png)
    


## 분류 : 생존자 분류 모델 만들기 

🔍 분류 모델을 위해 전처리하기 


```python
# age의 결측값을 평균값으로 대체합니다. 
replace_mean = df_train[df_train['age'] > 0]['age'].mean()
df_train['age'] = df_train['age'].fillna(replace_mean)
df_test['age'] = df_test['age'].fillna(replace_mean)

# embark : 2개의 결측값을 최빈값으로 대체합니다. 
embarked_mode = df_train['embarked'].value_counts().index[0]
df_train['embarked'] = df_train['embarked'].fillna(embarked_mode)
df_test['embarked'] = df_test['embarked'].fillna(embarked_mode)

# 원-핫 인코딩을 위한 통합 데이터 프레임(whole_df)을 생성합니다. 
whole_df = pd.concat([df_train, df_test], ignore_index=True)
train_idx_num = len(df_train)

# pnadas 패키지를 이용한 원-핫 인코딩을 수행합니다. 
whole_df_encoded = pd.get_dummies(whole_df)
df_train = whole_df_encoded[:train_idx_num]
df_test = whole_df_encoded[train_idx_num:]

df_train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pclass</th>
      <th>survived</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>sex_female</th>
      <th>sex_male</th>
      <th>embarked_C</th>
      <th>embarked_Q</th>
      <th>embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>1</td>
      <td>13.000000</td>
      <td>0</td>
      <td>1</td>
      <td>19.5000</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>4.000000</td>
      <td>1</td>
      <td>1</td>
      <td>23.0000</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>30.000000</td>
      <td>1</td>
      <td>0</td>
      <td>13.8583</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>0</td>
      <td>30.231444</td>
      <td>0</td>
      <td>0</td>
      <td>7.7250</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>1</td>
      <td>22.000000</td>
      <td>0</td>
      <td>0</td>
      <td>7.7250</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>



🔍 분류 모델링 : 로지스틱 회귀 모델 


```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score 

# 데이터를 학습 데이터셋, 테스트 데이터셋으로 분리합니다. 
x_train, y_train = df_train.loc[:, df_train.columns != 'survived'].values, df_train['survived'].values 
x_test, y_test = df_test.loc[:, df_test.columns != 'survived'].values, df_test['survived'].values 

# 로지스틱 회귀 모델을 학습합니다. 
lr = LogisticRegression(random_state = 0)
lr.fit(x_train, y_train)

# 학습한 모델의 테스트 데이터셋에 대한 예측 결과를 반환합니다. 
y_pred = lr.predict(x_test) 
y_pred_probability = lr.predict_proba(x_test)[:,1]
```

    C:\python_basic\python3.9\lib\site-packages\sklearn\linear_model\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    

🔍 분류 모델 평가하기 


```python
# 테스트 데이터셋에 대한 정확도, 정밀도, 특이도, f1 평가 지표를 각각 출력합니다. 
print("accuracy : %.2f" % accuracy_score(y_test, y_pred))
print("Precision : %.3f" % precision_score(y_test, y_pred))
print("Recall : %.3f" % recall_score(y_test, y_pred))
print("F1 : %.3f" % f1_score(y_test, y_pred))
```

    accuracy : 0.80
    Precision : 0.756
    Recall : 0.673
    F1 : 0.712
    


```python
from sklearn.metrics import confusion_matrix 

# Confusion Matrix를 출력합니다. 
comfmat = confusion_matrix(y_true = y_test, y_pred = y_pred)
print(comfmat)
```

    [[214  32]
     [ 48  99]]
    

🔍 로지스틱 회귀 모델의 AUC 구하기 


```python
from sklearn.metrics import roc_curve, roc_auc_score 

# AUC(Area Under the Curve)를 계산하여 출력합니다. 
false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_probability) 
roc_auc = roc_auc_score(y_test, y_pred_probability)
print("AUC L %.3f" % roc_auc)

# ROC curve를 그래프로 출력합니다. 
plt.rcParams['figure.figsize'] = [5, 4]
plt.plot(false_positive_rate, true_positive_rate, label = 'ROC curve (area = %0.3f)' % roc_auc, color = 'red', linewidth = 4.0)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve of Logistic regression')
plt.legend(loc = "lower right")
```

    AUC L 0.838
    




    <matplotlib.legend.Legend at 0x1ac0c32f400>




    
![png](/assets/images/Book/7/output_20_2.png)
    


🔍 의사결정 나무 모델 

▪ 의사결정 나무 모델은 피처 단위로 조건을 분기하여 정답의 집합을 좁혀나가는 방법입니다. 마치 스무고개놀이에서 정답을 찾아 나가는 과정과 유사하며, 이를 도식화하면 생김새가 '나무 모양'과 같다 하여 붙여진 이름입니다.

🔍 의사결정 나무 


```python
from sklearn.tree import DecisionTreeClassifier 

# 의사결정 나무를 학습하고, 학습한 모델로 테스트 데이터셋에 대한 예측값을 반환합니다. 
dtc = DecisionTreeClassifier()
dtc.fit(x_train, y_train)
y_pred = dtc.predict(x_test)
y_pred_probability = dtc.predict_proba(x_test)[:,1]

# 학습한 모델의 성능을 계산하여 출력합니다. 
print("accuracy : %.2f" % accuracy_score(y_test, y_pred))
print("Precision : %.3f" % precision_score(y_test, y_pred))
print("Recall : %.3f" % recall_score(y_test, y_pred))
print("F1 : %.3f" % f1_score(y_test, y_pred))

# 학습한 모델의 AUC를 계산하여 출력합니다. 
false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_probability)
roc_auc = roc_auc_score(y_test, y_pred_probability) 
print("AUC : %.3f" % roc_auc)

# ROC curve를 그래프로 출력합니다. 
plt.rcParams['figure.figsize'] = [5, 4]
plt.plot(false_positive_rate, true_positive_rate, label = 'ROC curve (area = %0.3f)' % roc_auc, color = 'red', linewidth = 4.0)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve of Logistic regression')
plt.legend(loc = "lower right")
```

    accuracy : 0.76
    Precision : 0.688
    Recall : 0.646
    F1 : 0.667
    AUC : 0.744
    




    <matplotlib.legend.Legend at 0x1ac0c386b80>




    
![png](/assets/images/Book/7/output_22_2.png)
    


## 모델 개선 : 피처 엔지니어링 첫걸음

🔍 분류 모델을 위해 다시 전처리하기 


```python
# 데이터를 다시 불러옵니다. 
df_train = pd.read_csv("./data/titanic_train.csv")
df_test = pd.read_csv("./data/titanic_test.csv")
df_train = df_train.drop(['ticket', 'body', 'home.dest'], axis = 1)
df_test = df_test.drop(['ticket', 'body', 'home.dest'], axis = 1)

# age의 결측값을 평균값으로 대체합니다. 
replace_mean = df_train[df_train['age'] > 0]['age'].mean()
df_train['age'] = df_train['age'].fillna(replace_mean)
df_test['age'] = df_test['age'].fillna(replace_mean)

# embark : 2개의 결측값을 최빈값으로 대체합니다. 
embarked_mode = df_train['embarked'].value_counts().index[0]
df_train['embarked'] = df_train['embarked'].fillna(embarked_mode)
df_test['embarked'] = df_test['embarked'].fillna(embarked_mode)

# 원-핫 인코딩을 위한 통합 데이터 프레임(whole_df)을 생성합니다. 
whole_df = pd.concat([df_train, df_test], ignore_index=True)
train_idx_num = len(df_train)
```

🔍 cabin 피처 활용하기


```python
print(whole_df['cabin'].value_counts()[:10])
```

    cabin
    C23 C25 C27        6
    B57 B59 B63 B66    5
    G6                 5
    F4                 4
    B96 B98            4
    F33                4
    C78                4
    D                  4
    F2                 4
    C22 C26            4
    Name: count, dtype: int64
    

🔍 cabin 피처 활용하기


```python
# 결측 데이터의 경우는 'X'로 대체합니다. 
whole_df['cabin'] = whole_df['cabin'].fillna('X')

# cabin 피처의 첫 번재 알파벳을 추출합니다. 
whole_df['cabin'] = whole_df['cabin'].apply(lambda x : x[0])

# 추출한 알파벳 중, G와 T는 수가 너무 작기 때문에 마찬가지로 'X'로 대체합니다. 
whole_df['cabin'] = whole_df['cabin'].replace({"G" : "X", "T" : "X"})

ax = sns.countplot(x = 'cabin', hue = 'survived', data = whole_df)
plt.show()
```


    
![png](/assets/images/Book/7/output_28_0.png)
    


🔍 name 피처 활용하기 


```python
# 이름에서 호칭을 추출합니다. 
name_grade = whole_df['name'].apply(lambda x : x.split(", ", 1)[1].split(".")[0])
name_grade = name_grade.unique().tolist()
print(name_grade)
```

    ['Miss', 'Mr', 'Master', 'Mrs', 'Dr', 'Mlle', 'Col', 'Rev', 'Ms', 'Mme', 'Sir', 'the Countess', 'Dona', 'Jonkheer', 'Lady', 'Major', 'Don', 'Capt']
    

🔍 name 피처 활용하기 


```python
# 호칭에 따라 사회적 지위(1901년대 기준)를 정의합니다. 
grade_dict = {'A' : ['Rev', 'Col', 'Major', 'Dr', 'Capt', 'Sir'], # 명예직을 나타냅니다. 
              'B' : ['Ms', 'Mme', 'Mrs', 'Dona'],                 # 여성을 나타냅니다. 
              'C' : ['Jonkheer', 'the Countess'],                 # 귀족이나 작위를 나타냅니다. 
              'D' : ['Mr', 'Don'],                                # 남성을 나타냅니다. 
              'E' : ['Master'],                                   # 젊은 남성을 나타냅니다. 
              'F' : ['Miss', 'Mile', 'Lady']}                     # 젊은 여성을 나타냅니다. 

# 정의한 호칭의 기준에 따라 A ~ F의 문자로 name 피처를 다시 정의하는 함수입니다. 
def give_grade(x) : 
    grade = x.split(", ", 1)[1].split(".")[0]
    for key, value in grade_dict.items() : 
        for title in value : 
            if grade == title : 
                return key 
    return 'G'

# 위의 함수를 적용하여 name 피처를 새롭게 정의합니다. 
whole_df['name'] = whole_df['name'].apply(lambda x : give_grade(x))
print(whole_df['name'].value_counts())
```

    name
    D    758
    F    261
    B    201
    E     61
    A     24
    G      2
    C      2
    Name: count, dtype: int64
    

🔍 원-핫 인코딩 


```python
# 판다스 패키지를 이용한 원-핫 인코딩을 수행합니다. 
whole_df_encoded = pd.get_dummies(whole_df)
df_train = whole_df_encoded[:train_idx_num]
df_test = whole_df_encoded[train_idx_num:]
df_train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pclass</th>
      <th>survived</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>name_A</th>
      <th>name_B</th>
      <th>name_C</th>
      <th>name_D</th>
      <th>...</th>
      <th>cabin_A</th>
      <th>cabin_B</th>
      <th>cabin_C</th>
      <th>cabin_D</th>
      <th>cabin_E</th>
      <th>cabin_F</th>
      <th>cabin_X</th>
      <th>embarked_C</th>
      <th>embarked_Q</th>
      <th>embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>1</td>
      <td>13.000000</td>
      <td>0</td>
      <td>1</td>
      <td>19.5000</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>4.000000</td>
      <td>1</td>
      <td>1</td>
      <td>23.0000</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>30.000000</td>
      <td>1</td>
      <td>0</td>
      <td>13.8583</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>0</td>
      <td>30.231444</td>
      <td>0</td>
      <td>0</td>
      <td>7.7250</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>1</td>
      <td>22.000000</td>
      <td>0</td>
      <td>0</td>
      <td>7.7250</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div>



🔍 피처 엔지니어링이 완료된 데이터셋 학습 


```python
# 데이터를 학습 데이터셋, 테스트 데이터셋으로 분리합니다. 
x_train, y_train = df_train.loc[:, df_train.columns != 'survived'].values, df_train['survived'].values 
x_test, y_test = df_test.loc[:, df_test.columns != 'survived'].values, df_test['survived'].values 

# 로지스틱 회귀 모델을 학습합니다. 
lr = LogisticRegression(random_state = 0)
lr.fit(x_train, y_train)

# 학습된 모델의 테스트 데이터셋에 대한 예측 결과를 반환합니다. 
y_pred = lr.predict(x_test)
y_pred_probability = lr.predict_proba(x_test)[:, 1]

# 테스트 데이터셋에 대한 accuracy, precision, recall, f1 평가 지표를 각각 출력합니다. 
print("accuracy : %.2f" % accuracy_score(y_test, y_pred))
print("Precision : %.3f" % precision_score(y_test, y_pred))
print("Recall : %.3f" % recall_score(y_test, y_pred))
print("F1 : %.3f" % f1_score(y_test, y_pred))  # AUC (Area Under the Curve) & ROC curve

# AUC (Area Under the Curve)를 계산하여 출력합니다. 
false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_probability) 
roc_auc = roc_auc_score(y_test, y_pred_probability) 
print("AUC L %.3f" % roc_auc)

# ROC curve를 그래프로 출력합니다. 
plt.rcParams['figure.figsize'] = [5, 4]
plt.plot(false_positive_rate, true_positive_rate, label = 'ROC curve (area = %0.3f)' % roc_auc, color = 'red', linewidth = 4.0) 
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve of Logistic regression')
plt.legend(loc = "lower right")
```

    accuracy : 0.80
    Precision : 0.739
    Recall : 0.714
    F1 : 0.727
    AUC L 0.852
    

    C:\python_basic\python3.9\lib\site-packages\sklearn\linear_model\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    




    <matplotlib.legend.Legend at 0x1ac0c606f10>




    
![png](/assets/images/Book/7/output_36_3.png)
    


🔍 피처 영향력 살펴보기 


```python
# 예측 대상인 survived 피처를 제외한 모든 피처를 리스트로 반환합니다. (그래프의 y축)
cols = df_train.columns.tolist()
cols.remove('survived')
y_pos = np.arange(len(cols))

# 각 피처별 회귀 분석 계스를 그래프의 x축으로 하여 피처 영향력 그래프를 출력합니다. 
plt.rcParams['figure.figsize'] = [10, 8]
fig, ax = plt.subplots()
ax.barh(y_pos, lr.coef_[0], align = 'center', color = 'green', ecolor = 'black')
ax.set_yticks(y_pos)
ax.set_yticklabels(cols)
ax.invert_yaxis()
ax.set_xlabel('Coef')
ax.set_title("Each Feature's Coef")

plt.show()
```


    
![png](/assets/images/Book/7/output_38_0.png)
    


## 평가 : 모델 검증하기

🔍 K-fold 교차 검증 

▪ 학습용 데이터셋과 테스트용 데이터셋을 나눌 때, 두 데이터는 불균등하게 나눠졌을 가능성이 있습니다. k-fold 교차 검증은 이 가능성을 낮춰주는 방법으로, 데이터를 k개의 fold로 나누어 k-1개는 학습 데이터, 나머지 1개는 테스트 데이터로 사용하는 방법입니다. 아래의 그림은 k = 5인 k-fold 교차 검증을 나타낸 것입니다. 

![png](/assets/images/Book/7/1.png)

▪ 이 그림에서는 총 5개의 학습을 통해 모델의 분할 검증을 5회 반복하는 것입니다. 만약 이 k번의 검증 과정에서 테스트 점수 간의 차이가 크지 않다면 모델은 과적합이 일어났을 가능성이 낮은 것입니다. 

🔍 K-fold 교차 검증 수행하기 


```python
from sklearn.model_selection import KFold 

# K-fold 교차 검증의 k를 5로 설정합니다. 
k = 5
cv = KFold(k, shuffle = True, random_state = 0)
auc_history = []

# K-fold를 5번의 분할 학습으로 반복합니다. 
for i, (train_data_row, test_data_row) in enumerate(cv.split(whole_df_encoded)) : 

    # 5개로 분할된 fold 중 4개를 학습 데이터셋, 1개를 테스트 데이터셋으로 지정합니다. 매 반복시마다 테스트 데이터셋은 변경됩니다. 
    df_train = whole_df_encoded.iloc[train_data_row]
    df_test = whole_df_encoded.iloc[test_data_row]

    # survived 피처를 y, 나머지 피처들을 x 데이터로 지정합니다. 
    splited_x_train, splited_y_train = df_train.loc[:, df_train.columns != 'survived'].values, df_train['survived'].values 
    splited_x_test, splited_y_test = df_test.loc[:, df_test.columns != 'survived'].values, df_test['survived'].values 

    # 주어진 데이터로 로지스틱 회귀 모델을 학습합니다. 
    lr = LogisticRegression(random_state = 0)
    lr.fit(splited_x_train, splited_y_train)
    y_pred = lr.predict(splited_x_test)
    y_pred_probability = lr.predict_proba(splited_x_test)[:, 1]

    # 테스트 데이터셋의 AUC를 계산하여 auc_history에 저장합니다. 
    false_positive_rate, true_positive_rate, thresholds = roc_curve(splited_y_test, y_pred_probability) 
    roc_auc = roc_auc_score(splited_y_test, y_pred_probability)
    auc_history.append(roc_auc)

# auc_history에 저장된 다섯 번의 학습 결과(AUC)를 그래프로 출력합니다. 
plt.xlabel("Each k-fold")
plt.ylabel("AUC of splited test data") 
plt.plot(range(1, k + 1), auc_history) # baseline 
```

    C:\python_basic\python3.9\lib\site-packages\sklearn\linear_model\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    C:\python_basic\python3.9\lib\site-packages\sklearn\linear_model\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    C:\python_basic\python3.9\lib\site-packages\sklearn\linear_model\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    C:\python_basic\python3.9\lib\site-packages\sklearn\linear_model\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    C:\python_basic\python3.9\lib\site-packages\sklearn\linear_model\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    




    [<matplotlib.lines.Line2D at 0x1ac0c6ebeb0>]




    
![png](/assets/images/Book/7/output_40_2.png)
    


🔍 학습 곡선 분석하기 


```python
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
import numpy as np

# 학습 곡선 데이터 계산
train_sizes, train_scores, test_scores = learning_curve(
    estimator=lr,         # 학습할 모델
    X=x_train,            # 훈련 데이터
    y=y_train,            # 정답 레이블
    train_sizes=np.linspace(0.1, 1.0, 5),  # 학습 데이터 비율 (10%~100%)
    cv=5,                 # 5-fold cross-validation
    scoring='accuracy',   # 정확도로 성능 측정
    n_jobs=-1             # 모든 CPU 코어 사용
)

# 평균과 표준편차 계산
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

# 그래프 그리기
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.1, color="r")

plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")
plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.1, color="g")

plt.title("Learning Curve")
plt.xlabel("Training Examples")
plt.ylabel("Score")
plt.legend(loc="best")
plt.grid()
plt.show()
```


    
![png](/assets/images/Book/7/output_42_0.png)
    


## 표로 정리하는 데이터 분석 

|주요 키워드|핵심 내용|설명|
|-|-|-|
|로지스틱 회귀모델|로지스틱 회귀를 이용한 분류 모델|모델의 결과은 0 ~ 1 사이의 확률값을 0, 1로 분류하는 방법입니다. 피처 영향력을 분석하기 용이하다는 장점을 가지고 있습니다.|
|결측값 처리|모델 학습의 과정에서 결측값을 처리하는 방법|결측값을 처리하는 방법은 결측값을 삭제해버리는 방법, 그리고 임의의 수치로 채워 넣는 방법이 존재합니다.|
|분류 모델의 평가|Confusion Matrix를 기반으로 한 분류 모델의 평가지표|Confusion Matrix를 통해 계산된 Accuracy, Precision, Recall, F1-score, AUC 등의 수치로 분류 보델을 평가합니다.|
|분류 모델의 개선|피처 엔지니어링|피처 엔제니어링이란 모델에 사용할 피처를 가공하는 분석 작업을 의미합니다.|
|분류 모델의 검증|모델의 괒거합을 검증하는 방법|분류 모델의 성능을 검증하기 위해서는 모델의 과적합 여부를 판단합니다. 그 방법으로 K-fold 교차 검증, 학습 곡선의 관찰 등의 방법이 있습니다.|
