---
title: "[Dacon 기업 성공 예측] Catboost Feature Engineering"
categories: Model_Training&Tuning
tags: [python, Dacon, Catboost, Feature_Engineering]
---

# Dacon 기업 성공 예측 Feature Engineering

---

# 기본 Feature

```python 
train = pd.read_csv('Dacon_data/train.csv')
test = pd.read_csv('Dacon_data/test.csv')
sample_submission = pd.read_csv('Dacon_data/sample_submission.csv')
```

```python 
train.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 4376 entries, 0 to 4375
    Data columns (total 14 columns):
    #   Column          Non-Null Count  Dtype  
    ---  ------          --------------  -----  
    0   ID              4376 non-null   object 
    1   설립연도            4376 non-null   int64  
    2   국가              4376 non-null   object 
    3   분야              3519 non-null   object 
    4   투자단계            4376 non-null   object 
    5   직원 수            4202 non-null   float64
    6   인수여부            4376 non-null   object 
    7   상장여부            4376 non-null   object 
    8   고객수(백만명)        3056 non-null   float64
    9   총 투자금(억원)       4376 non-null   float64
    10  연매출(억원)         4376 non-null   float64
    11  SNS 팔로워 수(백만명)  4376 non-null   float64
    12  기업가치(백억원)       3156 non-null   object 
    13  성공확률            4376 non-null   float64
    dtypes: float64(6), int64(1), object(7)
    memory usage: 478.8+ KB

```python
train = train.drop(columns=['ID'], axis = 1)
test = test.drop(columns=['ID'], axis = 1)

# 기준 연도 설정
CURRENT_YEAR = 2025

# 기업 나이 생성
train['기업나이'] = CURRENT_YEAR - train['설립연도']
test['기업나이'] = CURRENT_YEAR - test['설립연도']

# 기존 컬럼 제거
train = train.drop(columns=['설립연도'])
test = test.drop(columns=['설립연도'])

# 수치형 처리
numeric_features = ['기업나이', '직원 수', '고객수(백만명)', '총 투자금(억원)', '연매출(억원)', 'SNS 팔로워 수(백만명)']

# 이진형 처리
bool_features = ['인수여부', '상장여부']
bool_map = {'Yes': 1, 'No': 0}
for col in bool_features :
    train[col] = train[col].map(bool_map)
    test[col] = test[col].map(bool_map)

# 범주형 처리
category_features = ['국가', '분야', '투자단계', '기업가치(백억원)']
encoders = {}

for feature in category_features:
    encoders[feature] = LabelEncoder()
    train[feature] = train[feature].fillna('Missing')
    test[feature] = test[feature].fillna('Missing')
    train[feature] = encoders[feature].fit_transform(train[feature])
    test[feature] = encoders[feature].transform(test[feature])
    
# 고객수(백만명): 전체 평균으로 채우기
customer_mean = train['고객수(백만명)'].mean()
train['고객수(백만명)'] = train['고객수(백만명)'].fillna(customer_mean)
test['고객수(백만명)'] = test['고객수(백만명)'].fillna(customer_mean)

# 직원 수: 국가별 평균으로 채우기
train['직원 수'] = train.groupby('국가')['직원 수'].transform(lambda x: x.fillna(x.mean()))

# test 데이터는 국가별 평균을 train에서 가져와서 채우기
country_mean = train.groupby('국가')['직원 수'].mean()
test['직원 수'] = test.apply(
    lambda row: country_mean[row['국가']] if pd.isnull(row['직원 수']) else row['직원 수'], axis=1
)

# 컬럼명의 띄어쓰기를 언더바로 대체
train.columns = train.columns.str.replace(" ", "_")
test.columns = test.columns.str.replace(" ", "_")
```

```
    ✅ ID 컬럼 삭제 
        ◾ ID는 단순히 각 샘플을 구분해주는 고유 번호일 뿐, 예측 모델에 도움이 되는 정보는 아닙니다. 
        ◾ 오히려 학습에 불필요한 잡음이 될 수 있기 때문에 제거합니다. 
    ✅ 데이터를 전처리할 때는 변수의 성격에 따라 다른 방식으로 다뤄야 하기 때문에 features를 통해 
        세 가지로 나눕니다. 
        ◾ 수치형 변수 (numeric_features) : 평균이나 표준편차 등을 활용한 처리가 가능
        ◾ 이진형 변수 (bool_features) : Yes, No → 1 / 0 으로 변환
        ◾ 범주형 변수 (category_features) : 머신러닝 모델이 이해할 수 있게 숫자로 변환 필요
    ✅ encoders = {}
        ◾ 여러 개의 범주형 변수를 처리할 건데, 각각의 변수마다 LabelEncoder 객체를 따로 만들어서 
            추후에 필요할 때 재사용할 수 있도록 딕셔너리에 저장합니다. 
    ✅ null -> Missing 
        ◾ category_features 의 null값을 Missing으로 채워줌으로서 누락된 데이터도 하나의 범주로 간주해서 
            모델이 처리할 수 있게 합니다. 
    ✅ 직원수 : null값을 국가별 평균으로 처리합니다. 
    ✅ 고객수 : null값을 전체 평균으로 처리합니다. 
    ✅ train을 기준으로 test 결측치를 채우는 이유는 데이터 누수를 막기 위해서 입니다. 
    ✅ 컬럼명의 띄어쓰기를 언더바로 대체하여 모델 학습을 더 안정적으로 진행할 수 있습니다. 
```

```python 
train.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 4376 entries, 0 to 4375
    Data columns (total 13 columns):
    #   Column          Non-Null Count  Dtype  
    ---  ------          --------------  -----  
    0   국가              4376 non-null   int32  
    1   분야              4376 non-null   int32  
    2   투자단계            4376 non-null   int32  
    3   직원_수            4376 non-null   float64
    4   인수여부            4376 non-null   int64  
    5   상장여부            4376 non-null   int64  
    6   고객수(백만명)        4376 non-null   float64
    7   총_투자금(억원)       4376 non-null   float64
    8   연매출(억원)         4376 non-null   float64
    9   SNS_팔로워_수(백만명)  4376 non-null   float64
    10  기업가치(백억원)       4376 non-null   int32  
    11  성공확률            4376 non-null   float64
    12  기업나이            4376 non-null   int64  
    dtypes: float64(6), int32(4), int64(3)
    memory usage: 376.2 KB


# 1차 Feature Engineering 

```python 
# 투자 대비 매출
train['투자 대비 매출'] = train['연매출(억원)'] / (train['총 투자금(억원)'] + 1)
test['투자 대비 매출'] = test['연매출(억원)'] / (test['총 투자금(억원)'] + 1)

# 1인당 매출
train['1인당 매출'] = train['연매출(억원)'] / (train['직원 수'] + 1)
test['1인당 매출'] = test['연매출(억원)'] / (test['직원 수'] + 1)

# 1인당 투자금
train['1인당 투자금'] = train['총 투자금(억원)'] / (train['직원 수'] + 1)
test['1인당 투자금'] = test['총 투자금(억원)'] / (test['직원 수'] + 1)

# 1인당 고객 수
train['1인당 고객'] = train['고객수(백만명)'] / (train['직원 수'] + 1)
test['1인당 고객'] = test['고객수(백만명)'] / (test['직원 수'] + 1)

# 고객당 연매출
train['고객당 연매출'] = train['연매출(억원)'] / (train['고객수(백만명)'] + 1)
test['고객당 연매출'] = test['연매출(억원)'] / (test['고객수(백만명)'] + 1)

# SNS 팔로워 대비 연매출
train['SNS 팔로워 대비 매출'] = train['연매출(억원)'] / (train['SNS 팔로워 수(백만명)'] + 1)
test['SNS 팔로워 대비 매출'] = test['연매출(억원)'] / (test['SNS 팔로워 수(백만명)'] + 1)

# 기업가치 대비 연매출
train['가치 대비 매출'] = train['연매출(억원)'] / (train['기업가치(백억원)'] + 1)
test['가치 대비 매출'] = test['연매출(억원)'] / (test['기업가치(백억원)'] + 1)

# 로그 변환: 왜곡이 심한 컬럼
for col in ['연매출(억원)', '총 투자금(억원)', '직원 수', '고객수(백만명)', 'SNS 팔로워 수(백만명)']:
    train[f'log_{col}'] = np.log1p(train[col])
    test[f'log_{col}'] = np.log1p(test[col])
    
train = train.drop(columns = ['연매출(억원)', '총 투자금(억원)', '직원 수', '고객수(백만명)', 'SNS 팔로워 수(백만명)'])
test = test.drop(columns = ['연매출(억원)', '총 투자금(억원)', '직원 수', '고객수(백만명)', 'SNS 팔로워 수(백만명)'])
```

``` 
    ✅ 비율 기반 피처를 새로 만들어 모델이 더 잘 학습할 수 있도록 도와줍니다. 
        ◾ 투자 대비 매출 : 투자 효율성 지표
        ◾ 1인당 매출 : 생산성 지표 
        ◾ 1인당 투자금 : 기업의 투자 여력 파악 
        ◾ 1인당 고객 수 : 영업 / 서비스 부하 정도 파악
        ◾ 고객당 연매출 : 고객 가치 측정
        ◾ SNS 팔로워 대비 매출 : 브랜드 파워 실질성 확인 
        ◾ 기업 가치 대비 매출 : 기업의 실질 수익성 판단 
    ✅ 로그 변환 (log1p 사용)
        ◾ 보통 분포가 심하게 한쪽으로 왜곡되어 있습니다. 
        ◾ 이런 심한 스케일 차이는 머신러닝 모델이 제대로 학습하기 어렵게 만듭니다. 
        ◾ 따라서 로그 변환을 통해 데이터를 더 퍼지지 않게 만들 수 있고, 
            모델이 수치들을 더 고르게 보고 학습할 수 있습니다. 
        ◾ np.logi1p(x)는 log(x + 1)을 계산하는데, x가 0이어도 에러없이 처리할 수 있어 안정성이 좋습니다. 
```

```python 
train.columns 
```

    Index(['국가', '분야', '투자단계', '인수여부', '상장여부', '기업가치(백억원)', '성공확률', '기업나이',
       '투자_대비_매출', '1인당_매출', '1인당_투자금', '1인당_고객', '고객당_연매출', 'SNS_팔로워_대비_매출',
       '가치_대비_매출', 'log_연매출(억원)', 'log_총_투자금(억원)', 'log_직원_수', 'log_고객수(백만명)',
       'log_SNS_팔로워_수(백만명)'],
      dtype='object')

# 2차 Feature Engineering 

```python
import matplotlib.pyplot as plt
import matplotlib

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

import matplotlib.pyplot as plt

# ✅ 예시: 첫 번째 모델 기준으로 Feature Importance 시각화
model = models[0]

# 중요도 가져오기
importances = model.get_feature_importance()
feature_names = X.columns

# 중요도와 이름을 함께 정리
fi_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# ✅ 상위 20개 시각화
plt.figure(figsize=(10, 8))
plt.barh(fi_df['Feature'][:20][::-1], fi_df['Importance'][:20][::-1])
plt.xlabel("Importance")
plt.title("Top 20 Feature Importances (Fold 1)")
plt.tight_layout()
plt.show()
```

![png](/assets/images/Model_Training/2/1.png)

    ✅ 모델링을 하는 도중, 상장여부, 인수여부의 중요도가 거의 0에 가까워 
        모델 학습에 큰 기여를 하지 않는 것으로 판단되었습니다. 

```python
train = train.drop(columns = ["인수여부", "상장여부"])
test = test.drop(columns = ["인수여부", "상장여부"])
```

```python
train.columns 
```

    Index(['국가', '분야', '투자단계', '기업가치(백억원)', '성공확률', '기업나이', '투자_대비_매출', '1인당_매출',
       '1인당_투자금', '1인당_고객', '고객당_연매출', 'SNS_팔로워_대비_매출', '가치_대비_매출',
       'log_연매출(억원)', 'log_총_투자금(억원)', 'log_직원_수', 'log_고객수(백만명)',
       'log_SNS_팔로워_수(백만명)'],
      dtype='object')

# Result 

📌 기본 Feature 제출 점수 : 0.22132793

📌 1차 Feature Engineering 제출 점수 : 0.2208997853

📌 2차 Feature Engineering 제출 점수 : 0.2148252683

    ✅ Feature Engineering을 통해 모델의 성능을 향상시킬 수 있었습니다. 
    ✅ 하지만 모두 같은 조건은 아니기 때문에 Feature Engineering만으로 성능을 향상시켰다고 보기 어렵습니다. 
    ✅ 그러나 지속적으로 중요도를 확인하고 Feature를 조정하는 과정을 경험했습니다. 

