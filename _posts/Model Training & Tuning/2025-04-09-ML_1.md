---
title: "[Dacon 기업 성공 예측] LGBM으로 베이스라인 모델 만들기 & 전처리 실험 기록"
categories: Model_Training&Tuning
tags: [python, LGBM, KFold, Dacon, Ensemble]
---

# Dacon 기업 성공 예측

# Import

---

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import KFold
from lightgbm import LGBMRegressor, early_stopping, log_evaluation
```

---

◾ pandas

    ▪ 데이터 불러오기 및 다루기 위한 필수 라이브러리 
    ▪ csv 파일 불러오기, 결측치 처리, 컬럼 선택 등 기본적인 데이터 핸들링에 사용됨 
    
◾ numpy 

    ▪ 수치 계산에 특화된 라이브러리 
    ▪ 평균, 배열 연산, 예측값 평균 계산 등에 사용됨
        ▫ 예 - np.mean(perdictions, axis = 0)

◾ from sklearn.preprocessing import LabelEncoder

    ▪ 범주형 데이터를 숫자로 바꿔주는 인코더
    ▪ 머신러닝 모델이 문자 대신 숫자를 인식할 수 있도록 처리 
        ▫ 예 - 국가, 투자단계 등을 숫자로 변환
        
◾ from sklearn.model_selection import KFold

    ▪ K-Fold 교차검증을 위한 도구 
    ▪ 데이터를 여러 개의 Fold로 나누어 모델을 평가할 때 사용됨
        ▫ 예 - 5개의 Fold로 나누어 학습 / 검증 반복
        
◾ from lightgbm imort LGBMRegressor, early_stopping, log_evaluation

    ▪ LightGBM 모델과 학습 제어 도구
        ▫ LGBMRegressor : 빠르고 성능 좋은 회귀 모델 (트리 기반)
        ▫ early_stopping : 성능이 더 이상 좋아지지 않으면 학습 멈추기 
        ▫ log_evaluation : 학습 로그를 주기적으로 출력하기 위한 콜백 

---

```python
import pandas as pd
import numpy as np
import sklearn
import lightgbm
import sys

print("라이브러리 버전 목록")

print("Python:", sys.version)
print("pandas:", pd.__version__)
print("numpy:", np.__version__)
print("scikit-learn:", sklearn.__version__)
print("lightgbm:", lightgbm.__version__)
```

---

    라이브러리 버전 목록
    Python: 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)]
    pandas: 2.2.3
    numpy: 2.2.4
    scikit-learn: 1.6.1
    lightgbm: 4.6.0
    

# Data Load

✅ 데이터 로드

---

```python
train = pd.read_csv('Dacon_data/train.csv')
test = pd.read_csv('Dacon_data/test.csv')
sample_submission = pd.read_csv('Dacon_data/sample_submission.csv')
```

---

✅ train, test columns에서 object인 것들의 unique()값 확인하기

✅ train, test columns에서 null값이 존재하는 columns 확인하기

---

```python
# train 데이터 object 컬럼 고유값 확인
for col in train.select_dtypes('object').columns:
    print(f"📌[Train] {col} :", train[col].unique())

# test 데이터 object 컬럼 고유값 확인
for col in test.select_dtypes('object').columns:
    print(f"🔍[Test] {col} :", test[col].unique())

# 결측치 확인
print("📌 [Train] Null 체크")
print(train.isnull().sum()[train.isnull().sum() > 0])

print("🔍 [Test] Null 체크")
print(test.isnull().sum()[test.isnull().sum() > 0])
```

---

    📌[Train] ID : ['TRAIN_0000' 'TRAIN_0001' 'TRAIN_0002' ... 'TRAIN_4373' 'TRAIN_4374'
     'TRAIN_4375']
    📌[Train] 국가 : ['CT005' 'CT006' 'CT007' 'CT002' 'CT008' 'CT010' 'CT001' 'CT009' 'CT003'
     'CT004']
    📌[Train] 분야 : ['이커머스' '핀테크' '기술' nan '에듀테크' '게임' '헬스케어' '물류' '푸드테크' 'AI' '에너지']
    📌[Train] 투자단계 : ['Series A' 'Seed' 'Series C' 'Series B' 'IPO']
    📌[Train] 인수여부 : ['No' 'Yes']
    📌[Train] 상장여부 : ['No' 'Yes']
    📌[Train] 기업가치(백억원) : [nan '2500-3500' '3500-4500' '1500-2500' '4500-6000' '6000이상']
    🔍[Test] ID : ['TEST_0000' 'TEST_0001' 'TEST_0002' ... 'TEST_1752' 'TEST_1753'
     'TEST_1754']
    🔍[Test] 국가 : ['CT010' 'CT001' 'CT006' 'CT003' 'CT005' 'CT009' 'CT004' 'CT007' 'CT002'
     'CT008']
    🔍[Test] 분야 : ['핀테크' '푸드테크' '에듀테크' '에너지' nan '게임' '물류' '이커머스' 'AI' '헬스케어' '기술']
    🔍[Test] 투자단계 : ['Series C' 'IPO' 'Seed' 'Series A' 'Series B']
    🔍[Test] 인수여부 : ['No' 'Yes']
    🔍[Test] 상장여부 : ['Yes' 'No']
    🔍[Test] 기업가치(백억원) : ['1500-2500' nan '6000이상' '3500-4500' '4500-6000' '2500-3500']
    📌 [Train] Null 체크
    분야            857
    직원 수          174
    고객수(백만명)     1320
    기업가치(백억원)    1220
    dtype: int64
    🔍 [Test] Null 체크
    분야           354
    직원 수          76
    고객수(백만명)     547
    기업가치(백억원)    487
    dtype: int64
    

◾ 모델에 넣기 전, Object Type들을 처리해야 하므로 각 컬럼이 어떤 값을 가지는지 미리 확인해두는 작업이 필요합니다. 

◾ 또한 모델 학습에 영향을 줄 수 있는 결측값을 먼저 찾아보고 채우거나 전처리할 전략을 세우기 위함입니다. 

◾ train과 test 모두 동일한 컬럼에 결측치가 존재하고 있었고, object 타입의 컬럼도 동일한 구조를 가지고 있음을 확인할 수 있었습니다. 

    ▪ 사전 확인은 전처리 시 일관된 처리를 가능하게 해주며, 예측 모델의 안정성에도 긍정적인 영향을 줍니다. 

# Data Preprocessing

✅ 설립연도 → 기업나이로 변환

---

```python
# 기준 연도 설정
CURRENT_YEAR = 2025

# 기업 나이 생성
train['기업나이'] = CURRENT_YEAR - train['설립연도']
test['기업나이'] = CURRENT_YEAR - test['설립연도']

# 기존 컬럼 제거
train = train.drop(columns=['설립연도'])
test = test.drop(columns=['설립연도'])
```

---

◾ 머신러닝 모델 입장에서는 1999, 2015, 2020 같은 절대 연도 숫자는 의미가 잘 전달되지 않습니다. 

◾ 대신 '설립된지 5년 된 기업' 처럼 상대적인 수치를 주면 모델이 시간 흐름의 영향을 더 잘 파악할 수 있습니다. 

◾ 그래서 기준 연도를 설정하고, 기업 나이를 생성하고 기존의 컬럼을 제거하였습니다. 

---

```python
train = train.drop(columns=['ID'], axis = 1)
test = test.drop(columns=['ID'], axis = 1)

# 수치형 처리
numeric_features = ['기업나이', '직원 수', '고객수(백만명)', '총 투자금(억원)', '연매출(억원)', 'SNS 팔로워 수(백만명)']

# 이진형 처리
bool_features = ['인수여부', '상장여부']
bool_map = {'Yes': 1, 'No': 0}
for col in bool_features :
    train[col] = train[col].map(bool_map)
    test[col] = test[col].map(bool_map)

# 범주형 처리
category_features = ['국가', '분야', '투자단계', '기업가치(백억원)']
encoders = {}

for feature in category_features:
    encoders[feature] = LabelEncoder()
    train[feature] = train[feature].fillna('Missing')
    test[feature] = test[feature].fillna('Missing')
    train[feature] = encoders[feature].fit_transform(train[feature])
    test[feature] = encoders[feature].transform(test[feature])
    
# 고객수(백만명): 전체 평균으로 채우기
customer_mean = train['고객수(백만명)'].mean()
train['고객수(백만명)'] = train['고객수(백만명)'].fillna(customer_mean)
test['고객수(백만명)'] = test['고객수(백만명)'].fillna(customer_mean)

# 직원 수: 국가별 평균으로 채우기
train['직원 수'] = train.groupby('국가')['직원 수'].transform(lambda x: x.fillna(x.mean()))

# test 데이터는 국가별 평균을 train에서 가져와서 채우기
country_mean = train.groupby('국가')['직원 수'].mean()
test['직원 수'] = test.apply(
    lambda row: country_mean[row['국가']] if pd.isnull(row['직원 수']) else row['직원 수'], axis=1
)

# 컬럼명의 띄어쓰기를 언더바로 대체
train.columns = train.columns.str.replace(" ", "_")
test.columns = test.columns.str.replace(" ", "_")
```

---

```python
train = train.drop(columns=['ID'], axis = 1)
test = test.drop(columns=['ID'], axis = 1)
```

◾ ID는 단순히 각 샘플을 구분해주는 고유 번호일 뿐, 예측 모델이 도움이 되는 정보는 아닙니다. 

◾ 오히려 학습에 불필요한 잡음이 될 수 있기 때문에 제거합니다. 

```python
numeric_features = [...]
bool_features = [...]
category_features = [...]
```

◾ 데이터를 전처리할 때는 변수의 성격에 따라 다른 방식으로 다뤄야 하기 때문에 features를 통해 세 가지로 나눕니다. 
    
    ▪ 수치형 변수 (numeric_features) : 평균이나 표준편차 등을 활용한 처리가 가능
    ▪ 이진형 변수 (bool_features) : Yes, No → 1 / 0 으로 변환
    ▪ 범주형 변수 (category_features) : 머신러닝 모델이 이해할 수 있게 숫자로 변환 필요
        
```python
encoders = {}
```

◾ 여러 개의 범주형 변수를 처리할 건데, 각각의 변수마다 LabelEncoder 객체를 따로 만들어서 추후에 필요할 때 재사용할 수 있도록 딕셔너리에 저장합니다. 

```python
train[feature] = train[feature].fillna('Missing')
test[feature] = test[feature].fillna('Missing')
```

◾ 범주형 변수는 평균이나 중앙값으로 채우기 어렵기 때문에 'Missing'이라는 하나의 새로운 값으로 채워주는 것이 일반적입니다. 

◾ 이렇게 하면 누락된 데이터도 하나의 범주로 간주해서 모델이 처리할 수 있게 됩니다. 

```python 
train[feature] = encoders[feature].fit_transform(train[feature])
test[feature] = encoders[feature].transform(test[feature])
```

◾ fit()은 범주형 값들을 숫자로 매핑하는 기준(사전)을 학습합니다.

◾ transform()은 그 기준에 따라 실제 데이터를 숫자로 바꿔줍니다. 

◾ fit_transform()은 이 두가지 기능을 한번에 수행하는 역할을 수행합니다. 

✅ train[feature]에서는 fit_transform을 사용하고 test[feature]에서는 transform을 사용하는 이유는 다음과 같습니다. 

    ▪ test에만 있는 값을 새롭게 학습하면 train과 다른 기준이 생기기 때문에 모델 입장에서 헷갈리게 됩니다.
    ▪ 따라서 test에서는 항상 train에서 배운 기준 그대로 transform만 수행하게 됩니다. 
    
✅ 고객수는 전체 평균으로, 직원수는 국가별 평균으로 나눈 이유는 다음과 같습니다. 

    ▪ 고객수(백만명)은 전 세계적으로 고르게 분포된 지표이기 때문에 전체 평균으로 대체했습니다. 
    ▪ 직원수는 국가마다 규모나 채용 방식이 다르기 때문에 국가별 평균으로 대체했습니다. 
    
```python
country_mean = train.groupby('국가')['직원 수'].mean()
test['직원 수'] = test.apply(
    lambda row: country_mean[row['국가']] if pd.isnull(row['직원 수']) else row['직원 수'], axis=1
)
```

◾ groupby('국가')['직원수'].mean() : 국가별 평균 직원 수 계산 

◾ apply() : test 데이터의 각 행을 순회하면서 

◾ 직원 수가 결측이면 해당 국가의 평균값으로 채워주고 

◾ 결측이 아니라면 원래 값을 그대로 유지합니다. 

✅ test의 직원 수 결측치를 test 자체의 평균이 아닌 train에서 계산한 국가별 평균으로 채우는 것에 대한 이유는 다음과 같습니다. 

    ▪ 데이터 누수(Data Leakage)를 막기 위해서입니다. 
    ▪ Data Leakange란? 
        ▫ 모델 학습 과정에서 미래 정보(test의 통계)가 섞여 들어가는 것을 의미합니다. 
        ▫ 이러면 모델이 실제로는 모르는 정보를 몰래 본 셈이 돼서, 훈련 땐 잘맞췄는데 실제로는 못맞추는 모델이 될 가능성이 높아집니다. 
        ▫ 따라서 실제 예측 상황과 동일하게 모델을 평가할 수 있습니다.
        ▫ 또한 성능이 부풀려지지 않고 정직한 평가가 가능합니다. 
        
```python
train.columns = train.columns.str.replace(" ", "_")
test.columns = test.columns.str.replace(" ", "_")
```

◾ 이후 모델을 실행하는 과정에서 columns에 띄어쓰기가 있으면 파싱할 때 문제가 생길 수 있기 때문에 미리 공백을 제거합니다. 

# LGBMRegressor로 K-Fold 교차검증 수행

---

```python
# ✅ Feature, Target 정의
X = train.drop(columns=['성공확률'])
y = train['성공확률']

# ✅ 모델 저장용 리스트
models = []
cv_scores = []

# ✅ KFold 설정
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# ✅ 모델 학습
for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):
    print(f"\n🔁 Fold {fold+1}/5")

    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]

    model = LGBMRegressor(
        n_estimators=1000,
        learning_rate=0.05,
        random_state=42
    )

    model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        callbacks=[
            early_stopping(stopping_rounds=50),
            log_evaluation(period=100)
        ]
    )

    models.append(model)
    score = model.best_score_['valid_0']['l2']
    cv_scores.append(score)
```

---
    
    🔁 Fold 1/5
    [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000270 seconds.
    You can set `force_row_wise=true` to remove the overhead.
    And if memory is not enough, you can set `force_col_wise=true`.
    [LightGBM] [Info] Total Bins 1165
    [LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 12
    [LightGBM] [Info] Start training from score 0.534486
    Training until validation scores don't improve for 50 rounds
    Early stopping, best iteration is:
    [1]	valid_0's l2: 0.0579823
    
    🔁 Fold 2/5
    [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
    You can set `force_col_wise=true` to remove the overhead.
    [LightGBM] [Info] Total Bins 1165
    [LightGBM] [Info] Number of data points in the train set: 3501, number of used features: 12
    [LightGBM] [Info] Start training from score 0.537104
    Training until validation scores don't improve for 50 rounds
    Early stopping, best iteration is:
    [11]	valid_0's l2: 0.0590495
    
    🔁 Fold 3/5
    [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.
    You can set `force_row_wise=true` to remove the overhead.
    And if memory is not enough, you can set `force_col_wise=true`.
    [LightGBM] [Info] Total Bins 1164
    [LightGBM] [Info] Number of data points in the train set: 3501, number of used features: 12
    [LightGBM] [Info] Start training from score 0.537332
    Training until validation scores don't improve for 50 rounds
    Early stopping, best iteration is:
    [11]	valid_0's l2: 0.0580187
    
    🔁 Fold 4/5
    [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.
    You can set `force_col_wise=true` to remove the overhead.
    [LightGBM] [Info] Total Bins 1164
    [LightGBM] [Info] Number of data points in the train set: 3501, number of used features: 12
    [LightGBM] [Info] Start training from score 0.538018
    Training until validation scores don't improve for 50 rounds
    Early stopping, best iteration is:
    [35]	valid_0's l2: 0.0575089
    
    🔁 Fold 5/5
    [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
    You can set `force_col_wise=true` to remove the overhead.
    [LightGBM] [Info] Total Bins 1164
    [LightGBM] [Info] Number of data points in the train set: 3501, number of used features: 12
    [LightGBM] [Info] Start training from score 0.539760
    Training until validation scores don't improve for 50 rounds
    [100]	valid_0's l2: 0.0593835
    Early stopping, best iteration is:
    [56]	valid_0's l2: 0.0580773
    

```python
X = train.drop(columns=['성공확률'])
y = train['성공확률']
```

◾ X : 모델이 학습할 입력값(피처) '성공확률'은 예측하려는 값이기 때문에 drop합니다.

◾ y : 우리가 예측하고 싶은 타겟값이 '성공확률'이기 때문에 이렇게 설정합니다. 

```python
models = []
cv_scores = []
```

◾ models : 각 fold에서 학습된 모델을 저장해두는 리스트입니다. 나중에 앙상블 할 때 쓸 수도 있습니다. 

    ✅ 앙상블?
    ▪ 여러 모델의 예측을 결합해서 더 나은 성능을 얻는 기법입니다. 
    ▪ 각 fold에서 학습된 모델은 조금씩 다른 데이터를 보고 학습하였습니다. 
        ▫ 따라서 어떤 모델은 특정 패턴을 잘 보고 어떤 모델은 다른 부분에서 잘 예측하는 경향을 가질 수 있습니다.
    ▪ 그래서 각 모델들의 예측 결과를 평균하거나 가중평균, 또는 다수결 등으로 이용하여 다음과 같은 효과를 얻을 수 있습니다.  
        ▫ 개별 모델의 약저을 보완할 수 있습니다. 
        ▫ 결과적으로 더 안정적인 예측이 가능해집니다. 

◾ cv_scroes : 각 fold에서 얻은 검증 점수 (L2 loss)를 저장할 리스트입니다. 

```python 
kf = KFold(n_splits=5, shuffle=True, random_state=42)
```

◾ n_splits = 5 : 데이터를 5개로 나눠서 교차검증을 하겠다는 의미입니다. 

◾ shuffle = True : 데이터를 섞어서 좀 더 무작위성 있게 나누기 위해 설정합니다. 

◾ random_state = 42 : 랜덤한 분할을 항상 동일하게 만들기 위한 고정 시드입니다. 

```python 
for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):
```

◾ kf.split(X)은 학습용 index와 검증용 index를 5번 만들어달라는 의미입니다. 

◾ fold는 현재 몇 번째 fold인지 알려주는 번호의 시작입니다. (0부터 시작)

```python
X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]
```

◾ fold마다 분리된 학습 / 검증 데이터를 실제 데이터로 나눠줍니다. 

```python 
model = LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.05,
    random_state=42
)
```

◾ n_estimators : 최대 1000개의 트리를 만들 수 있습니다. (너무 많으면 오버피팅이 가능합니다.)

◾ learning_rate : 학습 속도를 결정하는 파라미터입니다. 작을수록 천천히, 하지만 더 정밀하게 학습합니다. 

◾ random_state : 결과 재현 가능하도록 고정값을 설정합니다 .

```python 
model.fit(
    X_train, y_train,
    eval_set=[(X_valid, y_valid)],
    callbacks=[
        early_stopping(stopping_rounds=50),
        log_evaluation(period=100)
    ]
)
```

◾ eval_set : 검증 데이터를 지정합니다. 여기서 모델 성능을 체크합니다. 

◾ early_stopping : 검증 성능이 50번 연속 좋아지지 않으면 학습을 일찍 종료합니다. 

◾ log_evaluation : 100번마다 학습 로그를 출력해줘서 경과를 확인할 수 있습니다. 

```python
models.append(model)
score = model.best_score_['valid_0']['l2']
cv_scores.append(score)
```

◾ 학습된 데이터를 models에 append 합니다.

◾ 검증 데이터에서의 L2 Loss(평균제곱오차)를 저정합니다. 

✅ 교차검증을 하는 이유 
    
    ▪ 하나의 고정된 검증셋으로만 평가하면 운이 좋거나 나쁜 경우도 포함돼서 성능이 흔들릴 수 있습니다. 
    ▪ 그래서 여러 번 나눠서 학습해보고, 평균적인 성능을 보는 것이 더 안정적입니다. 

🔍 결과 분석

◾ Fold 1/5 
    
    ▪ best iteration = 1
    ▪ l2 = 0.0579823 
        → 모델이 1번째 트리에서 성능이 가장 좋았습니다.
        → 즉, 초반에 성능이 좋아지고 이후로는 개선이 안된다는 의미이므로 과적합 될 가능성이 존재합니다. 
        
◾ Fold 2/5 
    
    ▪ best iteration = 11
    ▪ l2 = 0.0590495 
        → 11번째 트리에서 가장 성능이 좋았고, 그 이후로는 더 나아지지 않아서 early stopping
        → 여전히 좋은 성능입니다. 

◾ Fold 3/5 
    
    ▪ best iteration = 11
    ▪ l2 = 0.0580187
        → Fold 2와 거의 유사합니다. 모델이 비교적 빠르게 수렴하는 모습입니다. 

◾ Fold 4/5 
    
    ▪ best iteration = 35
    ▪ l2 = 0.0575089
        → 가장 낮은 오차입니다. 성능도 가장 좋고, 35번까지 학습한 것으로 보아 조금 더 복잡한 Fold 데이터 인 것으로 예측됩니다. 

◾ Fold 5/5 
    
    ▪ best iteration = 56
    ▪ l2 = 0.0580773
        → 꽤 많은 트리 수를 사용하였고, 성능은 평균 수준입니다.

# LGBM K-Fold Model Prediction

---

```python
# 테스트 데이터에서 feature만 추출
X_test = test  # 여기서만 feature 추출용으로 사용

# 모든 모델의 예측 결과 저장용
predictions = []

for model in models:
    preds = model.predict(X_test)
    predictions.append(preds)

# 모델들의 평균 예측
final_prediction = np.mean(predictions, axis=0)
```

---

```python
X_test = test
```

◾ test 데이터에는 '성공확률'이 없기 때문에 그대로 feature로 사용 가능합니다. 

```python
prediction = []
```

◾ 모델별 예측값을 저장할 리스트를 만들어줍니다. 

```python
for model in models : 
```

◾ 교차검증에서 저장한 5개의 모델을 하나씩 꺼내서 반복문을 수행합니다. 

```python
model.prediction(X_test)
```

◾ 각 모델로 테스트 데이터에 대해 예측을 수행합니다. 

```python
np.mean(predictions, axis = 0)
```

◾ 모델들의 예측을 평균 내어 최종 예측값을 생성합니다. 

# Submission

---

```python
# 제출 양식에 맞게 ID + 예측값 붙이기
sample_submission['성공확률'] = final_prediction
sample_submission.to_csv('./baseline_submission.csv', index = False, encoding = 'utf-8-sig')
```

---

```python
sample_submission['성공확률'] = final_prediction
```
◾ 제출 양식(sample_submission)에 만든 예측 결과(final_prediction)을 넣어줍니다.

◾ 여기서 '성공확률'은 컬럼명으로, 대회에서 요구한 이름과 일치합니다. 


```python
sample_submission.to_csv('./baseline_submission.csv', index = False, encoding = 'utf-8-sig')
```

◾ index = False 는 행 번호(index)를 저장하지 않도록 설정하는 것입니다. 

◾ encoding = 'utf-8-sig' 는 한글 깨짐 방지용 인코딩입니다.

📊 Public Leaderboard 성능

📌 제출 점수 (Weighted MAE): **0.22411**

🏅 등수: **62등**
